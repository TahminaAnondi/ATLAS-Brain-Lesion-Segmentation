{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'https://group-5.k8s-maia.com/'. Verify the server is running and reachable. (Invalid response: 503 Service Temporarily Unavailable)."
     ]
    }
   ],
   "source": [
    "!pip install keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Activation, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, SpatialDropout2D,Conv2DTranspose,Concatenate\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(x, n_base, batch_normalization):\n",
    "    \n",
    "    x = Conv2D(filters=n_base, kernel_size=(3,3), \n",
    "                        strides=(1,1),padding='same')(x)\n",
    "    if (batch_normalization):\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters=n_base, kernel_size=(3,3), \n",
    "                        strides=(1,1),padding='same')(x)\n",
    "    if (batch_normalization):\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_block(x, n_base, batch_normalization, dropout):\n",
    "    f = conv_block(x, n_base, batch_normalization)\n",
    "    p = layers.MaxPool2D(pool_size = (2,2))(f)\n",
    "    if(dropout):\n",
    "        p = layers.Dropout(0.2)(p)\n",
    "        \n",
    "    return f, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_block(x, f, n_base, batch_normalization, dropout):\n",
    "    \n",
    "    x = Conv2DTranspose(filters=n_base, kernel_size=(2,2), \n",
    "                         strides=(2,2),padding='same')(x)\n",
    "    x = Concatenate()([x,f])\n",
    "    if(dropout):\n",
    "        x = layers.Dropout(0.2)(x)\n",
    "    x = conv_block(x, n_base, batch_normalization)\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet(img_w, img_h, img_ch, n_base, LR, batch_normalization, dropout):\n",
    "\n",
    "    \n",
    "    \n",
    "    ## Encoder part\n",
    "#     model = Sequential()\n",
    "    inputs = layers.Input((img_w, img_h, img_ch))\n",
    "    \n",
    "    f1, p1 = downsample_block(inputs, n_base, batch_normalization, dropout)\n",
    "    f2, p2 = downsample_block(p1, n_base*2, batch_normalization, dropout)\n",
    "    f3, p3 = downsample_block(p2, n_base*4, batch_normalization, dropout)\n",
    "    f4, p4 = downsample_block(p3, n_base*8, batch_normalization, dropout)\n",
    "    \n",
    "    \n",
    "    ## Bottleneck\n",
    "    bottleneck = conv_block(p4, n_base*16, batch_normalization)\n",
    "    \n",
    "    ## Decoder part\n",
    "    p5 = upsample_block(bottleneck, f4, n_base*8, batch_normalization, dropout)\n",
    "    p6 = upsample_block(p5, f3, n_base*4, batch_normalization, dropout)\n",
    "    p7 = upsample_block(p6, f2, n_base*2, batch_normalization, dropout)\n",
    "    p8 = upsample_block(p7, f1, n_base, batch_normalization, dropout)\n",
    "\n",
    "    \n",
    "    ## 1 Convo layer\n",
    "    p9 = Conv2D(filters=1, kernel_size=(1,1), \n",
    "                            padding='same')(p8)\n",
    "    outputs = Activation('sigmoid')(p9)\n",
    "    \n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.8/dist-packages (0.19.3)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (2.22.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (1.9.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (21.3)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (9.1.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (2022.8.12)\n",
      "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (2.8.6)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (1.22.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->scikit-image) (3.0.9)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task1a) Lung segmentation in chest X-ray images:\n",
    "import os\n",
    "from random import shuffle\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "image_path = '/DL_course_data/Lab3/MRI/Image' \n",
    "mask_path = '/DL_course_data/Lab3/MRI/Mask'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(image_path,mask_path):\n",
    "    \n",
    "    image_list = os.listdir(image_path)\n",
    "    mask_list = os.listdir(mask_path)\n",
    "    \n",
    "    images = []\n",
    "    masks = []\n",
    "\n",
    "    for image in image_list:\n",
    "        img = imread(os.path.join(image_path, image), as_gray=True)  # \"as_grey\"\n",
    "        img = resize(img, (240, 240), anti_aliasing=True).astype('float32')\n",
    "        images.append(img)\n",
    "\n",
    "    for mask in mask_list:\n",
    "        mask_img = imread(os.path.join(mask_path, mask), as_gray=True)\n",
    "        mask_img = resize(mask_img, (240, 240), anti_aliasing=True).astype('float32')\n",
    "        masks.append(mask_img)\n",
    "        \n",
    "    ## Load data in traditional way\n",
    "    # img_train, img_val, mask_train, mask_val = train_test_split(images, masks, shuffle = True,\n",
    "    #                                                   test_size = 0.2)\n",
    "\n",
    "    images = np.expand_dims(images, axis = -1)\n",
    "    images = np.array(images)\n",
    "\n",
    "    masks = np.expand_dims(masks, axis = -1)\n",
    "    masks = np.array(masks)\n",
    "    \n",
    "    return images, masks\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + 0.0001) / (K.sum(y_true_f) + K.sum(y_pred_f) + 0.0001)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_base =8\n",
    "LR = 1e-4\n",
    "batch_normalization = True\n",
    "dropout = True\n",
    "epochs = 5\n",
    "Metric= 'Dice Coefficient'\n",
    "batch_size = 8\n",
    "\n",
    "img_w, img_h = 240,240\n",
    "img_ch = 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, masks = load_data(image_path,mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-e2c642e8f4a1>:1: DeprecationWarning: Please use `binary_dilation` from the `scipy.ndimage` namespace, the `scipy.ndimage.morphology` namespace is deprecated.\n",
      "  from scipy.ndimage.morphology import binary_dilation, binary_erosion\n",
      "<ipython-input-13-e2c642e8f4a1>:1: DeprecationWarning: Please use `binary_erosion` from the `scipy.ndimage` namespace, the `scipy.ndimage.morphology` namespace is deprecated.\n",
      "  from scipy.ndimage.morphology import binary_dilation, binary_erosion\n"
     ]
    }
   ],
   "source": [
    "from scipy.ndimage.morphology import binary_dilation, binary_erosion\n",
    "\n",
    "mask_dilated = np.zeros(masks.shape)\n",
    "mask_eroded = np.zeros(masks.shape)\n",
    "\n",
    "for i in range(len(masks)):\n",
    "    radius = 2\n",
    "    structure = np.ones((round(radius*2+1),round(radius*2+1)))\n",
    "    mask_dilated[i,:,:,0] = binary_dilation(masks[i,:,:,0], structure)\n",
    "    mask_eroded[i,:,:,0] = binary_erosion(masks[i,:,:,0],structure)\n",
    "weight_boundary = mask_dilated.astype(int) - mask_eroded.astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9403, 240, 240, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_boundary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_loss(weight_map, weight_strength): \n",
    "    def weighted_dice_loss(y_true, y_pred):\n",
    "        y_true_f = K.flatten(y_true) \n",
    "        y_pred_f = K.flatten(y_pred)\n",
    "        weight_f = K.flatten(weight_map) \n",
    "        weight_f = weight_f * weight_strength \n",
    "        weight_f = weight_f + 1\n",
    "        weighted_intersection = K.sum(weight_f * (y_true_f * y_pred_f))\n",
    "        return -(2. * weighted_intersection + K.epsilon()) / (K.sum(y_true_f) + K.sum(y_pred_f) + K.epsilon())\n",
    "    return weighted_dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_generator(gen1, gen2, gen3): \n",
    "    while True:\n",
    "        x = gen1.next() \n",
    "        y = gen2.next() \n",
    "        w = gen3.next() \n",
    "        yield([x, w], y)\n",
    "def generator_with_weights(x_train, y_train, weights_train, batch_size):\n",
    "    data_gen_args = dict(rotation_range=10.,\n",
    "                            width_shift_range=0.1, \n",
    "                            height_shift_range=0.1, \n",
    "                            zoom_range=0.2, \n",
    "                            horizontal_flip=True)\n",
    "    image_datagen = ImageDataGenerator(**data_gen_args) \n",
    "    mask_datagen = ImageDataGenerator(**data_gen_args) \n",
    "    weights_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "    image_generator = image_datagen.flow(x_train, shuffle=False, batch_size=batch_size,seed=1)\n",
    "    mask_generator = mask_datagen.flow(y_train, shuffle=False, batch_size=batch_size,seed=1)\n",
    "    weight_generator = weights_datagen.flow(weights_train, shuffle=False, batch_size=batch_size,seed=1)\n",
    "    \n",
    "    train_generator = combine_generator(image_generator, mask_generator,weight_generator)\n",
    "    return train_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_generator = generator_with_weights(x_train, y_train, weight_train, batch_size)\n",
    "\n",
    "model_history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, \n",
    "            epochs=n_epoch, verbose=1, max_queue_size=1, \n",
    "            validation_steps=len(x_val), \n",
    "            validation_data=([x_val, weight_val], y_val), class_weight='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=4)\n",
    "cvscores = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(x_train, y_train, batch_size):\n",
    "    n_train_sample = len(x_train)\n",
    "    while True:\n",
    "               \n",
    "        for ind in (range(0, n_train_sample, batch_size)):\n",
    "            \n",
    "            batch_img = x_train[ind:ind+batch_size]\n",
    "            batch_label = y_train[ind:ind+batch_size]\n",
    "            \n",
    "            # Sanity check assures batch size always satisfied\n",
    "            # by repeating the last 2-3 images at last batch.\n",
    "            length = len(batch_img)\n",
    "            if length == batch_size:\n",
    "                pass\n",
    "            else:\n",
    "                for tmp in range(batch_size - length):\n",
    "                    batch_img = np.append(batch_img, np.expand_dims(batch_img[-1],axis=0), axis = 0)\n",
    "                    batch_label = np.append(batch_label, np.expand_dims(batch_label[-1], axis=0), axis = 0)\n",
    "        \n",
    "            backgound_value = x_train.min()\n",
    "            data_gen_args = dict(rotation_range=10.,\n",
    "                                     width_shift_range=0.1,\n",
    "                                     height_shift_range=0.1,\n",
    "                                     cval = backgound_value,\n",
    "                                     zoom_range=0.2,\n",
    "                                     horizontal_flip = True)\n",
    "            \n",
    "            image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "            mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "            \n",
    "            image_generator = image_datagen.flow(batch_img, shuffle=False,\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 seed=1)\n",
    "            \n",
    "            mask_generator = mask_datagen.flow(batch_label, shuffle=False,\n",
    "                                               batch_size=batch_size,\n",
    "                                               seed=1)\n",
    "            \n",
    "            image = image_generator.next()\n",
    "            label = mask_generator.next()\n",
    "            \n",
    "            yield image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)           [(None, 240, 240, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_95 (Conv2D)             (None, 240, 240, 8)  80          ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 240, 240, 8)  32         ['conv2d_95[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_95 (Activation)     (None, 240, 240, 8)  0           ['batch_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_96 (Conv2D)             (None, 240, 240, 8)  584         ['activation_95[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 240, 240, 8)  32         ['conv2d_96[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_96 (Activation)     (None, 240, 240, 8)  0           ['batch_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_20 (MaxPooling2D  (None, 120, 120, 8)  0          ['activation_96[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_40 (Dropout)           (None, 120, 120, 8)  0           ['max_pooling2d_20[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_97 (Conv2D)             (None, 120, 120, 16  1168        ['dropout_40[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, 120, 120, 16  64         ['conv2d_97[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_97 (Activation)     (None, 120, 120, 16  0           ['batch_normalization_92[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_98 (Conv2D)             (None, 120, 120, 16  2320        ['activation_97[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, 120, 120, 16  64         ['conv2d_98[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_98 (Activation)     (None, 120, 120, 16  0           ['batch_normalization_93[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_21 (MaxPooling2D  (None, 60, 60, 16)  0           ['activation_98[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_41 (Dropout)           (None, 60, 60, 16)   0           ['max_pooling2d_21[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_99 (Conv2D)             (None, 60, 60, 32)   4640        ['dropout_41[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_94 (BatchN  (None, 60, 60, 32)  128         ['conv2d_99[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_99 (Activation)     (None, 60, 60, 32)   0           ['batch_normalization_94[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_100 (Conv2D)            (None, 60, 60, 32)   9248        ['activation_99[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_95 (BatchN  (None, 60, 60, 32)  128         ['conv2d_100[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_100 (Activation)    (None, 60, 60, 32)   0           ['batch_normalization_95[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_22 (MaxPooling2D  (None, 30, 30, 32)  0           ['activation_100[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_42 (Dropout)           (None, 30, 30, 32)   0           ['max_pooling2d_22[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_101 (Conv2D)            (None, 30, 30, 64)   18496       ['dropout_42[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_96 (BatchN  (None, 30, 30, 64)  256         ['conv2d_101[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_101 (Activation)    (None, 30, 30, 64)   0           ['batch_normalization_96[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_102 (Conv2D)            (None, 30, 30, 64)   36928       ['activation_101[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_97 (BatchN  (None, 30, 30, 64)  256         ['conv2d_102[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_102 (Activation)    (None, 30, 30, 64)   0           ['batch_normalization_97[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_23 (MaxPooling2D  (None, 15, 15, 64)  0           ['activation_102[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_43 (Dropout)           (None, 15, 15, 64)   0           ['max_pooling2d_23[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_103 (Conv2D)            (None, 15, 15, 128)  73856       ['dropout_43[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_98 (BatchN  (None, 15, 15, 128)  512        ['conv2d_103[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_103 (Activation)    (None, 15, 15, 128)  0           ['batch_normalization_98[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_104 (Conv2D)            (None, 15, 15, 128)  147584      ['activation_103[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_99 (BatchN  (None, 15, 15, 128)  512        ['conv2d_104[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_104 (Activation)    (None, 15, 15, 128)  0           ['batch_normalization_99[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose_20 (Conv2DTra  (None, 30, 30, 64)  32832       ['activation_104[0][0]']         \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_20 (Concatenate)   (None, 30, 30, 128)  0           ['conv2d_transpose_20[0][0]',    \n",
      "                                                                  'activation_102[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_44 (Dropout)           (None, 30, 30, 128)  0           ['concatenate_20[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_105 (Conv2D)            (None, 30, 30, 64)   73792       ['dropout_44[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_100 (Batch  (None, 30, 30, 64)  256         ['conv2d_105[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_105 (Activation)    (None, 30, 30, 64)   0           ['batch_normalization_100[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_106 (Conv2D)            (None, 30, 30, 64)   36928       ['activation_105[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_101 (Batch  (None, 30, 30, 64)  256         ['conv2d_106[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_106 (Activation)    (None, 30, 30, 64)   0           ['batch_normalization_101[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_transpose_21 (Conv2DTra  (None, 60, 60, 32)  8224        ['activation_106[0][0]']         \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_21 (Concatenate)   (None, 60, 60, 64)   0           ['conv2d_transpose_21[0][0]',    \n",
      "                                                                  'activation_100[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_45 (Dropout)           (None, 60, 60, 64)   0           ['concatenate_21[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_107 (Conv2D)            (None, 60, 60, 32)   18464       ['dropout_45[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_102 (Batch  (None, 60, 60, 32)  128         ['conv2d_107[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_107 (Activation)    (None, 60, 60, 32)   0           ['batch_normalization_102[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_108 (Conv2D)            (None, 60, 60, 32)   9248        ['activation_107[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_103 (Batch  (None, 60, 60, 32)  128         ['conv2d_108[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_108 (Activation)    (None, 60, 60, 32)   0           ['batch_normalization_103[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_transpose_22 (Conv2DTra  (None, 120, 120, 16  2064       ['activation_108[0][0]']         \n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_22 (Concatenate)   (None, 120, 120, 32  0           ['conv2d_transpose_22[0][0]',    \n",
      "                                )                                 'activation_98[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_46 (Dropout)           (None, 120, 120, 32  0           ['concatenate_22[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_109 (Conv2D)            (None, 120, 120, 16  4624        ['dropout_46[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_104 (Batch  (None, 120, 120, 16  64         ['conv2d_109[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_109 (Activation)    (None, 120, 120, 16  0           ['batch_normalization_104[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_110 (Conv2D)            (None, 120, 120, 16  2320        ['activation_109[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_105 (Batch  (None, 120, 120, 16  64         ['conv2d_110[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_110 (Activation)    (None, 120, 120, 16  0           ['batch_normalization_105[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_23 (Conv2DTra  (None, 240, 240, 8)  520        ['activation_110[0][0]']         \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_23 (Concatenate)   (None, 240, 240, 16  0           ['conv2d_transpose_23[0][0]',    \n",
      "                                )                                 'activation_96[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_47 (Dropout)           (None, 240, 240, 16  0           ['concatenate_23[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_111 (Conv2D)            (None, 240, 240, 8)  1160        ['dropout_47[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_106 (Batch  (None, 240, 240, 8)  32         ['conv2d_111[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_111 (Activation)    (None, 240, 240, 8)  0           ['batch_normalization_106[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_112 (Conv2D)            (None, 240, 240, 8)  584         ['activation_111[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_107 (Batch  (None, 240, 240, 8)  32         ['conv2d_112[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_112 (Activation)    (None, 240, 240, 8)  0           ['batch_normalization_107[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_113 (Conv2D)            (None, 240, 240, 1)  9           ['activation_112[0][0]']         \n",
      "                                                                                                  \n",
      " activation_113 (Activation)    (None, 240, 240, 1)  0           ['conv2d_113[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 488,617\n",
      "Trainable params: 487,145\n",
      "Non-trainable params: 1,472\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-72-628a63948e9c>:31: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(train_generator, steps_per_epoch = train_generator.n//batch_size,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "881/881 [==============================] - 75s 51ms/step - loss: 0.9553 - dice_coef: 0.0447 - precision_5: 0.0343 - recall_5: 0.9115 - val_loss: 0.9531 - val_dice_coef: 0.0469 - val_precision_5: 0.0425 - val_recall_5: 0.9014\n",
      "Epoch 2/5\n",
      "881/881 [==============================] - 45s 51ms/step - loss: 0.9426 - dice_coef: 0.0574 - precision_5: 0.0540 - recall_5: 0.9301 - val_loss: 0.9658 - val_dice_coef: 0.0342 - val_precision_5: 0.0785 - val_recall_5: 4.3460e-05\n",
      "Epoch 3/5\n",
      "881/881 [==============================] - 45s 52ms/step - loss: 0.9328 - dice_coef: 0.0672 - precision_5: 0.0610 - recall_5: 0.8904 - val_loss: 0.9646 - val_dice_coef: 0.0354 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 4/5\n",
      "881/881 [==============================] - 45s 51ms/step - loss: 0.9233 - dice_coef: 0.0767 - precision_5: 0.0639 - recall_5: 0.8555 - val_loss: 0.9613 - val_dice_coef: 0.0387 - val_precision_5: 0.0000e+00 - val_recall_5: 0.0000e+00\n",
      "Epoch 5/5\n",
      "881/881 [==============================] - 45s 51ms/step - loss: 0.9132 - dice_coef: 0.0869 - precision_5: 0.0662 - recall_5: 0.8153 - val_loss: 0.9714 - val_dice_coef: 0.0286 - val_precision_5: 0.0532 - val_recall_5: 0.0172\n",
      "74/74 [==============================] - 4s 48ms/step - loss: 0.9706 - dice_coef: 0.0293 - precision_5: 0.0628 - recall_5: 0.0251\n",
      "dice_coef: 2.93%\n",
      "2.93% (+/- 0.00%)\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 240, 240, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_114 (Conv2D)            (None, 240, 240, 8)  80          ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_108 (Batch  (None, 240, 240, 8)  32         ['conv2d_114[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_114 (Activation)    (None, 240, 240, 8)  0           ['batch_normalization_108[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_115 (Conv2D)            (None, 240, 240, 8)  584         ['activation_114[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_109 (Batch  (None, 240, 240, 8)  32         ['conv2d_115[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_115 (Activation)    (None, 240, 240, 8)  0           ['batch_normalization_109[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_24 (MaxPooling2D  (None, 120, 120, 8)  0          ['activation_115[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_48 (Dropout)           (None, 120, 120, 8)  0           ['max_pooling2d_24[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_116 (Conv2D)            (None, 120, 120, 16  1168        ['dropout_48[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_110 (Batch  (None, 120, 120, 16  64         ['conv2d_116[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_116 (Activation)    (None, 120, 120, 16  0           ['batch_normalization_110[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_117 (Conv2D)            (None, 120, 120, 16  2320        ['activation_116[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_111 (Batch  (None, 120, 120, 16  64         ['conv2d_117[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_117 (Activation)    (None, 120, 120, 16  0           ['batch_normalization_111[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_25 (MaxPooling2D  (None, 60, 60, 16)  0           ['activation_117[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_49 (Dropout)           (None, 60, 60, 16)   0           ['max_pooling2d_25[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_118 (Conv2D)            (None, 60, 60, 32)   4640        ['dropout_49[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_112 (Batch  (None, 60, 60, 32)  128         ['conv2d_118[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_118 (Activation)    (None, 60, 60, 32)   0           ['batch_normalization_112[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_119 (Conv2D)            (None, 60, 60, 32)   9248        ['activation_118[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_113 (Batch  (None, 60, 60, 32)  128         ['conv2d_119[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_119 (Activation)    (None, 60, 60, 32)   0           ['batch_normalization_113[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_26 (MaxPooling2D  (None, 30, 30, 32)  0           ['activation_119[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_50 (Dropout)           (None, 30, 30, 32)   0           ['max_pooling2d_26[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_120 (Conv2D)            (None, 30, 30, 64)   18496       ['dropout_50[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_114 (Batch  (None, 30, 30, 64)  256         ['conv2d_120[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_120 (Activation)    (None, 30, 30, 64)   0           ['batch_normalization_114[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_121 (Conv2D)            (None, 30, 30, 64)   36928       ['activation_120[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_115 (Batch  (None, 30, 30, 64)  256         ['conv2d_121[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_121 (Activation)    (None, 30, 30, 64)   0           ['batch_normalization_115[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_27 (MaxPooling2D  (None, 15, 15, 64)  0           ['activation_121[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_51 (Dropout)           (None, 15, 15, 64)   0           ['max_pooling2d_27[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_122 (Conv2D)            (None, 15, 15, 128)  73856       ['dropout_51[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_116 (Batch  (None, 15, 15, 128)  512        ['conv2d_122[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_122 (Activation)    (None, 15, 15, 128)  0           ['batch_normalization_116[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_123 (Conv2D)            (None, 15, 15, 128)  147584      ['activation_122[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_117 (Batch  (None, 15, 15, 128)  512        ['conv2d_123[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_123 (Activation)    (None, 15, 15, 128)  0           ['batch_normalization_117[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_transpose_24 (Conv2DTra  (None, 30, 30, 64)  32832       ['activation_123[0][0]']         \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_24 (Concatenate)   (None, 30, 30, 128)  0           ['conv2d_transpose_24[0][0]',    \n",
      "                                                                  'activation_121[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_52 (Dropout)           (None, 30, 30, 128)  0           ['concatenate_24[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_124 (Conv2D)            (None, 30, 30, 64)   73792       ['dropout_52[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_118 (Batch  (None, 30, 30, 64)  256         ['conv2d_124[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_124 (Activation)    (None, 30, 30, 64)   0           ['batch_normalization_118[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_125 (Conv2D)            (None, 30, 30, 64)   36928       ['activation_124[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_119 (Batch  (None, 30, 30, 64)  256         ['conv2d_125[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_125 (Activation)    (None, 30, 30, 64)   0           ['batch_normalization_119[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_transpose_25 (Conv2DTra  (None, 60, 60, 32)  8224        ['activation_125[0][0]']         \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_25 (Concatenate)   (None, 60, 60, 64)   0           ['conv2d_transpose_25[0][0]',    \n",
      "                                                                  'activation_119[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_53 (Dropout)           (None, 60, 60, 64)   0           ['concatenate_25[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_126 (Conv2D)            (None, 60, 60, 32)   18464       ['dropout_53[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_120 (Batch  (None, 60, 60, 32)  128         ['conv2d_126[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_126 (Activation)    (None, 60, 60, 32)   0           ['batch_normalization_120[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_127 (Conv2D)            (None, 60, 60, 32)   9248        ['activation_126[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_121 (Batch  (None, 60, 60, 32)  128         ['conv2d_127[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_127 (Activation)    (None, 60, 60, 32)   0           ['batch_normalization_121[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_transpose_26 (Conv2DTra  (None, 120, 120, 16  2064       ['activation_127[0][0]']         \n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_26 (Concatenate)   (None, 120, 120, 32  0           ['conv2d_transpose_26[0][0]',    \n",
      "                                )                                 'activation_117[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_54 (Dropout)           (None, 120, 120, 32  0           ['concatenate_26[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_128 (Conv2D)            (None, 120, 120, 16  4624        ['dropout_54[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_122 (Batch  (None, 120, 120, 16  64         ['conv2d_128[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_128 (Activation)    (None, 120, 120, 16  0           ['batch_normalization_122[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_129 (Conv2D)            (None, 120, 120, 16  2320        ['activation_128[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_123 (Batch  (None, 120, 120, 16  64         ['conv2d_129[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_129 (Activation)    (None, 120, 120, 16  0           ['batch_normalization_123[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_27 (Conv2DTra  (None, 240, 240, 8)  520        ['activation_129[0][0]']         \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_27 (Concatenate)   (None, 240, 240, 16  0           ['conv2d_transpose_27[0][0]',    \n",
      "                                )                                 'activation_115[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_55 (Dropout)           (None, 240, 240, 16  0           ['concatenate_27[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_130 (Conv2D)            (None, 240, 240, 8)  1160        ['dropout_55[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_124 (Batch  (None, 240, 240, 8)  32         ['conv2d_130[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_130 (Activation)    (None, 240, 240, 8)  0           ['batch_normalization_124[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_131 (Conv2D)            (None, 240, 240, 8)  584         ['activation_130[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_125 (Batch  (None, 240, 240, 8)  32         ['conv2d_131[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_131 (Activation)    (None, 240, 240, 8)  0           ['batch_normalization_125[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_132 (Conv2D)            (None, 240, 240, 1)  9           ['activation_131[0][0]']         \n",
      "                                                                                                  \n",
      " activation_132 (Activation)    (None, 240, 240, 1)  0           ['conv2d_132[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 488,617\n",
      "Trainable params: 487,145\n",
      "Non-trainable params: 1,472\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/5\n",
      "881/881 [==============================] - 48s 52ms/step - loss: 0.9439 - dice_coef: 0.0561 - precision_6: 0.0449 - recall_6: 0.8263 - val_loss: 0.9328 - val_dice_coef: 0.0672 - val_precision_6: 0.0616 - val_recall_6: 0.5356\n",
      "Epoch 2/5\n",
      "881/881 [==============================] - 45s 51ms/step - loss: 0.9181 - dice_coef: 0.0819 - precision_6: 0.0607 - recall_6: 0.8662 - val_loss: 0.9284 - val_dice_coef: 0.0716 - val_precision_6: 0.0717 - val_recall_6: 0.2934\n",
      "Epoch 3/5\n",
      "881/881 [==============================] - 45s 51ms/step - loss: 0.8999 - dice_coef: 0.1001 - precision_6: 0.0671 - recall_6: 0.7935 - val_loss: 0.9482 - val_dice_coef: 0.0518 - val_precision_6: 0.0577 - val_recall_6: 0.0670\n",
      "Epoch 4/5\n",
      "881/881 [==============================] - 45s 51ms/step - loss: 0.8876 - dice_coef: 0.1124 - precision_6: 0.0704 - recall_6: 0.7193 - val_loss: 0.9386 - val_dice_coef: 0.0614 - val_precision_6: 0.0645 - val_recall_6: 0.0790\n",
      "Epoch 5/5\n",
      "881/881 [==============================] - 45s 51ms/step - loss: 0.8804 - dice_coef: 0.1197 - precision_6: 0.0718 - recall_6: 0.6725 - val_loss: 0.8982 - val_dice_coef: 0.1018 - val_precision_6: 0.0673 - val_recall_6: 0.2865\n",
      "74/74 [==============================] - 4s 46ms/step - loss: 0.8996 - dice_coef: 0.1004 - precision_6: 0.0683 - recall_6: 0.2966\n",
      "dice_coef: 10.04%\n",
      "6.48% (+/- 3.56%)\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_8 (InputLayer)           [(None, 240, 240, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_133 (Conv2D)            (None, 240, 240, 8)  80          ['input_8[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_126 (Batch  (None, 240, 240, 8)  32         ['conv2d_133[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_133 (Activation)    (None, 240, 240, 8)  0           ['batch_normalization_126[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_134 (Conv2D)            (None, 240, 240, 8)  584         ['activation_133[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_127 (Batch  (None, 240, 240, 8)  32         ['conv2d_134[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_134 (Activation)    (None, 240, 240, 8)  0           ['batch_normalization_127[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_28 (MaxPooling2D  (None, 120, 120, 8)  0          ['activation_134[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_56 (Dropout)           (None, 120, 120, 8)  0           ['max_pooling2d_28[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_135 (Conv2D)            (None, 120, 120, 16  1168        ['dropout_56[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_128 (Batch  (None, 120, 120, 16  64         ['conv2d_135[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_135 (Activation)    (None, 120, 120, 16  0           ['batch_normalization_128[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_136 (Conv2D)            (None, 120, 120, 16  2320        ['activation_135[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_129 (Batch  (None, 120, 120, 16  64         ['conv2d_136[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_136 (Activation)    (None, 120, 120, 16  0           ['batch_normalization_129[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_29 (MaxPooling2D  (None, 60, 60, 16)  0           ['activation_136[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_57 (Dropout)           (None, 60, 60, 16)   0           ['max_pooling2d_29[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_137 (Conv2D)            (None, 60, 60, 32)   4640        ['dropout_57[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_130 (Batch  (None, 60, 60, 32)  128         ['conv2d_137[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_137 (Activation)    (None, 60, 60, 32)   0           ['batch_normalization_130[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_138 (Conv2D)            (None, 60, 60, 32)   9248        ['activation_137[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_131 (Batch  (None, 60, 60, 32)  128         ['conv2d_138[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_138 (Activation)    (None, 60, 60, 32)   0           ['batch_normalization_131[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_30 (MaxPooling2D  (None, 30, 30, 32)  0           ['activation_138[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_58 (Dropout)           (None, 30, 30, 32)   0           ['max_pooling2d_30[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_139 (Conv2D)            (None, 30, 30, 64)   18496       ['dropout_58[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_132 (Batch  (None, 30, 30, 64)  256         ['conv2d_139[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_139 (Activation)    (None, 30, 30, 64)   0           ['batch_normalization_132[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_140 (Conv2D)            (None, 30, 30, 64)   36928       ['activation_139[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_133 (Batch  (None, 30, 30, 64)  256         ['conv2d_140[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_140 (Activation)    (None, 30, 30, 64)   0           ['batch_normalization_133[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_31 (MaxPooling2D  (None, 15, 15, 64)  0           ['activation_140[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_59 (Dropout)           (None, 15, 15, 64)   0           ['max_pooling2d_31[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_141 (Conv2D)            (None, 15, 15, 128)  73856       ['dropout_59[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_134 (Batch  (None, 15, 15, 128)  512        ['conv2d_141[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_141 (Activation)    (None, 15, 15, 128)  0           ['batch_normalization_134[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_142 (Conv2D)            (None, 15, 15, 128)  147584      ['activation_141[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_135 (Batch  (None, 15, 15, 128)  512        ['conv2d_142[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_142 (Activation)    (None, 15, 15, 128)  0           ['batch_normalization_135[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_transpose_28 (Conv2DTra  (None, 30, 30, 64)  32832       ['activation_142[0][0]']         \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_28 (Concatenate)   (None, 30, 30, 128)  0           ['conv2d_transpose_28[0][0]',    \n",
      "                                                                  'activation_140[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_60 (Dropout)           (None, 30, 30, 128)  0           ['concatenate_28[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_143 (Conv2D)            (None, 30, 30, 64)   73792       ['dropout_60[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_136 (Batch  (None, 30, 30, 64)  256         ['conv2d_143[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_143 (Activation)    (None, 30, 30, 64)   0           ['batch_normalization_136[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_144 (Conv2D)            (None, 30, 30, 64)   36928       ['activation_143[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_137 (Batch  (None, 30, 30, 64)  256         ['conv2d_144[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_144 (Activation)    (None, 30, 30, 64)   0           ['batch_normalization_137[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_transpose_29 (Conv2DTra  (None, 60, 60, 32)  8224        ['activation_144[0][0]']         \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_29 (Concatenate)   (None, 60, 60, 64)   0           ['conv2d_transpose_29[0][0]',    \n",
      "                                                                  'activation_138[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_61 (Dropout)           (None, 60, 60, 64)   0           ['concatenate_29[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_145 (Conv2D)            (None, 60, 60, 32)   18464       ['dropout_61[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_138 (Batch  (None, 60, 60, 32)  128         ['conv2d_145[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_145 (Activation)    (None, 60, 60, 32)   0           ['batch_normalization_138[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_146 (Conv2D)            (None, 60, 60, 32)   9248        ['activation_145[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_139 (Batch  (None, 60, 60, 32)  128         ['conv2d_146[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_146 (Activation)    (None, 60, 60, 32)   0           ['batch_normalization_139[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_transpose_30 (Conv2DTra  (None, 120, 120, 16  2064       ['activation_146[0][0]']         \n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_30 (Concatenate)   (None, 120, 120, 32  0           ['conv2d_transpose_30[0][0]',    \n",
      "                                )                                 'activation_136[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_62 (Dropout)           (None, 120, 120, 32  0           ['concatenate_30[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_147 (Conv2D)            (None, 120, 120, 16  4624        ['dropout_62[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_140 (Batch  (None, 120, 120, 16  64         ['conv2d_147[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_147 (Activation)    (None, 120, 120, 16  0           ['batch_normalization_140[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_148 (Conv2D)            (None, 120, 120, 16  2320        ['activation_147[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_141 (Batch  (None, 120, 120, 16  64         ['conv2d_148[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_148 (Activation)    (None, 120, 120, 16  0           ['batch_normalization_141[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_31 (Conv2DTra  (None, 240, 240, 8)  520        ['activation_148[0][0]']         \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_31 (Concatenate)   (None, 240, 240, 16  0           ['conv2d_transpose_31[0][0]',    \n",
      "                                )                                 'activation_134[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_63 (Dropout)           (None, 240, 240, 16  0           ['concatenate_31[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_149 (Conv2D)            (None, 240, 240, 8)  1160        ['dropout_63[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_142 (Batch  (None, 240, 240, 8)  32         ['conv2d_149[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_149 (Activation)    (None, 240, 240, 8)  0           ['batch_normalization_142[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_150 (Conv2D)            (None, 240, 240, 8)  584         ['activation_149[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_143 (Batch  (None, 240, 240, 8)  32         ['conv2d_150[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_150 (Activation)    (None, 240, 240, 8)  0           ['batch_normalization_143[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_151 (Conv2D)            (None, 240, 240, 1)  9           ['activation_150[0][0]']         \n",
      "                                                                                                  \n",
      " activation_151 (Activation)    (None, 240, 240, 1)  0           ['conv2d_151[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 488,617\n",
      "Trainable params: 487,145\n",
      "Non-trainable params: 1,472\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/5\n",
      "881/881 [==============================] - 48s 52ms/step - loss: 0.9409 - dice_coef: 0.0591 - precision_7: 0.0445 - recall_7: 0.8304 - val_loss: 0.9442 - val_dice_coef: 0.0558 - val_precision_7: 0.0468 - val_recall_7: 0.3760\n",
      "Epoch 2/5\n",
      "881/881 [==============================] - 45s 52ms/step - loss: 0.9117 - dice_coef: 0.0883 - precision_7: 0.0624 - recall_7: 0.8687 - val_loss: 0.9575 - val_dice_coef: 0.0425 - val_precision_7: 0.0878 - val_recall_7: 0.0639\n",
      "Epoch 3/5\n",
      "881/881 [==============================] - 45s 51ms/step - loss: 0.8935 - dice_coef: 0.1065 - precision_7: 0.0692 - recall_7: 0.7859 - val_loss: 0.9458 - val_dice_coef: 0.0542 - val_precision_7: 0.0733 - val_recall_7: 0.0827\n",
      "Epoch 4/5\n",
      "881/881 [==============================] - 45s 51ms/step - loss: 0.8824 - dice_coef: 0.1176 - precision_7: 0.0723 - recall_7: 0.7213 - val_loss: 0.9761 - val_dice_coef: 0.0239 - val_precision_7: 0.0694 - val_recall_7: 0.0062\n",
      "Epoch 5/5\n",
      "881/881 [==============================] - 45s 52ms/step - loss: 0.8761 - dice_coef: 0.1239 - precision_7: 0.0735 - recall_7: 0.6867 - val_loss: 0.9483 - val_dice_coef: 0.0517 - val_precision_7: 0.0749 - val_recall_7: 0.0494\n",
      "74/74 [==============================] - 4s 46ms/step - loss: 0.9578 - dice_coef: 0.0419 - precision_7: 0.0796 - recall_7: 0.0364\n",
      "dice_coef: 4.19%\n",
      "5.72% (+/- 3.10%)\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 240, 240, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_152 (Conv2D)            (None, 240, 240, 8)  80          ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_144 (Batch  (None, 240, 240, 8)  32         ['conv2d_152[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_152 (Activation)    (None, 240, 240, 8)  0           ['batch_normalization_144[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_153 (Conv2D)            (None, 240, 240, 8)  584         ['activation_152[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_145 (Batch  (None, 240, 240, 8)  32         ['conv2d_153[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_153 (Activation)    (None, 240, 240, 8)  0           ['batch_normalization_145[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_32 (MaxPooling2D  (None, 120, 120, 8)  0          ['activation_153[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_64 (Dropout)           (None, 120, 120, 8)  0           ['max_pooling2d_32[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_154 (Conv2D)            (None, 120, 120, 16  1168        ['dropout_64[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_146 (Batch  (None, 120, 120, 16  64         ['conv2d_154[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_154 (Activation)    (None, 120, 120, 16  0           ['batch_normalization_146[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_155 (Conv2D)            (None, 120, 120, 16  2320        ['activation_154[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_147 (Batch  (None, 120, 120, 16  64         ['conv2d_155[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_155 (Activation)    (None, 120, 120, 16  0           ['batch_normalization_147[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_33 (MaxPooling2D  (None, 60, 60, 16)  0           ['activation_155[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_65 (Dropout)           (None, 60, 60, 16)   0           ['max_pooling2d_33[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_156 (Conv2D)            (None, 60, 60, 32)   4640        ['dropout_65[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_148 (Batch  (None, 60, 60, 32)  128         ['conv2d_156[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_156 (Activation)    (None, 60, 60, 32)   0           ['batch_normalization_148[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_157 (Conv2D)            (None, 60, 60, 32)   9248        ['activation_156[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_149 (Batch  (None, 60, 60, 32)  128         ['conv2d_157[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_157 (Activation)    (None, 60, 60, 32)   0           ['batch_normalization_149[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_34 (MaxPooling2D  (None, 30, 30, 32)  0           ['activation_157[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_66 (Dropout)           (None, 30, 30, 32)   0           ['max_pooling2d_34[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_158 (Conv2D)            (None, 30, 30, 64)   18496       ['dropout_66[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_150 (Batch  (None, 30, 30, 64)  256         ['conv2d_158[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_158 (Activation)    (None, 30, 30, 64)   0           ['batch_normalization_150[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_159 (Conv2D)            (None, 30, 30, 64)   36928       ['activation_158[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_151 (Batch  (None, 30, 30, 64)  256         ['conv2d_159[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_159 (Activation)    (None, 30, 30, 64)   0           ['batch_normalization_151[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_35 (MaxPooling2D  (None, 15, 15, 64)  0           ['activation_159[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_67 (Dropout)           (None, 15, 15, 64)   0           ['max_pooling2d_35[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_160 (Conv2D)            (None, 15, 15, 128)  73856       ['dropout_67[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_152 (Batch  (None, 15, 15, 128)  512        ['conv2d_160[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_160 (Activation)    (None, 15, 15, 128)  0           ['batch_normalization_152[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_161 (Conv2D)            (None, 15, 15, 128)  147584      ['activation_160[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_153 (Batch  (None, 15, 15, 128)  512        ['conv2d_161[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_161 (Activation)    (None, 15, 15, 128)  0           ['batch_normalization_153[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_transpose_32 (Conv2DTra  (None, 30, 30, 64)  32832       ['activation_161[0][0]']         \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_32 (Concatenate)   (None, 30, 30, 128)  0           ['conv2d_transpose_32[0][0]',    \n",
      "                                                                  'activation_159[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_68 (Dropout)           (None, 30, 30, 128)  0           ['concatenate_32[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_162 (Conv2D)            (None, 30, 30, 64)   73792       ['dropout_68[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_154 (Batch  (None, 30, 30, 64)  256         ['conv2d_162[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_162 (Activation)    (None, 30, 30, 64)   0           ['batch_normalization_154[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_163 (Conv2D)            (None, 30, 30, 64)   36928       ['activation_162[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_155 (Batch  (None, 30, 30, 64)  256         ['conv2d_163[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_163 (Activation)    (None, 30, 30, 64)   0           ['batch_normalization_155[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_transpose_33 (Conv2DTra  (None, 60, 60, 32)  8224        ['activation_163[0][0]']         \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_33 (Concatenate)   (None, 60, 60, 64)   0           ['conv2d_transpose_33[0][0]',    \n",
      "                                                                  'activation_157[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_69 (Dropout)           (None, 60, 60, 64)   0           ['concatenate_33[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_164 (Conv2D)            (None, 60, 60, 32)   18464       ['dropout_69[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_156 (Batch  (None, 60, 60, 32)  128         ['conv2d_164[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_164 (Activation)    (None, 60, 60, 32)   0           ['batch_normalization_156[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_165 (Conv2D)            (None, 60, 60, 32)   9248        ['activation_164[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_157 (Batch  (None, 60, 60, 32)  128         ['conv2d_165[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_165 (Activation)    (None, 60, 60, 32)   0           ['batch_normalization_157[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_transpose_34 (Conv2DTra  (None, 120, 120, 16  2064       ['activation_165[0][0]']         \n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_34 (Concatenate)   (None, 120, 120, 32  0           ['conv2d_transpose_34[0][0]',    \n",
      "                                )                                 'activation_155[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_70 (Dropout)           (None, 120, 120, 32  0           ['concatenate_34[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_166 (Conv2D)            (None, 120, 120, 16  4624        ['dropout_70[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_158 (Batch  (None, 120, 120, 16  64         ['conv2d_166[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_166 (Activation)    (None, 120, 120, 16  0           ['batch_normalization_158[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_167 (Conv2D)            (None, 120, 120, 16  2320        ['activation_166[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_159 (Batch  (None, 120, 120, 16  64         ['conv2d_167[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_167 (Activation)    (None, 120, 120, 16  0           ['batch_normalization_159[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_35 (Conv2DTra  (None, 240, 240, 8)  520        ['activation_167[0][0]']         \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_35 (Concatenate)   (None, 240, 240, 16  0           ['conv2d_transpose_35[0][0]',    \n",
      "                                )                                 'activation_153[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_71 (Dropout)           (None, 240, 240, 16  0           ['concatenate_35[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_168 (Conv2D)            (None, 240, 240, 8)  1160        ['dropout_71[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_160 (Batch  (None, 240, 240, 8)  32         ['conv2d_168[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_168 (Activation)    (None, 240, 240, 8)  0           ['batch_normalization_160[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_169 (Conv2D)            (None, 240, 240, 8)  584         ['activation_168[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_161 (Batch  (None, 240, 240, 8)  32         ['conv2d_169[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_169 (Activation)    (None, 240, 240, 8)  0           ['batch_normalization_161[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_170 (Conv2D)            (None, 240, 240, 1)  9           ['activation_169[0][0]']         \n",
      "                                                                                                  \n",
      " activation_170 (Activation)    (None, 240, 240, 1)  0           ['conv2d_170[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 488,617\n",
      "Trainable params: 487,145\n",
      "Non-trainable params: 1,472\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/5\n",
      "881/881 [==============================] - 49s 52ms/step - loss: 0.9506 - dice_coef: 0.0494 - precision_8: 0.0407 - recall_8: 0.9046 - val_loss: 0.9628 - val_dice_coef: 0.0372 - val_precision_8: 0.0684 - val_recall_8: 0.0290\n",
      "Epoch 2/5\n",
      "881/881 [==============================] - 46s 52ms/step - loss: 0.9310 - dice_coef: 0.0690 - precision_8: 0.0578 - recall_8: 0.8952 - val_loss: 0.9729 - val_dice_coef: 0.0271 - val_precision_8: 0.0860 - val_recall_8: 0.0023\n",
      "Epoch 3/5\n",
      "881/881 [==============================] - 45s 51ms/step - loss: 0.9160 - dice_coef: 0.0840 - precision_8: 0.0629 - recall_8: 0.8332 - val_loss: 0.9691 - val_dice_coef: 0.0309 - val_precision_8: 0.0734 - val_recall_8: 0.0071\n",
      "Epoch 4/5\n",
      "881/881 [==============================] - 45s 52ms/step - loss: 0.9026 - dice_coef: 0.0974 - precision_8: 0.0664 - recall_8: 0.7716 - val_loss: 0.9647 - val_dice_coef: 0.0353 - val_precision_8: 0.0644 - val_recall_8: 0.0097\n",
      "Epoch 5/5\n",
      "881/881 [==============================] - 45s 52ms/step - loss: 0.8926 - dice_coef: 0.1075 - precision_8: 0.0687 - recall_8: 0.7133 - val_loss: 0.9591 - val_dice_coef: 0.0409 - val_precision_8: 0.0659 - val_recall_8: 0.0172\n",
      "74/74 [==============================] - 4s 48ms/step - loss: 0.9637 - dice_coef: 0.0361 - precision_8: 0.0705 - recall_8: 0.0135\n",
      "dice_coef: 3.61%\n",
      "5.19% (+/- 2.84%)\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import image\n",
    "\n",
    "for train, val in kf.split(images, masks):\n",
    "    image_train, image_val = images[train],images[val]\n",
    "    mask_train, mask_val = masks[train], masks[val]\n",
    "    ## Get model\n",
    "    model = get_unet(img_w, img_h, img_ch, n_base, LR, \n",
    "                batch_normalization, dropout)\n",
    "\n",
    "    ## Add augmentation\n",
    "    image_aug = ImageDataGenerator(rotation_range=10,\n",
    "                                    width_shift_range=0.1,\n",
    "                                    height_shift_range=0.1,\n",
    "                                    zoom_range = 0.2,\n",
    "                                    horizontal_flip=True)\n",
    "\n",
    "    train_generator = image_aug.flow(\n",
    "                                    image_train,mask_train,\n",
    "                                    batch_size = batch_size)\n",
    "\n",
    "    val_generator = image_aug.flow(\n",
    "                                    image_val,mask_val,\n",
    "                                    batch_size = batch_size)\n",
    "\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss = [dice_coef_loss],          # Model Compiling   \n",
    "                optimizer = Adam(lr = LR),\n",
    "                metrics = [dice_coef, tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "    model.fit_generator(train_generator, steps_per_epoch = train_generator.n//batch_size,\n",
    "                validation_data = val_generator, validation_steps = val_generator.n//batch_size,\n",
    "                epochs = epochs,  verbose=1)\n",
    "\n",
    "\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(image_val, mask_val, verbose=1)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "    \n",
    "    print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.9252661392092705, 10.042130947113037, 4.18890155851841, 3.611527383327484]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'dice_coef', 'precision_8', 'recall_8']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
