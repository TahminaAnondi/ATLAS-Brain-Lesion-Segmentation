{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /usr/local/lib/python3.8/dist-packages (2.9.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Activation, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, SpatialDropout2D,Conv2DTranspose,Concatenate\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(x, n_base, batch_normalization):\n",
    "    \n",
    "    x = Conv2D(filters=n_base, kernel_size=(3,3), \n",
    "                        strides=(1,1),padding='same')(x)\n",
    "    if (batch_normalization):\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters=n_base, kernel_size=(3,3), \n",
    "                        strides=(1,1),padding='same')(x)\n",
    "    if (batch_normalization):\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_block(x, n_base, batch_normalization, dropout):\n",
    "    f = conv_block(x, n_base, batch_normalization)\n",
    "    p = layers.MaxPool2D(pool_size = (2,2))(f)\n",
    "    if(dropout):\n",
    "        p = layers.Dropout(0.2)(p)\n",
    "        \n",
    "    return f, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_block(x, f, n_base, batch_normalization, dropout):\n",
    "    \n",
    "    x = Conv2DTranspose(filters=n_base, kernel_size=(2,2), \n",
    "                         strides=(2,2),padding='same')(x)\n",
    "    x = Concatenate()([x,f])\n",
    "    if(dropout):\n",
    "        x = layers.Dropout(0.2)(x)\n",
    "    x = conv_block(x, n_base, batch_normalization)\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet_weightmap(img_w, img_h, img_ch, n_base, LR, batch_normalization, dropout):\n",
    "\n",
    "    \n",
    "    \n",
    "    ## Encoder part\n",
    "#     model = Sequential()\n",
    "    image = layers.Input((img_w, img_h, img_ch))\n",
    "    weight = layers.Input((img_w, img_h, img_ch))\n",
    "    inputs= layers.concatenate([image,weight],axis=-1)\n",
    "\n",
    "    # inputs = layers.Input((img_w, img_h, img_ch))\n",
    "    \n",
    "    f1, p1 = downsample_block(inputs, n_base, batch_normalization, dropout)\n",
    "    f2, p2 = downsample_block(p1, n_base*2, batch_normalization, dropout)\n",
    "    f3, p3 = downsample_block(p2, n_base*4, batch_normalization, dropout)\n",
    "    f4, p4 = downsample_block(p3, n_base*8, batch_normalization, dropout)\n",
    "    \n",
    "    \n",
    "    ## Bottleneck\n",
    "    bottleneck = conv_block(p4, n_base*16, batch_normalization)\n",
    "    \n",
    "    ## Decoder part\n",
    "    p5 = upsample_block(bottleneck, f4, n_base*8, batch_normalization, dropout)\n",
    "    p6 = upsample_block(p5, f3, n_base*4, batch_normalization, dropout)\n",
    "    p7 = upsample_block(p6, f2, n_base*2, batch_normalization, dropout)\n",
    "    p8 = upsample_block(p7, f1, n_base, batch_normalization, dropout)\n",
    "\n",
    "    \n",
    "    ## 1 Convo layer\n",
    "    p9 = Conv2D(filters=1, kernel_size=(1,1), \n",
    "                            padding='same')(p8)\n",
    "    outputs = Activation('sigmoid')(p9)\n",
    "    \n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.8/dist-packages (0.19.3)\n",
      "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (2.8.6)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (2.22.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (1.22.3)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (9.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (21.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (1.9.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (2022.8.12)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->scikit-image) (3.0.9)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task1a) Lung segmentation in chest X-ray images:\n",
    "import os\n",
    "from random import shuffle\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "image_path = '/DL_course_data/Lab3/MRI/Image' \n",
    "mask_path = '/DL_course_data/Lab3/MRI/Mask'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Brats17_TCIA_117_1_t1ce_61_Tumor.png'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'Brats17_TCIA_117_1_t1ce_61.png'\n",
    "mask = str.replace(name,'.png','_Tumor.png')\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(image_path,mask_path):\n",
    "    \n",
    "    image_list = os.listdir(image_path)\n",
    "    mask_list = os.listdir(mask_path)\n",
    "    \n",
    "    images = []\n",
    "    masks = []\n",
    "\n",
    "    for image in image_list:\n",
    "        img = imread(os.path.join(image_path, image), as_gray=True)  # \"as_grey\"\n",
    "        img = resize(img, (240, 240), anti_aliasing=True).astype('float32')\n",
    "        images.append(img)\n",
    "\n",
    "    for image in image_list:\n",
    "        mask = str.replace(image,'.png','_Tumor.png')\n",
    "        mask_img = imread(os.path.join(mask_path, mask), as_gray=True)\n",
    "        mask_img = resize(mask_img, (240, 240), anti_aliasing=True).astype('float32')\n",
    "        masks.append(mask_img)\n",
    "        \n",
    "    ## Load data in traditional way\n",
    "    # img_train, img_val, mask_train, mask_val = train_test_split(images, masks, shuffle = True,\n",
    "    #                                                   test_size = 0.2)\n",
    "\n",
    "    images = np.expand_dims(images, axis = -1)\n",
    "    images = np.array(images)\n",
    "\n",
    "    masks = np.expand_dims(masks, axis = -1)\n",
    "    masks = np.array(masks)\n",
    "    \n",
    "    return images, masks\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + 0.0001) / (K.sum(y_true_f) + K.sum(y_pred_f) + 0.0001)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_base =8\n",
    "LR = 1e-4\n",
    "batch_normalization = True\n",
    "dropout = True\n",
    "epochs = 100\n",
    "Metric= 'Dice Coefficient'\n",
    "batch_size = 8\n",
    "\n",
    "img_w, img_h = 240,240\n",
    "img_ch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, masks = load_data(image_path,mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('images', images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('masks', masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.load('images.npy')\n",
    "masks = np.load('masks.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import binary_dilation, binary_erosion\n",
    "\n",
    "mask_dilated = np.zeros(masks.shape)\n",
    "mask_eroded = np.zeros(masks.shape)\n",
    "radius = 2\n",
    "structure = np.ones((round(radius*2+1),round(radius*2+1)))\n",
    "\n",
    "for i in range(len(masks)):\n",
    "    mask_dilated[i,:,:,0] = binary_dilation(masks[i,:,:,0], structure)\n",
    "    mask_eroded[i,:,:,0] = binary_erosion(masks[i,:,:,0],structure)\n",
    "weight_boundary = mask_dilated.astype(int) - mask_eroded.astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(weight_boundary[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_loss(weight_map, weight_strength): \n",
    "    def weighted_dice_loss(y_true, y_pred):\n",
    "        y_true_f = K.flatten(y_true) \n",
    "        y_pred_f = K.flatten(y_pred)\n",
    "        weight_f = K.flatten(weight_map) \n",
    "        weight_f = weight_f * weight_strength \n",
    "        weight_f = 1/(weight_f + 1)\n",
    "        weighted_intersection = K.sum(weight_f * (y_true_f * y_pred_f))\n",
    "        return -(2. * weighted_intersection + K.epsilon()) / (K.sum(y_true_f) + K.sum(y_pred_f) + K.epsilon())\n",
    "    return weighted_dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9403, 240, 240, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import concatenate\n",
    "\n",
    "\n",
    "def generator_with_weights(x_train, y_train, weight_train, batch_size):\n",
    "    n_train_sample = len(x_train)\n",
    "    while True:\n",
    "               \n",
    "        for ind in (range(0, n_train_sample, batch_size)):\n",
    "            \n",
    "            batch_img = x_train[ind:ind+batch_size]\n",
    "            batch_weightmap = weight_train[ind:ind+batch_size]\n",
    "            batch_label = y_train[ind:ind+batch_size]\n",
    "            \n",
    "            # Sanity check assures batch size always satisfied\n",
    "            # by repeating the last 2-3 images at last batch.\n",
    "            length = len(batch_img)\n",
    "            if length == batch_size:\n",
    "                pass\n",
    "            else:\n",
    "                for tmp in range(batch_size - length):\n",
    "                    batch_img = np.append(batch_img, np.expand_dims(batch_img[-1],axis=0), axis = 0)\n",
    "                    batch_weightmap = np.append(batch_weightmap, np.expand_dims(batch_weightmap[-1],axis=0), axis = 0)\n",
    "                    batch_label = np.append(batch_label, np.expand_dims(batch_label[-1], axis=0), axis = 0)\n",
    "        \n",
    "            backgound_value = x_train.min()\n",
    "            data_gen_args = dict(rotation_range=10.,\n",
    "                                     width_shift_range=0.1,\n",
    "                                     height_shift_range=0.1,\n",
    "                                     cval = backgound_value,\n",
    "                                     zoom_range=0.2,\n",
    "                                     horizontal_flip = True)\n",
    "            \n",
    "            image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "            weights_datagen = ImageDataGenerator(**data_gen_args)\n",
    "            mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "            \n",
    "            image_generator = image_datagen.flow(batch_img, shuffle=False,\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 seed=1)\n",
    "\n",
    "            weights_generator = image_datagen.flow(batch_weightmap, shuffle=False,\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 seed=1)\n",
    "            \n",
    "            mask_generator = mask_datagen.flow(batch_label, shuffle=False,\n",
    "                                               batch_size=batch_size,\n",
    "                                               seed=1)\n",
    "            \n",
    "            image = image_generator.next()\n",
    "            weight = weights_generator.next()\n",
    "            label = mask_generator.next()\n",
    "            input = concatenate([image,weight],axis=-1)\n",
    "            \n",
    "            \n",
    "            yield input, label\n",
    "            # yield (image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=4)\n",
    "cvscores = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train, val in kf.split(images, masks, weight_boundary):\n",
    "#     image_train, image_val = images[train],images[val]\n",
    "#     weight_train, weight_val = weight_boundary[train], weight_boundary[val]\n",
    "#     mask_train, mask_val = masks[train], masks[val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Get model\n",
    "# model = get_unet_weightmap(img_w, img_h, img_ch, n_base, LR, \n",
    "#             batch_normalization, dropout)\n",
    "\n",
    "# train_generator = generator_with_weights(image_train, mask_train, weight_train, batch_size)\n",
    "# val_generator = generator_with_weights(image_val, mask_val, weight_val, batch_size)\n",
    "\n",
    "# # Compile the modela\n",
    "# model.compile(loss = [dice_coef_loss],          # Model Compiling   \n",
    "#             optimizer = Adam(lr = LR),\n",
    "#             metrics = [dice_coef, tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "# model_history = model.fit(train_generator, \n",
    "#                 validation_data = (val_generator), batch_size = batch_size,\n",
    "#                 epochs = epochs,  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'mlcompute' from 'tensorflow.python.compiler' (/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/compiler/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/xinyi/Documents/GitHub/deep_learning_G5/Lab5/Lab_5_task_2.ipynb Cell 25\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/xinyi/Documents/GitHub/deep_learning_G5/Lab5/Lab_5_task_2.ipynb#X52sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompiler\u001b[39;00m \u001b[39mimport\u001b[39;00m mlcompute\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/xinyi/Documents/GitHub/deep_learning_G5/Lab5/Lab_5_task_2.ipynb#X52sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m tf\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mrun_functions_eagerly(\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/xinyi/Documents/GitHub/deep_learning_G5/Lab5/Lab_5_task_2.ipynb#X52sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m mlcompute\u001b[39m.\u001b[39mset_mlc_device(device_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgpu\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'mlcompute' from 'tensorflow.python.compiler' (/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/compiler/__init__.py)"
     ]
    }
   ],
   "source": [
    "# from tensorflow.python.compiler import mlcompute\n",
    "\n",
    "tf.config.run_functions_eagerly(True)\n",
    "mlcompute.set_mlc_device(device_name='gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_available = tf.test.is_gpu_available()\n",
    "gpu_available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)           [(None, 240, 240, 2  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 240, 240, 8)  152         ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 240, 240, 8)  32         ['conv2d_19[1][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 240, 240, 8)  0           ['batch_normalization_18[1][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 240, 240, 8)  584         ['activation_19[1][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 240, 240, 8)  32         ['conv2d_20[1][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 240, 240, 8)  0           ['batch_normalization_19[1][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 120, 120, 8)  0          ['activation_20[1][0]']          \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 120, 120, 8)  0           ['max_pooling2d_4[1][0]']        \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 120, 120, 16  1168        ['dropout_8[1][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 120, 120, 16  64         ['conv2d_21[1][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 120, 120, 16  0           ['batch_normalization_20[1][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 120, 120, 16  2320        ['activation_21[1][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 120, 120, 16  64         ['conv2d_22[1][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 120, 120, 16  0           ['batch_normalization_21[1][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 60, 60, 16)  0           ['activation_22[1][0]']          \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 60, 60, 16)   0           ['max_pooling2d_5[1][0]']        \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 60, 60, 32)   4640        ['dropout_9[1][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 60, 60, 32)  128         ['conv2d_23[1][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 60, 60, 32)   0           ['batch_normalization_22[1][0]'] \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 60, 60, 32)   9248        ['activation_23[1][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 60, 60, 32)  128         ['conv2d_24[1][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 60, 60, 32)   0           ['batch_normalization_23[1][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPooling2D)  (None, 30, 30, 32)  0           ['activation_24[1][0]']          \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 30, 30, 32)   0           ['max_pooling2d_6[1][0]']        \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 30, 30, 64)   18496       ['dropout_10[1][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 30, 30, 64)  256         ['conv2d_25[1][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 30, 30, 64)   0           ['batch_normalization_24[1][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 30, 30, 64)   36928       ['activation_25[1][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 30, 30, 64)  256         ['conv2d_26[1][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 30, 30, 64)   0           ['batch_normalization_25[1][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPooling2D)  (None, 15, 15, 64)  0           ['activation_26[1][0]']          \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 15, 15, 64)   0           ['max_pooling2d_7[1][0]']        \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 15, 15, 128)  73856       ['dropout_11[1][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 15, 15, 128)  512        ['conv2d_27[1][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 15, 15, 128)  0           ['batch_normalization_26[1][0]'] \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 15, 15, 128)  147584      ['activation_27[1][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 15, 15, 128)  512        ['conv2d_28[1][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 15, 15, 128)  0           ['batch_normalization_27[1][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose_4 (Conv2DTran  (None, 30, 30, 64)  32832       ['activation_28[1][0]']          \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 30, 30, 128)  0           ['conv2d_transpose_4[1][0]',     \n",
      "                                                                  'activation_26[1][0]']          \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 30, 30, 128)  0           ['concatenate_6[1][0]']          \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 30, 30, 64)   73792       ['dropout_12[1][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 30, 30, 64)  256         ['conv2d_29[1][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 30, 30, 64)   0           ['batch_normalization_28[1][0]'] \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 30, 30, 64)   36928       ['activation_29[1][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 30, 30, 64)  256         ['conv2d_30[1][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 30, 30, 64)   0           ['batch_normalization_29[1][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose_5 (Conv2DTran  (None, 60, 60, 32)  8224        ['activation_30[1][0]']          \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 60, 60, 64)   0           ['conv2d_transpose_5[1][0]',     \n",
      "                                                                  'activation_24[1][0]']          \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 60, 60, 64)   0           ['concatenate_7[1][0]']          \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 60, 60, 32)   18464       ['dropout_13[1][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 60, 60, 32)  128         ['conv2d_31[1][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 60, 60, 32)   0           ['batch_normalization_30[1][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 60, 60, 32)   9248        ['activation_31[1][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 60, 60, 32)  128         ['conv2d_32[1][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 60, 60, 32)   0           ['batch_normalization_31[1][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose_6 (Conv2DTran  (None, 120, 120, 16  2064       ['activation_32[1][0]']          \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 120, 120, 32  0           ['conv2d_transpose_6[1][0]',     \n",
      "                                )                                 'activation_22[1][0]']          \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 120, 120, 32  0           ['concatenate_8[1][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 120, 120, 16  4624        ['dropout_14[1][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 120, 120, 16  64         ['conv2d_33[1][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 120, 120, 16  0           ['batch_normalization_32[1][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 120, 120, 16  2320        ['activation_33[1][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 120, 120, 16  64         ['conv2d_34[1][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 120, 120, 16  0           ['batch_normalization_33[1][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_7 (Conv2DTran  (None, 240, 240, 8)  520        ['activation_34[1][0]']          \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 240, 240, 16  0           ['conv2d_transpose_7[1][0]',     \n",
      "                                )                                 'activation_20[1][0]']          \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 240, 240, 16  0           ['concatenate_9[1][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 240, 240, 8)  1160        ['dropout_15[1][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 240, 240, 8)  32         ['conv2d_35[1][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 240, 240, 8)  0           ['batch_normalization_34[1][0]'] \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 240, 240, 8)  584         ['activation_35[1][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 240, 240, 8)  32         ['conv2d_36[1][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 240, 240, 8)  0           ['batch_normalization_35[1][0]'] \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 240, 240, 1)  9           ['activation_36[1][0]']          \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 240, 240, 1)  0           ['conv2d_37[1][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 488,689\n",
      "Trainable params: 487,217\n",
      "Non-trainable params: 1,472\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "/var/folders/m4/9tqx2h0977b4g9l7n72kv3280000gn/T/ipykernel_96782/2219939039.py:19: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model_history = model.fit_generator(train_generator,steps_per_epoch = len(image_train)//batch_size,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 24/881 [..............................] - ETA: 20:11 - loss: 0.9688 - dice_coef: 0.0312 - precision_1: 0.0131 - recall_1: 0.6885"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/xinyi/Documents/GitHub/deep_learning_G5/Lab5/Lab_5_task_2.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xinyi/Documents/GitHub/deep_learning_G5/Lab5/Lab_5_task_2.ipynb#X36sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Compile the model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xinyi/Documents/GitHub/deep_learning_G5/Lab5/Lab_5_task_2.ipynb#X36sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(loss \u001b[39m=\u001b[39m [dice_coef_loss],          \u001b[39m# Model Compiling   \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xinyi/Documents/GitHub/deep_learning_G5/Lab5/Lab_5_task_2.ipynb#X36sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m             optimizer \u001b[39m=\u001b[39m Adam(lr \u001b[39m=\u001b[39m LR),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xinyi/Documents/GitHub/deep_learning_G5/Lab5/Lab_5_task_2.ipynb#X36sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m             metrics \u001b[39m=\u001b[39m [dice_coef, tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mPrecision(), tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mRecall()])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/xinyi/Documents/GitHub/deep_learning_G5/Lab5/Lab_5_task_2.ipynb#X36sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m model_history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit_generator(train_generator,steps_per_epoch \u001b[39m=\u001b[39;49m \u001b[39mlen\u001b[39;49m(image_train)\u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49mbatch_size,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xinyi/Documents/GitHub/deep_learning_G5/Lab5/Lab_5_task_2.ipynb#X36sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     validation_data \u001b[39m=\u001b[39;49m val_generator, validation_steps \u001b[39m=\u001b[39;49m \u001b[39mlen\u001b[39;49m(image_val)\u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49mbatch_size,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xinyi/Documents/GitHub/deep_learning_G5/Lab5/Lab_5_task_2.ipynb#X36sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     epochs \u001b[39m=\u001b[39;49m epochs,  verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xinyi/Documents/GitHub/deep_learning_G5/Lab5/Lab_5_task_2.ipynb#X36sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# evaluate the model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xinyi/Documents/GitHub/deep_learning_G5/Lab5/Lab_5_task_2.ipynb#X36sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m scores \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(image_val, mask_val, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py:2209\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2198\u001b[0m \u001b[39m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[1;32m   2199\u001b[0m \n\u001b[1;32m   2200\u001b[0m \u001b[39mDEPRECATED:\u001b[39;00m\n\u001b[1;32m   2201\u001b[0m \u001b[39m  `Model.fit` now supports generators, so there is no longer any need to use\u001b[39;00m\n\u001b[1;32m   2202\u001b[0m \u001b[39m  this endpoint.\u001b[39;00m\n\u001b[1;32m   2203\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2204\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   2205\u001b[0m     \u001b[39m'\u001b[39m\u001b[39m`Model.fit_generator` is deprecated and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   2206\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mwill be removed in a future version. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   2207\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   2208\u001b[0m     stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m-> 2209\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m   2210\u001b[0m     generator,\n\u001b[1;32m   2211\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m   2212\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m   2213\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   2214\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   2215\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[1;32m   2216\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[1;32m   2217\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[1;32m   2218\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[1;32m   2219\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   2220\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   2221\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   2222\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m   2223\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1385\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2957\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1854\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from matplotlib import image\n",
    "\n",
    "for train, val in kf.split(images, masks, weight_boundary):\n",
    "    image_train, image_val = images[train],images[val]\n",
    "    weight_train, weight_val = weight_boundary[train], weight_boundary[val]\n",
    "    mask_train, mask_val = masks[train], masks[val]\n",
    "    ## Get model\n",
    "    model = get_unet_weightmap(img_w, img_h, img_ch, n_base, LR, \n",
    "                batch_normalization, dropout)\n",
    "\n",
    "    train_generator = generator_with_weights(image_train, mask_train, weight_train, batch_size)\n",
    "    val_generator = generator_with_weights(image_val, mask_val, weight_val, batch_size)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss = [dice_coef_loss],          # Model Compiling   \n",
    "                optimizer = Adam(lr = LR),\n",
    "                metrics = [dice_coef, tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "    model_history = model.fit_generator(train_generator,steps_per_epoch = len(image_train)//batch_size,\n",
    "        validation_data = val_generator, validation_steps = len(image_val)//batch_size,\n",
    "        epochs = epochs,  verbose=1)\n",
    "\n",
    "\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(image_val, mask_val, verbose=1)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "    \n",
    "    print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.9252661392092705, 10.042130947113037, 4.18890155851841, 3.611527383327484]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'dice_coef', 'precision_8', 'recall_8']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
