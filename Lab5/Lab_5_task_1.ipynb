{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /usr/local/lib/python3.8/dist-packages (2.9.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Activation, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, SpatialDropout2D,Conv2DTranspose,Concatenate\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(x, n_base, batch_normalization):\n",
    "    \n",
    "    x = Conv2D(filters=n_base, kernel_size=(3,3), \n",
    "                        strides=(1,1),padding='same')(x)\n",
    "    if (batch_normalization):\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters=n_base, kernel_size=(3,3), \n",
    "                        strides=(1,1),padding='same')(x)\n",
    "    if (batch_normalization):\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_block(x, n_base, batch_normalization, dropout):\n",
    "    f = conv_block(x, n_base, batch_normalization)\n",
    "    p = layers.MaxPool2D(pool_size = (2,2))(f)\n",
    "    if(dropout):\n",
    "        p = layers.Dropout(0.2)(p)\n",
    "        \n",
    "    return f, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_block(x, f, n_base, batch_normalization, dropout):\n",
    "    \n",
    "    x = Conv2DTranspose(filters=n_base, kernel_size=(2,2), \n",
    "                         strides=(2,2),padding='same')(x)\n",
    "    x = Concatenate()([x,f])\n",
    "    if(dropout):\n",
    "        x = layers.Dropout(0.2)(x)\n",
    "    x = conv_block(x, n_base, batch_normalization)\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet(img_w, img_h, img_ch, n_base, LR, batch_normalization, dropout):\n",
    "\n",
    "    \n",
    "    \n",
    "    ## Encoder part\n",
    "#     model = Sequential()\n",
    "    inputs = layers.Input((img_w, img_h, img_ch))\n",
    "    \n",
    "    f1, p1 = downsample_block(inputs, n_base, batch_normalization, dropout)\n",
    "    f2, p2 = downsample_block(p1, n_base*2, batch_normalization, dropout)\n",
    "    f3, p3 = downsample_block(p2, n_base*4, batch_normalization, dropout)\n",
    "    f4, p4 = downsample_block(p3, n_base*8, batch_normalization, dropout)\n",
    "    \n",
    "    \n",
    "    ## Bottleneck\n",
    "    bottleneck = conv_block(p4, n_base*16, batch_normalization)\n",
    "    \n",
    "    ## Decoder part\n",
    "    p5 = upsample_block(bottleneck, f4, n_base*8, batch_normalization, dropout)\n",
    "    p6 = upsample_block(p5, f3, n_base*4, batch_normalization, dropout)\n",
    "    p7 = upsample_block(p6, f2, n_base*2, batch_normalization, dropout)\n",
    "    p8 = upsample_block(p7, f1, n_base, batch_normalization, dropout)\n",
    "\n",
    "    \n",
    "    ## 1 Convo layer\n",
    "    p9 = Conv2D(filters=1, kernel_size=(1,1), \n",
    "                            padding='same')(p8)\n",
    "    outputs = Activation('sigmoid')(p9)\n",
    "    \n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.8/dist-packages (0.19.3)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (2.22.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (2.8.6)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (9.1.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (2022.8.12)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (1.22.3)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (1.9.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->scikit-image) (3.0.9)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task1a) Lung segmentation in chest X-ray images:\n",
    "import os\n",
    "from random import shuffle\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "image_path = '/DL_course_data/Lab3/MRI/Image' \n",
    "mask_path = '/DL_course_data/Lab3/MRI/Mask'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(image_path,mask_path):\n",
    "    \n",
    "    image_list = os.listdir(image_path)\n",
    "    mask_list = os.listdir(mask_path)\n",
    "    \n",
    "    images = []\n",
    "    masks = []\n",
    "\n",
    "    for image in image_list:\n",
    "        img = imread(os.path.join(image_path, image), as_gray=True)  # \"as_grey\"\n",
    "        img = resize(img, (240, 240), anti_aliasing=True).astype('float32')\n",
    "        images.append(img)\n",
    "\n",
    "    for image in image_list:\n",
    "        mask = str.replace(image,'.png','_Tumor.png')\n",
    "        mask_img = imread(os.path.join(mask_path, mask), as_gray=True)\n",
    "        mask_img = resize(mask_img, (240, 240), anti_aliasing=True).astype('float32')\n",
    "        masks.append(mask_img)\n",
    "        \n",
    "    ## Load data in traditional way\n",
    "    # img_train, img_val, mask_train, mask_val = train_test_split(images, masks, shuffle = True,\n",
    "    #                                                   test_size = 0.2)\n",
    "\n",
    "    images = np.expand_dims(images, axis = -1)\n",
    "    images = np.array(images)\n",
    "\n",
    "    masks = np.expand_dims(masks, axis = -1)\n",
    "    masks = np.array(masks)\n",
    "    \n",
    "    return images, masks\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + 0.0001) / (K.sum(y_true_f) + K.sum(y_pred_f) + 0.0001)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_base =8\n",
    "LR = 1e-4\n",
    "batch_normalization = True\n",
    "dropout = True\n",
    "epochs = 100\n",
    "Metric= 'Dice Coefficient'\n",
    "batch_size = 8\n",
    "\n",
    "img_w, img_h = 240,240\n",
    "img_ch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, masks = load_data(image_path,mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=3)\n",
    "cvscores = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(x_train, y_train, batch_size):\n",
    "    n_train_sample = len(x_train)\n",
    "    while True:\n",
    "        for ind in (range(0, n_train_sample, batch_size)):\n",
    "            \n",
    "            batch_img = x_train[ind:ind+batch_size]\n",
    "            batch_label = y_train[ind:ind+batch_size]\n",
    "            \n",
    "            # Sanity check assures batch size always satisfied\n",
    "            # by repeating the last 2-3 images at last batch.\n",
    "            length = len(batch_img)\n",
    "            if length == batch_size:\n",
    "                pass\n",
    "            else:\n",
    "                for tmp in range(batch_size - length):\n",
    "                    batch_img = np.append(batch_img, np.expand_dims(batch_img[-1],axis=0), axis = 0)\n",
    "                    batch_label = np.append(batch_label, np.expand_dims(batch_label[-1], axis=0), axis = 0)\n",
    "        \n",
    "            backgound_value = x_train.min()\n",
    "            data_gen_args = dict(rotation_range=10.,\n",
    "                                     width_shift_range=0.1,\n",
    "                                     height_shift_range=0.1,\n",
    "                                     cval = backgound_value,\n",
    "                                     zoom_range=0.2,\n",
    "                                     horizontal_flip = True)\n",
    "            \n",
    "            image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "            mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "            \n",
    "            image_generator = image_datagen.flow(batch_img, shuffle=False,\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 seed=1)\n",
    "            \n",
    "            mask_generator = mask_datagen.flow(batch_label, shuffle=False,\n",
    "                                               batch_size=batch_size,\n",
    "                                               seed=1)\n",
    "            \n",
    "            image = image_generator.next()\n",
    "            label = mask_generator.next()\n",
    "            \n",
    "            yield image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datagen = ImageDataGenerator()\n",
    "image_generator = image_datagen.flow(images, shuffle=False,\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1176):\n",
    "    image = image_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 240, 240, 1)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_11 (InputLayer)          [(None, 240, 240, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_190 (Conv2D)            (None, 240, 240, 8)  80          ['input_11[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_180 (Batch  (None, 240, 240, 8)  32         ['conv2d_190[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_190 (Activation)    (None, 240, 240, 8)  0           ['batch_normalization_180[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_191 (Conv2D)            (None, 240, 240, 8)  584         ['activation_190[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_181 (Batch  (None, 240, 240, 8)  32         ['conv2d_191[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_191 (Activation)    (None, 240, 240, 8)  0           ['batch_normalization_181[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_40 (MaxPooling2D  (None, 120, 120, 8)  0          ['activation_191[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_80 (Dropout)           (None, 120, 120, 8)  0           ['max_pooling2d_40[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_192 (Conv2D)            (None, 120, 120, 16  1168        ['dropout_80[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_182 (Batch  (None, 120, 120, 16  64         ['conv2d_192[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_192 (Activation)    (None, 120, 120, 16  0           ['batch_normalization_182[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_193 (Conv2D)            (None, 120, 120, 16  2320        ['activation_192[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_183 (Batch  (None, 120, 120, 16  64         ['conv2d_193[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_193 (Activation)    (None, 120, 120, 16  0           ['batch_normalization_183[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_41 (MaxPooling2D  (None, 60, 60, 16)  0           ['activation_193[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_81 (Dropout)           (None, 60, 60, 16)   0           ['max_pooling2d_41[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_194 (Conv2D)            (None, 60, 60, 32)   4640        ['dropout_81[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_184 (Batch  (None, 60, 60, 32)  128         ['conv2d_194[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_194 (Activation)    (None, 60, 60, 32)   0           ['batch_normalization_184[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_195 (Conv2D)            (None, 60, 60, 32)   9248        ['activation_194[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_185 (Batch  (None, 60, 60, 32)  128         ['conv2d_195[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_195 (Activation)    (None, 60, 60, 32)   0           ['batch_normalization_185[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_42 (MaxPooling2D  (None, 30, 30, 32)  0           ['activation_195[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_82 (Dropout)           (None, 30, 30, 32)   0           ['max_pooling2d_42[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_196 (Conv2D)            (None, 30, 30, 64)   18496       ['dropout_82[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_186 (Batch  (None, 30, 30, 64)  256         ['conv2d_196[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_196 (Activation)    (None, 30, 30, 64)   0           ['batch_normalization_186[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_197 (Conv2D)            (None, 30, 30, 64)   36928       ['activation_196[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_187 (Batch  (None, 30, 30, 64)  256         ['conv2d_197[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_197 (Activation)    (None, 30, 30, 64)   0           ['batch_normalization_187[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_43 (MaxPooling2D  (None, 15, 15, 64)  0           ['activation_197[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_83 (Dropout)           (None, 15, 15, 64)   0           ['max_pooling2d_43[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_198 (Conv2D)            (None, 15, 15, 128)  73856       ['dropout_83[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_188 (Batch  (None, 15, 15, 128)  512        ['conv2d_198[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_198 (Activation)    (None, 15, 15, 128)  0           ['batch_normalization_188[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_199 (Conv2D)            (None, 15, 15, 128)  147584      ['activation_198[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_189 (Batch  (None, 15, 15, 128)  512        ['conv2d_199[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_199 (Activation)    (None, 15, 15, 128)  0           ['batch_normalization_189[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_transpose_40 (Conv2DTra  (None, 30, 30, 64)  32832       ['activation_199[0][0]']         \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_40 (Concatenate)   (None, 30, 30, 128)  0           ['conv2d_transpose_40[0][0]',    \n",
      "                                                                  'activation_197[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_84 (Dropout)           (None, 30, 30, 128)  0           ['concatenate_40[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_200 (Conv2D)            (None, 30, 30, 64)   73792       ['dropout_84[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_190 (Batch  (None, 30, 30, 64)  256         ['conv2d_200[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_200 (Activation)    (None, 30, 30, 64)   0           ['batch_normalization_190[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_201 (Conv2D)            (None, 30, 30, 64)   36928       ['activation_200[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_191 (Batch  (None, 30, 30, 64)  256         ['conv2d_201[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_201 (Activation)    (None, 30, 30, 64)   0           ['batch_normalization_191[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_transpose_41 (Conv2DTra  (None, 60, 60, 32)  8224        ['activation_201[0][0]']         \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_41 (Concatenate)   (None, 60, 60, 64)   0           ['conv2d_transpose_41[0][0]',    \n",
      "                                                                  'activation_195[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_85 (Dropout)           (None, 60, 60, 64)   0           ['concatenate_41[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_202 (Conv2D)            (None, 60, 60, 32)   18464       ['dropout_85[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_192 (Batch  (None, 60, 60, 32)  128         ['conv2d_202[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_202 (Activation)    (None, 60, 60, 32)   0           ['batch_normalization_192[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_203 (Conv2D)            (None, 60, 60, 32)   9248        ['activation_202[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_193 (Batch  (None, 60, 60, 32)  128         ['conv2d_203[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_203 (Activation)    (None, 60, 60, 32)   0           ['batch_normalization_193[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_transpose_42 (Conv2DTra  (None, 120, 120, 16  2064       ['activation_203[0][0]']         \n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_42 (Concatenate)   (None, 120, 120, 32  0           ['conv2d_transpose_42[0][0]',    \n",
      "                                )                                 'activation_193[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_86 (Dropout)           (None, 120, 120, 32  0           ['concatenate_42[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_204 (Conv2D)            (None, 120, 120, 16  4624        ['dropout_86[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_194 (Batch  (None, 120, 120, 16  64         ['conv2d_204[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_204 (Activation)    (None, 120, 120, 16  0           ['batch_normalization_194[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_205 (Conv2D)            (None, 120, 120, 16  2320        ['activation_204[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_195 (Batch  (None, 120, 120, 16  64         ['conv2d_205[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_205 (Activation)    (None, 120, 120, 16  0           ['batch_normalization_195[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_43 (Conv2DTra  (None, 240, 240, 8)  520        ['activation_205[0][0]']         \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_43 (Concatenate)   (None, 240, 240, 16  0           ['conv2d_transpose_43[0][0]',    \n",
      "                                )                                 'activation_191[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_87 (Dropout)           (None, 240, 240, 16  0           ['concatenate_43[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_206 (Conv2D)            (None, 240, 240, 8)  1160        ['dropout_87[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_196 (Batch  (None, 240, 240, 8)  32         ['conv2d_206[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_206 (Activation)    (None, 240, 240, 8)  0           ['batch_normalization_196[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_207 (Conv2D)            (None, 240, 240, 8)  584         ['activation_206[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_197 (Batch  (None, 240, 240, 8)  32         ['conv2d_207[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_207 (Activation)    (None, 240, 240, 8)  0           ['batch_normalization_197[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_208 (Conv2D)            (None, 240, 240, 1)  9           ['activation_207[0][0]']         \n",
      "                                                                                                  \n",
      " activation_208 (Activation)    (None, 240, 240, 1)  0           ['conv2d_208[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 488,617\n",
      "Trainable params: 487,145\n",
      "Non-trainable params: 1,472\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-65-0248fc7df464>:19: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model_history = model.fit_generator(train_generator, steps_per_epoch = len(image_train)//batch_size,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "783/783 [==============================] - 142s 179ms/step - loss: 0.9389 - dice_coef: 0.0611 - precision_10: 0.0767 - recall_10: 0.9466 - val_loss: 0.9328 - val_dice_coef: 0.0672 - val_precision_10: 0.2019 - val_recall_10: 0.8159\n",
      "Epoch 2/100\n",
      "783/783 [==============================] - 142s 181ms/step - loss: 0.9102 - dice_coef: 0.0898 - precision_10: 0.1989 - recall_10: 0.9163 - val_loss: 0.9061 - val_dice_coef: 0.0939 - val_precision_10: 0.2439 - val_recall_10: 0.8436\n",
      "Epoch 3/100\n",
      "783/783 [==============================] - 141s 180ms/step - loss: 0.8709 - dice_coef: 0.1291 - precision_10: 0.2757 - recall_10: 0.8927 - val_loss: 0.8573 - val_dice_coef: 0.1427 - val_precision_10: 0.2944 - val_recall_10: 0.8761\n",
      "Epoch 4/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.8022 - dice_coef: 0.1978 - precision_10: 0.3773 - recall_10: 0.8700 - val_loss: 0.7793 - val_dice_coef: 0.2207 - val_precision_10: 0.5348 - val_recall_10: 0.7874\n",
      "Epoch 5/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.6974 - dice_coef: 0.3026 - precision_10: 0.5091 - recall_10: 0.8358 - val_loss: 0.6672 - val_dice_coef: 0.3328 - val_precision_10: 0.6013 - val_recall_10: 0.8191\n",
      "Epoch 6/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.5752 - dice_coef: 0.4248 - precision_10: 0.6391 - recall_10: 0.7981 - val_loss: 0.5469 - val_dice_coef: 0.4531 - val_precision_10: 0.7499 - val_recall_10: 0.7709\n",
      "Epoch 7/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.4648 - dice_coef: 0.5352 - precision_10: 0.7415 - recall_10: 0.7731 - val_loss: 0.4431 - val_dice_coef: 0.5569 - val_precision_10: 0.8267 - val_recall_10: 0.7554\n",
      "Epoch 8/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.3876 - dice_coef: 0.6124 - precision_10: 0.7912 - recall_10: 0.7633 - val_loss: 0.3760 - val_dice_coef: 0.6240 - val_precision_10: 0.8572 - val_recall_10: 0.7538\n",
      "Epoch 9/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.3357 - dice_coef: 0.6643 - precision_10: 0.8273 - recall_10: 0.7574 - val_loss: 0.3449 - val_dice_coef: 0.6551 - val_precision_10: 0.8940 - val_recall_10: 0.7164\n",
      "Epoch 10/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.2993 - dice_coef: 0.7007 - precision_10: 0.8537 - recall_10: 0.7562 - val_loss: 0.3198 - val_dice_coef: 0.6802 - val_precision_10: 0.8922 - val_recall_10: 0.7350\n",
      "Epoch 11/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.2759 - dice_coef: 0.7241 - precision_10: 0.8677 - recall_10: 0.7592 - val_loss: 0.2870 - val_dice_coef: 0.7130 - val_precision_10: 0.8922 - val_recall_10: 0.7557\n",
      "Epoch 12/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.2618 - dice_coef: 0.7382 - precision_10: 0.8727 - recall_10: 0.7611 - val_loss: 0.2790 - val_dice_coef: 0.7210 - val_precision_10: 0.9046 - val_recall_10: 0.7481\n",
      "Epoch 13/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.2494 - dice_coef: 0.7506 - precision_10: 0.8848 - recall_10: 0.7622 - val_loss: 0.2676 - val_dice_coef: 0.7324 - val_precision_10: 0.9149 - val_recall_10: 0.7460\n",
      "Epoch 14/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.2416 - dice_coef: 0.7584 - precision_10: 0.8834 - recall_10: 0.7655 - val_loss: 0.2630 - val_dice_coef: 0.7370 - val_precision_10: 0.9151 - val_recall_10: 0.7457\n",
      "Epoch 15/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.2285 - dice_coef: 0.7715 - precision_10: 0.8961 - recall_10: 0.7708 - val_loss: 0.2655 - val_dice_coef: 0.7345 - val_precision_10: 0.8921 - val_recall_10: 0.7411\n",
      "Epoch 16/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.2275 - dice_coef: 0.7725 - precision_10: 0.8977 - recall_10: 0.7694 - val_loss: 0.2586 - val_dice_coef: 0.7414 - val_precision_10: 0.8670 - val_recall_10: 0.7920\n",
      "Epoch 17/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.2191 - dice_coef: 0.7809 - precision_10: 0.9027 - recall_10: 0.7778 - val_loss: 0.2469 - val_dice_coef: 0.7531 - val_precision_10: 0.9081 - val_recall_10: 0.7558\n",
      "Epoch 18/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.2164 - dice_coef: 0.7836 - precision_10: 0.9062 - recall_10: 0.7769 - val_loss: 0.2432 - val_dice_coef: 0.7568 - val_precision_10: 0.9191 - val_recall_10: 0.7529\n",
      "Epoch 19/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.2106 - dice_coef: 0.7894 - precision_10: 0.9085 - recall_10: 0.7816 - val_loss: 0.2417 - val_dice_coef: 0.7583 - val_precision_10: 0.9160 - val_recall_10: 0.7657\n",
      "Epoch 20/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.2078 - dice_coef: 0.7922 - precision_10: 0.9068 - recall_10: 0.7840 - val_loss: 0.2423 - val_dice_coef: 0.7577 - val_precision_10: 0.9192 - val_recall_10: 0.7540\n",
      "Epoch 21/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.2048 - dice_coef: 0.7952 - precision_10: 0.9124 - recall_10: 0.7816 - val_loss: 0.2472 - val_dice_coef: 0.7528 - val_precision_10: 0.9215 - val_recall_10: 0.7496\n",
      "Epoch 22/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.2031 - dice_coef: 0.7969 - precision_10: 0.9105 - recall_10: 0.7892 - val_loss: 0.2597 - val_dice_coef: 0.7403 - val_precision_10: 0.9395 - val_recall_10: 0.7264\n",
      "Epoch 23/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1958 - dice_coef: 0.8042 - precision_10: 0.9160 - recall_10: 0.7951 - val_loss: 0.2425 - val_dice_coef: 0.7575 - val_precision_10: 0.9361 - val_recall_10: 0.7416\n",
      "Epoch 24/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1975 - dice_coef: 0.8025 - precision_10: 0.9124 - recall_10: 0.7959 - val_loss: 0.2696 - val_dice_coef: 0.7304 - val_precision_10: 0.9451 - val_recall_10: 0.7183\n",
      "Epoch 25/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1933 - dice_coef: 0.8067 - precision_10: 0.9162 - recall_10: 0.7948 - val_loss: 0.2421 - val_dice_coef: 0.7579 - val_precision_10: 0.8905 - val_recall_10: 0.7827\n",
      "Epoch 26/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1888 - dice_coef: 0.8112 - precision_10: 0.9182 - recall_10: 0.8004 - val_loss: 0.2393 - val_dice_coef: 0.7607 - val_precision_10: 0.9187 - val_recall_10: 0.7564\n",
      "Epoch 27/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1856 - dice_coef: 0.8144 - precision_10: 0.9188 - recall_10: 0.8005 - val_loss: 0.2301 - val_dice_coef: 0.7699 - val_precision_10: 0.9045 - val_recall_10: 0.7904\n",
      "Epoch 28/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1868 - dice_coef: 0.8132 - precision_10: 0.9175 - recall_10: 0.8006 - val_loss: 0.2397 - val_dice_coef: 0.7603 - val_precision_10: 0.9244 - val_recall_10: 0.7519\n",
      "Epoch 29/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1802 - dice_coef: 0.8198 - precision_10: 0.9238 - recall_10: 0.8060 - val_loss: 0.2298 - val_dice_coef: 0.7702 - val_precision_10: 0.9374 - val_recall_10: 0.7545\n",
      "Epoch 30/100\n",
      "783/783 [==============================] - 140s 178ms/step - loss: 0.1821 - dice_coef: 0.8179 - precision_10: 0.9224 - recall_10: 0.8049 - val_loss: 0.2242 - val_dice_coef: 0.7758 - val_precision_10: 0.9301 - val_recall_10: 0.7663\n",
      "Epoch 31/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1791 - dice_coef: 0.8209 - precision_10: 0.9244 - recall_10: 0.8075 - val_loss: 0.2285 - val_dice_coef: 0.7715 - val_precision_10: 0.9100 - val_recall_10: 0.7813\n",
      "Epoch 32/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1759 - dice_coef: 0.8241 - precision_10: 0.9253 - recall_10: 0.8112 - val_loss: 0.2217 - val_dice_coef: 0.7783 - val_precision_10: 0.9101 - val_recall_10: 0.7816\n",
      "Epoch 33/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1749 - dice_coef: 0.8251 - precision_10: 0.9229 - recall_10: 0.8117 - val_loss: 0.2344 - val_dice_coef: 0.7656 - val_precision_10: 0.9339 - val_recall_10: 0.7528\n",
      "Epoch 34/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1720 - dice_coef: 0.8280 - precision_10: 0.9262 - recall_10: 0.8138 - val_loss: 0.2614 - val_dice_coef: 0.7386 - val_precision_10: 0.9458 - val_recall_10: 0.7135\n",
      "Epoch 35/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1728 - dice_coef: 0.8272 - precision_10: 0.9267 - recall_10: 0.8113 - val_loss: 0.2307 - val_dice_coef: 0.7693 - val_precision_10: 0.9344 - val_recall_10: 0.7569\n",
      "Epoch 36/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1686 - dice_coef: 0.8314 - precision_10: 0.9285 - recall_10: 0.8162 - val_loss: 0.2269 - val_dice_coef: 0.7731 - val_precision_10: 0.9266 - val_recall_10: 0.7761\n",
      "Epoch 37/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1686 - dice_coef: 0.8314 - precision_10: 0.9263 - recall_10: 0.8175 - val_loss: 0.2217 - val_dice_coef: 0.7783 - val_precision_10: 0.9442 - val_recall_10: 0.7609\n",
      "Epoch 38/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1657 - dice_coef: 0.8343 - precision_10: 0.9310 - recall_10: 0.8178 - val_loss: 0.2292 - val_dice_coef: 0.7708 - val_precision_10: 0.8877 - val_recall_10: 0.7903\n",
      "Epoch 39/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1665 - dice_coef: 0.8335 - precision_10: 0.9299 - recall_10: 0.8173 - val_loss: 0.2179 - val_dice_coef: 0.7821 - val_precision_10: 0.9343 - val_recall_10: 0.7701\n",
      "Epoch 40/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1641 - dice_coef: 0.8359 - precision_10: 0.9302 - recall_10: 0.8207 - val_loss: 0.2304 - val_dice_coef: 0.7696 - val_precision_10: 0.9109 - val_recall_10: 0.7844\n",
      "Epoch 41/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1627 - dice_coef: 0.8373 - precision_10: 0.9313 - recall_10: 0.8224 - val_loss: 0.2263 - val_dice_coef: 0.7737 - val_precision_10: 0.9378 - val_recall_10: 0.7609\n",
      "Epoch 42/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1615 - dice_coef: 0.8385 - precision_10: 0.9325 - recall_10: 0.8235 - val_loss: 0.2133 - val_dice_coef: 0.7867 - val_precision_10: 0.9208 - val_recall_10: 0.7904\n",
      "Epoch 43/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1599 - dice_coef: 0.8401 - precision_10: 0.9350 - recall_10: 0.8225 - val_loss: 0.2250 - val_dice_coef: 0.7750 - val_precision_10: 0.9187 - val_recall_10: 0.7795\n",
      "Epoch 44/100\n",
      "783/783 [==============================] - 146s 187ms/step - loss: 0.1586 - dice_coef: 0.8414 - precision_10: 0.9330 - recall_10: 0.8253 - val_loss: 0.2328 - val_dice_coef: 0.7672 - val_precision_10: 0.9276 - val_recall_10: 0.7607\n",
      "Epoch 45/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1589 - dice_coef: 0.8411 - precision_10: 0.9341 - recall_10: 0.8249 - val_loss: 0.2277 - val_dice_coef: 0.7723 - val_precision_10: 0.9286 - val_recall_10: 0.7637\n",
      "Epoch 46/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1569 - dice_coef: 0.8431 - precision_10: 0.9357 - recall_10: 0.8246 - val_loss: 0.2312 - val_dice_coef: 0.7688 - val_precision_10: 0.8983 - val_recall_10: 0.7818\n",
      "Epoch 47/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1569 - dice_coef: 0.8431 - precision_10: 0.9356 - recall_10: 0.8247 - val_loss: 0.2194 - val_dice_coef: 0.7806 - val_precision_10: 0.9177 - val_recall_10: 0.7880\n",
      "Epoch 48/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1556 - dice_coef: 0.8444 - precision_10: 0.9334 - recall_10: 0.8274 - val_loss: 0.2150 - val_dice_coef: 0.7850 - val_precision_10: 0.9039 - val_recall_10: 0.8009\n",
      "Epoch 49/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1531 - dice_coef: 0.8469 - precision_10: 0.9360 - recall_10: 0.8311 - val_loss: 0.2082 - val_dice_coef: 0.7918 - val_precision_10: 0.9196 - val_recall_10: 0.7959\n",
      "Epoch 50/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1501 - dice_coef: 0.8499 - precision_10: 0.9385 - recall_10: 0.8291 - val_loss: 0.2326 - val_dice_coef: 0.7674 - val_precision_10: 0.8703 - val_recall_10: 0.8068\n",
      "Epoch 51/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1528 - dice_coef: 0.8472 - precision_10: 0.9374 - recall_10: 0.8276 - val_loss: 0.2089 - val_dice_coef: 0.7911 - val_precision_10: 0.9105 - val_recall_10: 0.8078\n",
      "Epoch 52/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1503 - dice_coef: 0.8497 - precision_10: 0.9388 - recall_10: 0.8304 - val_loss: 0.2142 - val_dice_coef: 0.7858 - val_precision_10: 0.9191 - val_recall_10: 0.7872\n",
      "Epoch 53/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1509 - dice_coef: 0.8491 - precision_10: 0.9385 - recall_10: 0.8290 - val_loss: 0.2182 - val_dice_coef: 0.7818 - val_precision_10: 0.9068 - val_recall_10: 0.7949\n",
      "Epoch 54/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1515 - dice_coef: 0.8485 - precision_10: 0.9359 - recall_10: 0.8302 - val_loss: 0.2220 - val_dice_coef: 0.7780 - val_precision_10: 0.8905 - val_recall_10: 0.8039\n",
      "Epoch 55/100\n",
      "783/783 [==============================] - 146s 187ms/step - loss: 0.1469 - dice_coef: 0.8531 - precision_10: 0.9417 - recall_10: 0.8314 - val_loss: 0.2253 - val_dice_coef: 0.7747 - val_precision_10: 0.9037 - val_recall_10: 0.7857\n",
      "Epoch 56/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1467 - dice_coef: 0.8533 - precision_10: 0.9393 - recall_10: 0.8319 - val_loss: 0.2037 - val_dice_coef: 0.7963 - val_precision_10: 0.9207 - val_recall_10: 0.8086\n",
      "Epoch 57/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1451 - dice_coef: 0.8549 - precision_10: 0.9413 - recall_10: 0.8339 - val_loss: 0.2120 - val_dice_coef: 0.7880 - val_precision_10: 0.9190 - val_recall_10: 0.7951\n",
      "Epoch 58/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1455 - dice_coef: 0.8545 - precision_10: 0.9420 - recall_10: 0.8336 - val_loss: 0.2142 - val_dice_coef: 0.7858 - val_precision_10: 0.9323 - val_recall_10: 0.7830\n",
      "Epoch 59/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1468 - dice_coef: 0.8532 - precision_10: 0.9423 - recall_10: 0.8339 - val_loss: 0.2114 - val_dice_coef: 0.7886 - val_precision_10: 0.9351 - val_recall_10: 0.7786\n",
      "Epoch 60/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1462 - dice_coef: 0.8538 - precision_10: 0.9415 - recall_10: 0.8352 - val_loss: 0.2172 - val_dice_coef: 0.7828 - val_precision_10: 0.8867 - val_recall_10: 0.8166\n",
      "Epoch 61/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1446 - dice_coef: 0.8554 - precision_10: 0.9433 - recall_10: 0.8325 - val_loss: 0.2059 - val_dice_coef: 0.7941 - val_precision_10: 0.9152 - val_recall_10: 0.8077\n",
      "Epoch 62/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1437 - dice_coef: 0.8563 - precision_10: 0.9428 - recall_10: 0.8367 - val_loss: 0.2128 - val_dice_coef: 0.7872 - val_precision_10: 0.9048 - val_recall_10: 0.8014\n",
      "Epoch 63/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1424 - dice_coef: 0.8576 - precision_10: 0.9457 - recall_10: 0.8358 - val_loss: 0.1993 - val_dice_coef: 0.8007 - val_precision_10: 0.9191 - val_recall_10: 0.8098\n",
      "Epoch 64/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1413 - dice_coef: 0.8587 - precision_10: 0.9459 - recall_10: 0.8374 - val_loss: 0.2036 - val_dice_coef: 0.7964 - val_precision_10: 0.8989 - val_recall_10: 0.8240\n",
      "Epoch 65/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1403 - dice_coef: 0.8597 - precision_10: 0.9424 - recall_10: 0.8367 - val_loss: 0.2074 - val_dice_coef: 0.7926 - val_precision_10: 0.9073 - val_recall_10: 0.8138\n",
      "Epoch 66/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1394 - dice_coef: 0.8606 - precision_10: 0.9432 - recall_10: 0.8362 - val_loss: 0.2071 - val_dice_coef: 0.7929 - val_precision_10: 0.9398 - val_recall_10: 0.7790\n",
      "Epoch 67/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1401 - dice_coef: 0.8599 - precision_10: 0.9435 - recall_10: 0.8363 - val_loss: 0.2124 - val_dice_coef: 0.7876 - val_precision_10: 0.9241 - val_recall_10: 0.7784\n",
      "Epoch 68/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1366 - dice_coef: 0.8634 - precision_10: 0.9460 - recall_10: 0.8393 - val_loss: 0.2033 - val_dice_coef: 0.7967 - val_precision_10: 0.9183 - val_recall_10: 0.8005\n",
      "Epoch 69/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1388 - dice_coef: 0.8612 - precision_10: 0.9451 - recall_10: 0.8370 - val_loss: 0.2048 - val_dice_coef: 0.7952 - val_precision_10: 0.9344 - val_recall_10: 0.7892\n",
      "Epoch 70/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1382 - dice_coef: 0.8618 - precision_10: 0.9463 - recall_10: 0.8384 - val_loss: 0.2002 - val_dice_coef: 0.7998 - val_precision_10: 0.9314 - val_recall_10: 0.7950\n",
      "Epoch 71/100\n",
      "783/783 [==============================] - 146s 186ms/step - loss: 0.1375 - dice_coef: 0.8625 - precision_10: 0.9472 - recall_10: 0.8396 - val_loss: 0.2049 - val_dice_coef: 0.7951 - val_precision_10: 0.9377 - val_recall_10: 0.7808\n",
      "Epoch 72/100\n",
      "783/783 [==============================] - 140s 178ms/step - loss: 0.1369 - dice_coef: 0.8631 - precision_10: 0.9475 - recall_10: 0.8404 - val_loss: 0.1961 - val_dice_coef: 0.8039 - val_precision_10: 0.9253 - val_recall_10: 0.8066\n",
      "Epoch 73/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1345 - dice_coef: 0.8655 - precision_10: 0.9492 - recall_10: 0.8419 - val_loss: 0.2000 - val_dice_coef: 0.8000 - val_precision_10: 0.9276 - val_recall_10: 0.7982\n",
      "Epoch 74/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1383 - dice_coef: 0.8617 - precision_10: 0.9466 - recall_10: 0.8391 - val_loss: 0.2063 - val_dice_coef: 0.7937 - val_precision_10: 0.9397 - val_recall_10: 0.7792\n",
      "Epoch 75/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1355 - dice_coef: 0.8645 - precision_10: 0.9483 - recall_10: 0.8414 - val_loss: 0.2117 - val_dice_coef: 0.7883 - val_precision_10: 0.9060 - val_recall_10: 0.8058\n",
      "Epoch 76/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1324 - dice_coef: 0.8676 - precision_10: 0.9492 - recall_10: 0.8436 - val_loss: 0.2103 - val_dice_coef: 0.7897 - val_precision_10: 0.9242 - val_recall_10: 0.7963\n",
      "Epoch 77/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1336 - dice_coef: 0.8664 - precision_10: 0.9500 - recall_10: 0.8425 - val_loss: 0.2072 - val_dice_coef: 0.7928 - val_precision_10: 0.9047 - val_recall_10: 0.8134\n",
      "Epoch 78/100\n",
      "783/783 [==============================] - 140s 178ms/step - loss: 0.1330 - dice_coef: 0.8670 - precision_10: 0.9502 - recall_10: 0.8416 - val_loss: 0.1984 - val_dice_coef: 0.8016 - val_precision_10: 0.9357 - val_recall_10: 0.7883\n",
      "Epoch 79/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1330 - dice_coef: 0.8670 - precision_10: 0.9499 - recall_10: 0.8430 - val_loss: 0.1990 - val_dice_coef: 0.8010 - val_precision_10: 0.9363 - val_recall_10: 0.7924\n",
      "Epoch 80/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1298 - dice_coef: 0.8702 - precision_10: 0.9510 - recall_10: 0.8451 - val_loss: 0.2022 - val_dice_coef: 0.7978 - val_precision_10: 0.9178 - val_recall_10: 0.8082\n",
      "Epoch 81/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1322 - dice_coef: 0.8678 - precision_10: 0.9488 - recall_10: 0.8428 - val_loss: 0.2009 - val_dice_coef: 0.7991 - val_precision_10: 0.9411 - val_recall_10: 0.7787\n",
      "Epoch 82/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1317 - dice_coef: 0.8683 - precision_10: 0.9504 - recall_10: 0.8443 - val_loss: 0.2020 - val_dice_coef: 0.7980 - val_precision_10: 0.9219 - val_recall_10: 0.8016\n",
      "Epoch 83/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1310 - dice_coef: 0.8690 - precision_10: 0.9514 - recall_10: 0.8439 - val_loss: 0.2006 - val_dice_coef: 0.7994 - val_precision_10: 0.9189 - val_recall_10: 0.8094\n",
      "Epoch 84/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1295 - dice_coef: 0.8705 - precision_10: 0.9521 - recall_10: 0.8453 - val_loss: 0.2004 - val_dice_coef: 0.7996 - val_precision_10: 0.9428 - val_recall_10: 0.7849\n",
      "Epoch 85/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1283 - dice_coef: 0.8717 - precision_10: 0.9521 - recall_10: 0.8482 - val_loss: 0.1994 - val_dice_coef: 0.8006 - val_precision_10: 0.9316 - val_recall_10: 0.7959\n",
      "Epoch 86/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1304 - dice_coef: 0.8696 - precision_10: 0.9503 - recall_10: 0.8449 - val_loss: 0.1977 - val_dice_coef: 0.8023 - val_precision_10: 0.9314 - val_recall_10: 0.7932\n",
      "Epoch 87/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1306 - dice_coef: 0.8694 - precision_10: 0.9493 - recall_10: 0.8444 - val_loss: 0.2229 - val_dice_coef: 0.7771 - val_precision_10: 0.9366 - val_recall_10: 0.7622\n",
      "Epoch 88/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1287 - dice_coef: 0.8713 - precision_10: 0.9515 - recall_10: 0.8447 - val_loss: 0.2044 - val_dice_coef: 0.7956 - val_precision_10: 0.9424 - val_recall_10: 0.7812\n",
      "Epoch 89/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1259 - dice_coef: 0.8741 - precision_10: 0.9541 - recall_10: 0.8487 - val_loss: 0.2000 - val_dice_coef: 0.8000 - val_precision_10: 0.9298 - val_recall_10: 0.8026\n",
      "Epoch 90/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1262 - dice_coef: 0.8738 - precision_10: 0.9529 - recall_10: 0.8477 - val_loss: 0.1985 - val_dice_coef: 0.8015 - val_precision_10: 0.9361 - val_recall_10: 0.7949\n",
      "Epoch 91/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1246 - dice_coef: 0.8754 - precision_10: 0.9537 - recall_10: 0.8484 - val_loss: 0.1991 - val_dice_coef: 0.8009 - val_precision_10: 0.9497 - val_recall_10: 0.7754\n",
      "Epoch 92/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1259 - dice_coef: 0.8741 - precision_10: 0.9529 - recall_10: 0.8485 - val_loss: 0.1962 - val_dice_coef: 0.8038 - val_precision_10: 0.9304 - val_recall_10: 0.8021\n",
      "Epoch 93/100\n",
      "783/783 [==============================] - 140s 178ms/step - loss: 0.1246 - dice_coef: 0.8754 - precision_10: 0.9537 - recall_10: 0.8478 - val_loss: 0.1980 - val_dice_coef: 0.8020 - val_precision_10: 0.9414 - val_recall_10: 0.7776\n",
      "Epoch 94/100\n",
      "783/783 [==============================] - 146s 187ms/step - loss: 0.1246 - dice_coef: 0.8754 - precision_10: 0.9553 - recall_10: 0.8499 - val_loss: 0.2012 - val_dice_coef: 0.7988 - val_precision_10: 0.9255 - val_recall_10: 0.8000\n",
      "Epoch 95/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1238 - dice_coef: 0.8762 - precision_10: 0.9553 - recall_10: 0.8485 - val_loss: 0.2008 - val_dice_coef: 0.7992 - val_precision_10: 0.9420 - val_recall_10: 0.7820\n",
      "Epoch 96/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1244 - dice_coef: 0.8756 - precision_10: 0.9550 - recall_10: 0.8505 - val_loss: 0.1980 - val_dice_coef: 0.8020 - val_precision_10: 0.9375 - val_recall_10: 0.7881\n",
      "Epoch 97/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1262 - dice_coef: 0.8738 - precision_10: 0.9532 - recall_10: 0.8488 - val_loss: 0.2005 - val_dice_coef: 0.7995 - val_precision_10: 0.9378 - val_recall_10: 0.7916\n",
      "Epoch 98/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1254 - dice_coef: 0.8746 - precision_10: 0.9527 - recall_10: 0.8464 - val_loss: 0.1957 - val_dice_coef: 0.8043 - val_precision_10: 0.9426 - val_recall_10: 0.7904\n",
      "Epoch 99/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1216 - dice_coef: 0.8784 - precision_10: 0.9568 - recall_10: 0.8528 - val_loss: 0.1930 - val_dice_coef: 0.8070 - val_precision_10: 0.9416 - val_recall_10: 0.7936\n",
      "Epoch 100/100\n",
      "783/783 [==============================] - 140s 179ms/step - loss: 0.1213 - dice_coef: 0.8787 - precision_10: 0.9567 - recall_10: 0.8530 - val_loss: 0.2060 - val_dice_coef: 0.7940 - val_precision_10: 0.9128 - val_recall_10: 0.8019\n",
      "98/98 [==============================] - 4s 44ms/step - loss: 0.1680 - dice_coef: 0.8320 - precision_10: 0.8795 - recall_10: 0.8381\n",
      "dice_coef: 83.20%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.91% (+/- 35.58%)\n",
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_12 (InputLayer)          [(None, 240, 240, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_209 (Conv2D)            (None, 240, 240, 8)  80          ['input_12[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_198 (Batch  (None, 240, 240, 8)  32         ['conv2d_209[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_209 (Activation)    (None, 240, 240, 8)  0           ['batch_normalization_198[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_210 (Conv2D)            (None, 240, 240, 8)  584         ['activation_209[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_199 (Batch  (None, 240, 240, 8)  32         ['conv2d_210[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_210 (Activation)    (None, 240, 240, 8)  0           ['batch_normalization_199[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_44 (MaxPooling2D  (None, 120, 120, 8)  0          ['activation_210[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_88 (Dropout)           (None, 120, 120, 8)  0           ['max_pooling2d_44[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_211 (Conv2D)            (None, 120, 120, 16  1168        ['dropout_88[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_200 (Batch  (None, 120, 120, 16  64         ['conv2d_211[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_211 (Activation)    (None, 120, 120, 16  0           ['batch_normalization_200[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_212 (Conv2D)            (None, 120, 120, 16  2320        ['activation_211[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_201 (Batch  (None, 120, 120, 16  64         ['conv2d_212[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_212 (Activation)    (None, 120, 120, 16  0           ['batch_normalization_201[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_45 (MaxPooling2D  (None, 60, 60, 16)  0           ['activation_212[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_89 (Dropout)           (None, 60, 60, 16)   0           ['max_pooling2d_45[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_213 (Conv2D)            (None, 60, 60, 32)   4640        ['dropout_89[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_202 (Batch  (None, 60, 60, 32)  128         ['conv2d_213[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_213 (Activation)    (None, 60, 60, 32)   0           ['batch_normalization_202[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_214 (Conv2D)            (None, 60, 60, 32)   9248        ['activation_213[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_203 (Batch  (None, 60, 60, 32)  128         ['conv2d_214[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_214 (Activation)    (None, 60, 60, 32)   0           ['batch_normalization_203[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_46 (MaxPooling2D  (None, 30, 30, 32)  0           ['activation_214[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_90 (Dropout)           (None, 30, 30, 32)   0           ['max_pooling2d_46[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_215 (Conv2D)            (None, 30, 30, 64)   18496       ['dropout_90[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_204 (Batch  (None, 30, 30, 64)  256         ['conv2d_215[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_215 (Activation)    (None, 30, 30, 64)   0           ['batch_normalization_204[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_216 (Conv2D)            (None, 30, 30, 64)   36928       ['activation_215[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_205 (Batch  (None, 30, 30, 64)  256         ['conv2d_216[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_216 (Activation)    (None, 30, 30, 64)   0           ['batch_normalization_205[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_47 (MaxPooling2D  (None, 15, 15, 64)  0           ['activation_216[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_91 (Dropout)           (None, 15, 15, 64)   0           ['max_pooling2d_47[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_217 (Conv2D)            (None, 15, 15, 128)  73856       ['dropout_91[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_206 (Batch  (None, 15, 15, 128)  512        ['conv2d_217[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_217 (Activation)    (None, 15, 15, 128)  0           ['batch_normalization_206[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_218 (Conv2D)            (None, 15, 15, 128)  147584      ['activation_217[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_207 (Batch  (None, 15, 15, 128)  512        ['conv2d_218[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_218 (Activation)    (None, 15, 15, 128)  0           ['batch_normalization_207[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_transpose_44 (Conv2DTra  (None, 30, 30, 64)  32832       ['activation_218[0][0]']         \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_44 (Concatenate)   (None, 30, 30, 128)  0           ['conv2d_transpose_44[0][0]',    \n",
      "                                                                  'activation_216[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_92 (Dropout)           (None, 30, 30, 128)  0           ['concatenate_44[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_219 (Conv2D)            (None, 30, 30, 64)   73792       ['dropout_92[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_208 (Batch  (None, 30, 30, 64)  256         ['conv2d_219[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_219 (Activation)    (None, 30, 30, 64)   0           ['batch_normalization_208[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_220 (Conv2D)            (None, 30, 30, 64)   36928       ['activation_219[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_209 (Batch  (None, 30, 30, 64)  256         ['conv2d_220[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_220 (Activation)    (None, 30, 30, 64)   0           ['batch_normalization_209[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_transpose_45 (Conv2DTra  (None, 60, 60, 32)  8224        ['activation_220[0][0]']         \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_45 (Concatenate)   (None, 60, 60, 64)   0           ['conv2d_transpose_45[0][0]',    \n",
      "                                                                  'activation_214[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_93 (Dropout)           (None, 60, 60, 64)   0           ['concatenate_45[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_221 (Conv2D)            (None, 60, 60, 32)   18464       ['dropout_93[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_210 (Batch  (None, 60, 60, 32)  128         ['conv2d_221[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_221 (Activation)    (None, 60, 60, 32)   0           ['batch_normalization_210[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_222 (Conv2D)            (None, 60, 60, 32)   9248        ['activation_221[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_211 (Batch  (None, 60, 60, 32)  128         ['conv2d_222[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_222 (Activation)    (None, 60, 60, 32)   0           ['batch_normalization_211[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_transpose_46 (Conv2DTra  (None, 120, 120, 16  2064       ['activation_222[0][0]']         \n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_46 (Concatenate)   (None, 120, 120, 32  0           ['conv2d_transpose_46[0][0]',    \n",
      "                                )                                 'activation_212[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_94 (Dropout)           (None, 120, 120, 32  0           ['concatenate_46[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_223 (Conv2D)            (None, 120, 120, 16  4624        ['dropout_94[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_212 (Batch  (None, 120, 120, 16  64         ['conv2d_223[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_223 (Activation)    (None, 120, 120, 16  0           ['batch_normalization_212[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_224 (Conv2D)            (None, 120, 120, 16  2320        ['activation_223[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_213 (Batch  (None, 120, 120, 16  64         ['conv2d_224[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_224 (Activation)    (None, 120, 120, 16  0           ['batch_normalization_213[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_47 (Conv2DTra  (None, 240, 240, 8)  520        ['activation_224[0][0]']         \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_47 (Concatenate)   (None, 240, 240, 16  0           ['conv2d_transpose_47[0][0]',    \n",
      "                                )                                 'activation_210[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_95 (Dropout)           (None, 240, 240, 16  0           ['concatenate_47[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_225 (Conv2D)            (None, 240, 240, 8)  1160        ['dropout_95[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_214 (Batch  (None, 240, 240, 8)  32         ['conv2d_225[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_225 (Activation)    (None, 240, 240, 8)  0           ['batch_normalization_214[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_226 (Conv2D)            (None, 240, 240, 8)  584         ['activation_225[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_215 (Batch  (None, 240, 240, 8)  32         ['conv2d_226[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_226 (Activation)    (None, 240, 240, 8)  0           ['batch_normalization_215[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_227 (Conv2D)            (None, 240, 240, 1)  9           ['activation_226[0][0]']         \n",
      "                                                                                                  \n",
      " activation_227 (Activation)    (None, 240, 240, 1)  0           ['conv2d_227[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 488,617\n",
      "Trainable params: 487,145\n",
      "Non-trainable params: 1,472\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "783/783 [==============================] - 155s 195ms/step - loss: 0.9179 - dice_coef: 0.0821 - precision_11: 0.0878 - recall_11: 0.9171 - val_loss: 0.9348 - val_dice_coef: 0.0652 - val_precision_11: 0.6283 - val_recall_11: 0.3216\n",
      "Epoch 2/100\n",
      "783/783 [==============================] - 152s 195ms/step - loss: 0.8558 - dice_coef: 0.1442 - precision_11: 0.2836 - recall_11: 0.8794 - val_loss: 0.8381 - val_dice_coef: 0.1619 - val_precision_11: 0.5076 - val_recall_11: 0.6906\n",
      "Epoch 3/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.7763 - dice_coef: 0.2237 - precision_11: 0.4068 - recall_11: 0.8505 - val_loss: 0.7607 - val_dice_coef: 0.2393 - val_precision_11: 0.6908 - val_recall_11: 0.6437\n",
      "Epoch 4/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.6644 - dice_coef: 0.3356 - precision_11: 0.5485 - recall_11: 0.8216 - val_loss: 0.6481 - val_dice_coef: 0.3519 - val_precision_11: 0.7892 - val_recall_11: 0.6573\n",
      "Epoch 5/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.5438 - dice_coef: 0.4562 - precision_11: 0.6709 - recall_11: 0.7954 - val_loss: 0.5454 - val_dice_coef: 0.4546 - val_precision_11: 0.8471 - val_recall_11: 0.6461\n",
      "Epoch 6/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.4494 - dice_coef: 0.5506 - precision_11: 0.7361 - recall_11: 0.7777 - val_loss: 0.4593 - val_dice_coef: 0.5407 - val_precision_11: 0.8672 - val_recall_11: 0.6584\n",
      "Epoch 7/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.3797 - dice_coef: 0.6203 - precision_11: 0.7903 - recall_11: 0.7671 - val_loss: 0.3879 - val_dice_coef: 0.6121 - val_precision_11: 0.8583 - val_recall_11: 0.6951\n",
      "Epoch 8/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.3348 - dice_coef: 0.6652 - precision_11: 0.8221 - recall_11: 0.7614 - val_loss: 0.3467 - val_dice_coef: 0.6533 - val_precision_11: 0.8606 - val_recall_11: 0.7160\n",
      "Epoch 9/100\n",
      "783/783 [==============================] - 152s 195ms/step - loss: 0.3038 - dice_coef: 0.6962 - precision_11: 0.8411 - recall_11: 0.7659 - val_loss: 0.3200 - val_dice_coef: 0.6800 - val_precision_11: 0.8648 - val_recall_11: 0.7113\n",
      "Epoch 10/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.2840 - dice_coef: 0.7160 - precision_11: 0.8555 - recall_11: 0.7647 - val_loss: 0.3117 - val_dice_coef: 0.6883 - val_precision_11: 0.8716 - val_recall_11: 0.7052\n",
      "Epoch 11/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.2690 - dice_coef: 0.7310 - precision_11: 0.8619 - recall_11: 0.7697 - val_loss: 0.2842 - val_dice_coef: 0.7158 - val_precision_11: 0.8635 - val_recall_11: 0.7509\n",
      "Epoch 12/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.2538 - dice_coef: 0.7462 - precision_11: 0.8769 - recall_11: 0.7680 - val_loss: 0.2968 - val_dice_coef: 0.7032 - val_precision_11: 0.9061 - val_recall_11: 0.6878\n",
      "Epoch 13/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.2458 - dice_coef: 0.7542 - precision_11: 0.8823 - recall_11: 0.7729 - val_loss: 0.2846 - val_dice_coef: 0.7154 - val_precision_11: 0.9064 - val_recall_11: 0.7047\n",
      "Epoch 14/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.2381 - dice_coef: 0.7619 - precision_11: 0.8917 - recall_11: 0.7748 - val_loss: 0.2749 - val_dice_coef: 0.7251 - val_precision_11: 0.8469 - val_recall_11: 0.7559\n",
      "Epoch 15/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.2293 - dice_coef: 0.7707 - precision_11: 0.8933 - recall_11: 0.7781 - val_loss: 0.2652 - val_dice_coef: 0.7348 - val_precision_11: 0.8809 - val_recall_11: 0.7489\n",
      "Epoch 16/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.2260 - dice_coef: 0.7740 - precision_11: 0.8990 - recall_11: 0.7788 - val_loss: 0.2586 - val_dice_coef: 0.7414 - val_precision_11: 0.8865 - val_recall_11: 0.7434\n",
      "Epoch 17/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.2198 - dice_coef: 0.7802 - precision_11: 0.9040 - recall_11: 0.7796 - val_loss: 0.2609 - val_dice_coef: 0.7391 - val_precision_11: 0.8697 - val_recall_11: 0.7599\n",
      "Epoch 18/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.2156 - dice_coef: 0.7844 - precision_11: 0.9058 - recall_11: 0.7851 - val_loss: 0.2536 - val_dice_coef: 0.7464 - val_precision_11: 0.8916 - val_recall_11: 0.7549\n",
      "Epoch 19/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.2130 - dice_coef: 0.7870 - precision_11: 0.9061 - recall_11: 0.7869 - val_loss: 0.2550 - val_dice_coef: 0.7450 - val_precision_11: 0.9118 - val_recall_11: 0.7315\n",
      "Epoch 20/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.2069 - dice_coef: 0.7931 - precision_11: 0.9110 - recall_11: 0.7875 - val_loss: 0.2506 - val_dice_coef: 0.7494 - val_precision_11: 0.8969 - val_recall_11: 0.7500\n",
      "Epoch 21/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.2067 - dice_coef: 0.7933 - precision_11: 0.9144 - recall_11: 0.7891 - val_loss: 0.2524 - val_dice_coef: 0.7476 - val_precision_11: 0.8897 - val_recall_11: 0.7509\n",
      "Epoch 22/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.2046 - dice_coef: 0.7954 - precision_11: 0.9125 - recall_11: 0.7921 - val_loss: 0.2515 - val_dice_coef: 0.7485 - val_precision_11: 0.9030 - val_recall_11: 0.7459\n",
      "Epoch 23/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.2030 - dice_coef: 0.7970 - precision_11: 0.9122 - recall_11: 0.7944 - val_loss: 0.2589 - val_dice_coef: 0.7411 - val_precision_11: 0.8926 - val_recall_11: 0.7398\n",
      "Epoch 24/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1946 - dice_coef: 0.8054 - precision_11: 0.9178 - recall_11: 0.7977 - val_loss: 0.2488 - val_dice_coef: 0.7512 - val_precision_11: 0.8942 - val_recall_11: 0.7526\n",
      "Epoch 25/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1946 - dice_coef: 0.8054 - precision_11: 0.9178 - recall_11: 0.7976 - val_loss: 0.2588 - val_dice_coef: 0.7412 - val_precision_11: 0.8766 - val_recall_11: 0.7580\n",
      "Epoch 26/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1946 - dice_coef: 0.8054 - precision_11: 0.9169 - recall_11: 0.7987 - val_loss: 0.2634 - val_dice_coef: 0.7366 - val_precision_11: 0.8523 - val_recall_11: 0.7654\n",
      "Epoch 27/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1898 - dice_coef: 0.8102 - precision_11: 0.9179 - recall_11: 0.8036 - val_loss: 0.2553 - val_dice_coef: 0.7447 - val_precision_11: 0.8766 - val_recall_11: 0.7572\n",
      "Epoch 28/100\n",
      "783/783 [==============================] - 152s 195ms/step - loss: 0.1884 - dice_coef: 0.8116 - precision_11: 0.9196 - recall_11: 0.8032 - val_loss: 0.2502 - val_dice_coef: 0.7498 - val_precision_11: 0.8836 - val_recall_11: 0.7599\n",
      "Epoch 29/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1855 - dice_coef: 0.8145 - precision_11: 0.9213 - recall_11: 0.8050 - val_loss: 0.2454 - val_dice_coef: 0.7546 - val_precision_11: 0.8757 - val_recall_11: 0.7770\n",
      "Epoch 30/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1823 - dice_coef: 0.8177 - precision_11: 0.9239 - recall_11: 0.8058 - val_loss: 0.2455 - val_dice_coef: 0.7545 - val_precision_11: 0.9034 - val_recall_11: 0.7527\n",
      "Epoch 31/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1826 - dice_coef: 0.8174 - precision_11: 0.9238 - recall_11: 0.8052 - val_loss: 0.2364 - val_dice_coef: 0.7636 - val_precision_11: 0.8941 - val_recall_11: 0.7716\n",
      "Epoch 32/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1816 - dice_coef: 0.8184 - precision_11: 0.9248 - recall_11: 0.8089 - val_loss: 0.2317 - val_dice_coef: 0.7683 - val_precision_11: 0.9044 - val_recall_11: 0.7725\n",
      "Epoch 33/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1820 - dice_coef: 0.8180 - precision_11: 0.9237 - recall_11: 0.8085 - val_loss: 0.2474 - val_dice_coef: 0.7526 - val_precision_11: 0.8667 - val_recall_11: 0.7809\n",
      "Epoch 34/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1819 - dice_coef: 0.8181 - precision_11: 0.9214 - recall_11: 0.8093 - val_loss: 0.2617 - val_dice_coef: 0.7383 - val_precision_11: 0.9164 - val_recall_11: 0.7249\n",
      "Epoch 35/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1745 - dice_coef: 0.8255 - precision_11: 0.9273 - recall_11: 0.8134 - val_loss: 0.2365 - val_dice_coef: 0.7635 - val_precision_11: 0.8801 - val_recall_11: 0.7755\n",
      "Epoch 36/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1751 - dice_coef: 0.8249 - precision_11: 0.9264 - recall_11: 0.8104 - val_loss: 0.2350 - val_dice_coef: 0.7650 - val_precision_11: 0.8943 - val_recall_11: 0.7745\n",
      "Epoch 37/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1728 - dice_coef: 0.8272 - precision_11: 0.9268 - recall_11: 0.8147 - val_loss: 0.2448 - val_dice_coef: 0.7552 - val_precision_11: 0.8982 - val_recall_11: 0.7581\n",
      "Epoch 38/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1730 - dice_coef: 0.8270 - precision_11: 0.9290 - recall_11: 0.8154 - val_loss: 0.2499 - val_dice_coef: 0.7501 - val_precision_11: 0.8928 - val_recall_11: 0.7494\n",
      "Epoch 39/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1714 - dice_coef: 0.8286 - precision_11: 0.9290 - recall_11: 0.8169 - val_loss: 0.2299 - val_dice_coef: 0.7701 - val_precision_11: 0.8728 - val_recall_11: 0.7976\n",
      "Epoch 40/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1692 - dice_coef: 0.8308 - precision_11: 0.9302 - recall_11: 0.8165 - val_loss: 0.2397 - val_dice_coef: 0.7603 - val_precision_11: 0.9294 - val_recall_11: 0.7340\n",
      "Epoch 41/100\n",
      "783/783 [==============================] - 152s 195ms/step - loss: 0.1670 - dice_coef: 0.8330 - precision_11: 0.9307 - recall_11: 0.8178 - val_loss: 0.2320 - val_dice_coef: 0.7680 - val_precision_11: 0.8989 - val_recall_11: 0.7691\n",
      "Epoch 42/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1661 - dice_coef: 0.8339 - precision_11: 0.9326 - recall_11: 0.8182 - val_loss: 0.2508 - val_dice_coef: 0.7492 - val_precision_11: 0.8932 - val_recall_11: 0.7460\n",
      "Epoch 43/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1663 - dice_coef: 0.8337 - precision_11: 0.9333 - recall_11: 0.8195 - val_loss: 0.2294 - val_dice_coef: 0.7706 - val_precision_11: 0.9205 - val_recall_11: 0.7543\n",
      "Epoch 44/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1643 - dice_coef: 0.8357 - precision_11: 0.9341 - recall_11: 0.8199 - val_loss: 0.2421 - val_dice_coef: 0.7579 - val_precision_11: 0.9115 - val_recall_11: 0.7488\n",
      "Epoch 45/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1630 - dice_coef: 0.8370 - precision_11: 0.9342 - recall_11: 0.8225 - val_loss: 0.2414 - val_dice_coef: 0.7586 - val_precision_11: 0.9162 - val_recall_11: 0.7411\n",
      "Epoch 46/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1609 - dice_coef: 0.8391 - precision_11: 0.9342 - recall_11: 0.8232 - val_loss: 0.2462 - val_dice_coef: 0.7538 - val_precision_11: 0.8660 - val_recall_11: 0.7766\n",
      "Epoch 47/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1590 - dice_coef: 0.8410 - precision_11: 0.9349 - recall_11: 0.8234 - val_loss: 0.2379 - val_dice_coef: 0.7621 - val_precision_11: 0.8948 - val_recall_11: 0.7647\n",
      "Epoch 48/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1580 - dice_coef: 0.8420 - precision_11: 0.9357 - recall_11: 0.8249 - val_loss: 0.2324 - val_dice_coef: 0.7676 - val_precision_11: 0.8998 - val_recall_11: 0.7711\n",
      "Epoch 49/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1581 - dice_coef: 0.8419 - precision_11: 0.9369 - recall_11: 0.8243 - val_loss: 0.2293 - val_dice_coef: 0.7707 - val_precision_11: 0.9155 - val_recall_11: 0.7676\n",
      "Epoch 50/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1577 - dice_coef: 0.8423 - precision_11: 0.9380 - recall_11: 0.8248 - val_loss: 0.2455 - val_dice_coef: 0.7545 - val_precision_11: 0.8274 - val_recall_11: 0.8058\n",
      "Epoch 51/100\n",
      "783/783 [==============================] - 151s 194ms/step - loss: 0.1545 - dice_coef: 0.8455 - precision_11: 0.9378 - recall_11: 0.8282 - val_loss: 0.2341 - val_dice_coef: 0.7659 - val_precision_11: 0.9067 - val_recall_11: 0.7606\n",
      "Epoch 52/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1549 - dice_coef: 0.8451 - precision_11: 0.9381 - recall_11: 0.8281 - val_loss: 0.2419 - val_dice_coef: 0.7581 - val_precision_11: 0.9325 - val_recall_11: 0.7309\n",
      "Epoch 53/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1535 - dice_coef: 0.8465 - precision_11: 0.9370 - recall_11: 0.8299 - val_loss: 0.2256 - val_dice_coef: 0.7744 - val_precision_11: 0.9115 - val_recall_11: 0.7719\n",
      "Epoch 54/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1514 - dice_coef: 0.8486 - precision_11: 0.9399 - recall_11: 0.8282 - val_loss: 0.2466 - val_dice_coef: 0.7534 - val_precision_11: 0.8469 - val_recall_11: 0.7911\n",
      "Epoch 55/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1538 - dice_coef: 0.8462 - precision_11: 0.9391 - recall_11: 0.8250 - val_loss: 0.2175 - val_dice_coef: 0.7825 - val_precision_11: 0.9267 - val_recall_11: 0.7641\n",
      "Epoch 56/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1498 - dice_coef: 0.8502 - precision_11: 0.9411 - recall_11: 0.8288 - val_loss: 0.2309 - val_dice_coef: 0.7691 - val_precision_11: 0.9224 - val_recall_11: 0.7511\n",
      "Epoch 57/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1482 - dice_coef: 0.8518 - precision_11: 0.9398 - recall_11: 0.8319 - val_loss: 0.2174 - val_dice_coef: 0.7826 - val_precision_11: 0.9345 - val_recall_11: 0.7604\n",
      "Epoch 58/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1531 - dice_coef: 0.8469 - precision_11: 0.9382 - recall_11: 0.8286 - val_loss: 0.2267 - val_dice_coef: 0.7733 - val_precision_11: 0.9228 - val_recall_11: 0.7618\n",
      "Epoch 59/100\n",
      "783/783 [==============================] - 157s 201ms/step - loss: 0.1499 - dice_coef: 0.8501 - precision_11: 0.9406 - recall_11: 0.8315 - val_loss: 0.2312 - val_dice_coef: 0.7688 - val_precision_11: 0.8846 - val_recall_11: 0.7916\n",
      "Epoch 60/100\n",
      "783/783 [==============================] - 152s 195ms/step - loss: 0.1479 - dice_coef: 0.8521 - precision_11: 0.9420 - recall_11: 0.8326 - val_loss: 0.2121 - val_dice_coef: 0.7879 - val_precision_11: 0.9200 - val_recall_11: 0.7693\n",
      "Epoch 61/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1467 - dice_coef: 0.8533 - precision_11: 0.9419 - recall_11: 0.8330 - val_loss: 0.2175 - val_dice_coef: 0.7825 - val_precision_11: 0.9049 - val_recall_11: 0.7850\n",
      "Epoch 62/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1457 - dice_coef: 0.8543 - precision_11: 0.9418 - recall_11: 0.8360 - val_loss: 0.2143 - val_dice_coef: 0.7857 - val_precision_11: 0.9051 - val_recall_11: 0.7923\n",
      "Epoch 63/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1448 - dice_coef: 0.8552 - precision_11: 0.9453 - recall_11: 0.8320 - val_loss: 0.2231 - val_dice_coef: 0.7769 - val_precision_11: 0.8669 - val_recall_11: 0.8087\n",
      "Epoch 64/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1468 - dice_coef: 0.8532 - precision_11: 0.9421 - recall_11: 0.8355 - val_loss: 0.2146 - val_dice_coef: 0.7854 - val_precision_11: 0.9206 - val_recall_11: 0.7749\n",
      "Epoch 65/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1447 - dice_coef: 0.8553 - precision_11: 0.9413 - recall_11: 0.8339 - val_loss: 0.2327 - val_dice_coef: 0.7673 - val_precision_11: 0.9281 - val_recall_11: 0.7458\n",
      "Epoch 66/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1457 - dice_coef: 0.8543 - precision_11: 0.9406 - recall_11: 0.8330 - val_loss: 0.2225 - val_dice_coef: 0.7775 - val_precision_11: 0.9485 - val_recall_11: 0.7357\n",
      "Epoch 67/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1402 - dice_coef: 0.8598 - precision_11: 0.9453 - recall_11: 0.8366 - val_loss: 0.2208 - val_dice_coef: 0.7792 - val_precision_11: 0.9323 - val_recall_11: 0.7574\n",
      "Epoch 68/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1415 - dice_coef: 0.8585 - precision_11: 0.9431 - recall_11: 0.8384 - val_loss: 0.2195 - val_dice_coef: 0.7805 - val_precision_11: 0.9331 - val_recall_11: 0.7450\n",
      "Epoch 69/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1399 - dice_coef: 0.8601 - precision_11: 0.9445 - recall_11: 0.8388 - val_loss: 0.2220 - val_dice_coef: 0.7780 - val_precision_11: 0.9502 - val_recall_11: 0.7272\n",
      "Epoch 70/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1385 - dice_coef: 0.8615 - precision_11: 0.9456 - recall_11: 0.8387 - val_loss: 0.2183 - val_dice_coef: 0.7817 - val_precision_11: 0.9396 - val_recall_11: 0.7500\n",
      "Epoch 71/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1392 - dice_coef: 0.8608 - precision_11: 0.9458 - recall_11: 0.8390 - val_loss: 0.2114 - val_dice_coef: 0.7886 - val_precision_11: 0.9369 - val_recall_11: 0.7612\n",
      "Epoch 72/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1376 - dice_coef: 0.8624 - precision_11: 0.9476 - recall_11: 0.8402 - val_loss: 0.2155 - val_dice_coef: 0.7845 - val_precision_11: 0.9356 - val_recall_11: 0.7708\n",
      "Epoch 73/100\n",
      "783/783 [==============================] - 152s 195ms/step - loss: 0.1382 - dice_coef: 0.8618 - precision_11: 0.9455 - recall_11: 0.8404 - val_loss: 0.2064 - val_dice_coef: 0.7936 - val_precision_11: 0.9363 - val_recall_11: 0.7718\n",
      "Epoch 74/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1391 - dice_coef: 0.8609 - precision_11: 0.9467 - recall_11: 0.8394 - val_loss: 0.2198 - val_dice_coef: 0.7802 - val_precision_11: 0.9417 - val_recall_11: 0.7505\n",
      "Epoch 75/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1355 - dice_coef: 0.8645 - precision_11: 0.9484 - recall_11: 0.8439 - val_loss: 0.2068 - val_dice_coef: 0.7932 - val_precision_11: 0.9290 - val_recall_11: 0.7720\n",
      "Epoch 76/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1364 - dice_coef: 0.8636 - precision_11: 0.9486 - recall_11: 0.8422 - val_loss: 0.2169 - val_dice_coef: 0.7831 - val_precision_11: 0.9291 - val_recall_11: 0.7668\n",
      "Epoch 77/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1352 - dice_coef: 0.8648 - precision_11: 0.9483 - recall_11: 0.8433 - val_loss: 0.2154 - val_dice_coef: 0.7846 - val_precision_11: 0.9334 - val_recall_11: 0.7643\n",
      "Epoch 78/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1372 - dice_coef: 0.8628 - precision_11: 0.9484 - recall_11: 0.8409 - val_loss: 0.2103 - val_dice_coef: 0.7897 - val_precision_11: 0.9327 - val_recall_11: 0.7730\n",
      "Epoch 79/100\n",
      "783/783 [==============================] - 152s 195ms/step - loss: 0.1339 - dice_coef: 0.8661 - precision_11: 0.9493 - recall_11: 0.8436 - val_loss: 0.2154 - val_dice_coef: 0.7846 - val_precision_11: 0.9305 - val_recall_11: 0.7650\n",
      "Epoch 80/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1348 - dice_coef: 0.8652 - precision_11: 0.9487 - recall_11: 0.8423 - val_loss: 0.2120 - val_dice_coef: 0.7880 - val_precision_11: 0.9342 - val_recall_11: 0.7676\n",
      "Epoch 81/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1334 - dice_coef: 0.8666 - precision_11: 0.9490 - recall_11: 0.8437 - val_loss: 0.2145 - val_dice_coef: 0.7855 - val_precision_11: 0.9240 - val_recall_11: 0.7691\n",
      "Epoch 82/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1338 - dice_coef: 0.8662 - precision_11: 0.9501 - recall_11: 0.8442 - val_loss: 0.2075 - val_dice_coef: 0.7925 - val_precision_11: 0.9338 - val_recall_11: 0.7749\n",
      "Epoch 83/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1307 - dice_coef: 0.8693 - precision_11: 0.9509 - recall_11: 0.8467 - val_loss: 0.2040 - val_dice_coef: 0.7960 - val_precision_11: 0.9267 - val_recall_11: 0.7845\n",
      "Epoch 84/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1307 - dice_coef: 0.8693 - precision_11: 0.9505 - recall_11: 0.8472 - val_loss: 0.2032 - val_dice_coef: 0.7968 - val_precision_11: 0.9154 - val_recall_11: 0.8006\n",
      "Epoch 85/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1322 - dice_coef: 0.8678 - precision_11: 0.9516 - recall_11: 0.8446 - val_loss: 0.2089 - val_dice_coef: 0.7911 - val_precision_11: 0.9260 - val_recall_11: 0.7711\n",
      "Epoch 86/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1318 - dice_coef: 0.8682 - precision_11: 0.9493 - recall_11: 0.8449 - val_loss: 0.2167 - val_dice_coef: 0.7833 - val_precision_11: 0.9404 - val_recall_11: 0.7603\n",
      "Epoch 87/100\n",
      "783/783 [==============================] - 152s 195ms/step - loss: 0.1305 - dice_coef: 0.8695 - precision_11: 0.9487 - recall_11: 0.8450 - val_loss: 0.2146 - val_dice_coef: 0.7854 - val_precision_11: 0.9177 - val_recall_11: 0.7859\n",
      "Epoch 88/100\n",
      "783/783 [==============================] - 152s 195ms/step - loss: 0.1294 - dice_coef: 0.8706 - precision_11: 0.9507 - recall_11: 0.8455 - val_loss: 0.2077 - val_dice_coef: 0.7923 - val_precision_11: 0.9302 - val_recall_11: 0.7735\n",
      "Epoch 89/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1284 - dice_coef: 0.8716 - precision_11: 0.9525 - recall_11: 0.8477 - val_loss: 0.2107 - val_dice_coef: 0.7893 - val_precision_11: 0.9207 - val_recall_11: 0.7836\n",
      "Epoch 90/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1278 - dice_coef: 0.8722 - precision_11: 0.9513 - recall_11: 0.8481 - val_loss: 0.2127 - val_dice_coef: 0.7873 - val_precision_11: 0.9363 - val_recall_11: 0.7623\n",
      "Epoch 91/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1266 - dice_coef: 0.8734 - precision_11: 0.9519 - recall_11: 0.8494 - val_loss: 0.2105 - val_dice_coef: 0.7895 - val_precision_11: 0.9215 - val_recall_11: 0.7861\n",
      "Epoch 92/100\n",
      "783/783 [==============================] - 152s 195ms/step - loss: 0.1269 - dice_coef: 0.8731 - precision_11: 0.9518 - recall_11: 0.8496 - val_loss: 0.2056 - val_dice_coef: 0.7944 - val_precision_11: 0.9143 - val_recall_11: 0.7969\n",
      "Epoch 93/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1267 - dice_coef: 0.8733 - precision_11: 0.9529 - recall_11: 0.8483 - val_loss: 0.2170 - val_dice_coef: 0.7830 - val_precision_11: 0.9445 - val_recall_11: 0.7529\n",
      "Epoch 94/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1286 - dice_coef: 0.8714 - precision_11: 0.9530 - recall_11: 0.8482 - val_loss: 0.2110 - val_dice_coef: 0.7890 - val_precision_11: 0.9387 - val_recall_11: 0.7663\n",
      "Epoch 95/100\n",
      "783/783 [==============================] - 152s 195ms/step - loss: 0.1259 - dice_coef: 0.8741 - precision_11: 0.9542 - recall_11: 0.8503 - val_loss: 0.2124 - val_dice_coef: 0.7876 - val_precision_11: 0.9450 - val_recall_11: 0.7565\n",
      "Epoch 96/100\n",
      "783/783 [==============================] - 152s 195ms/step - loss: 0.1245 - dice_coef: 0.8755 - precision_11: 0.9545 - recall_11: 0.8517 - val_loss: 0.2161 - val_dice_coef: 0.7839 - val_precision_11: 0.9401 - val_recall_11: 0.7624\n",
      "Epoch 97/100\n",
      "783/783 [==============================] - 152s 195ms/step - loss: 0.1264 - dice_coef: 0.8736 - precision_11: 0.9518 - recall_11: 0.8497 - val_loss: 0.2124 - val_dice_coef: 0.7876 - val_precision_11: 0.9318 - val_recall_11: 0.7719\n",
      "Epoch 98/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1249 - dice_coef: 0.8751 - precision_11: 0.9519 - recall_11: 0.8504 - val_loss: 0.2179 - val_dice_coef: 0.7821 - val_precision_11: 0.9444 - val_recall_11: 0.7499\n",
      "Epoch 99/100\n",
      "783/783 [==============================] - 152s 195ms/step - loss: 0.1249 - dice_coef: 0.8751 - precision_11: 0.9550 - recall_11: 0.8519 - val_loss: 0.2218 - val_dice_coef: 0.7782 - val_precision_11: 0.9391 - val_recall_11: 0.7553\n",
      "Epoch 100/100\n",
      "783/783 [==============================] - 152s 194ms/step - loss: 0.1247 - dice_coef: 0.8753 - precision_11: 0.9544 - recall_11: 0.8522 - val_loss: 0.2129 - val_dice_coef: 0.7871 - val_precision_11: 0.9422 - val_recall_11: 0.7616\n",
      " 1/98 [..............................] - ETA: 277:14:34 - loss: 0.0865 - dice_coef: 0.9135 - precision_11: 0.9241 - recall_11: 0.9046"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'https://group-5.k8s-maia.com/'. Verify the server is running and reachable."
     ]
    }
   ],
   "source": [
    "from matplotlib import image\n",
    "batch_size = 8\n",
    "for train, val in kf.split(images):\n",
    "    image_train, image_val = images[train],images[val]\n",
    "    mask_train, mask_val = masks[train], masks[val]\n",
    "    ## Get model\n",
    "    model = get_unet(img_w, img_h, img_ch, n_base, LR, batch_normalization, dropout)\n",
    "    train_generator = generator(image_train, mask_train, batch_size)\n",
    "    val_generator = generator(image_val, mask_val, batch_size)\n",
    "        \n",
    "    # Compile the model\n",
    "    model.compile(loss = [dice_coef_loss],          # Model Compiling   \n",
    "                optimizer = Adam(lr = LR),\n",
    "                metrics = [dice_coef, tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "#     model_history = model.fit(train_generator, \n",
    "#                 validation_data = (val_generator),\n",
    "#                 epochs = epochs,  verbose=1)\n",
    "    model_history = model.fit_generator(train_generator, steps_per_epoch = len(image_train)//batch_size,\n",
    "        validation_data = val_generator, validation_steps = len(image_val)//batch_size,\n",
    "        epochs = epochs,  verbose=1)\n",
    "\n",
    "\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(image_val, mask_val, verbose=1)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.title(\"Learning curve\")\n",
    "    plt.plot(model_history.history[\"loss\"], label=\"loss\")\n",
    "    plt.plot(model_history.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.plot( np.argmin(model_history.history[\"val_loss\"]),\n",
    "            np.min(model_history.history[\"val_loss\"]),\n",
    "            marker=\"x\", color=\"r\", label=\"best model\")\n",
    "\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss Value\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.title(\"Dice Coefficients\")\n",
    "    plt.plot(model_history.history['dice_coef'], label=\"dice\")\n",
    "    plt.plot(model_history.history['val_dice_coef'], label=\"val_dice\")\n",
    "    plt.plot( np.argmax(model_history.history[\"val_dice_coef\"]),\n",
    "            np.max(model_history.history[\"val_dice_coef\"]),\n",
    "            marker=\"x\", color=\"r\", label=\"best model\")\n",
    "\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Dice Coef\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'https://group-5.k8s-maia.com/'. Verify the server is running and reachable. (Forbidden)."
     ]
    }
   ],
   "source": [
    "cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'dice_coef', 'precision_8', 'recall_8']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
