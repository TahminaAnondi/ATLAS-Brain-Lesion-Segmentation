{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /usr/local/lib/python3.8/dist-packages (2.9.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Activation, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, SpatialDropout2D,Conv2DTranspose,Concatenate\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(x, n_base, batch_normalization):\n",
    "    \n",
    "    x = Conv2D(filters=n_base, kernel_size=(3,3), \n",
    "                        strides=(1,1),padding='same')(x)\n",
    "    if (batch_normalization):\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters=n_base, kernel_size=(3,3), \n",
    "                        strides=(1,1),padding='same')(x)\n",
    "    if (batch_normalization):\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_block(x, n_base, batch_normalization, dropout):\n",
    "    f = conv_block(x, n_base, batch_normalization)\n",
    "    p = layers.MaxPool2D(pool_size = (2,2))(f)\n",
    "    if(dropout):\n",
    "        p = layers.Dropout(0.2)(p)\n",
    "        \n",
    "    return f, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_block(x, f, n_base, batch_normalization, dropout):\n",
    "    \n",
    "    x = Conv2DTranspose(filters=n_base, kernel_size=(2,2), \n",
    "                         strides=(2,2),padding='same')(x)\n",
    "    x = Concatenate()([x,f])\n",
    "    if(dropout):\n",
    "        x = layers.Dropout(0.2)(x)\n",
    "    x = conv_block(x, n_base, batch_normalization)\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet_weightmap(img_w, img_h, img_ch, n_base, LR, batch_normalization, dropout):\n",
    "\n",
    "    \n",
    "    \n",
    "    ## Encoder part\n",
    "#     model = Sequential()\n",
    "    image = layers.Input((img_w, img_h, img_ch))\n",
    "    weight = layers.Input((img_w, img_h, img_ch))\n",
    "    inputs= layers.concatenate([image,weight],axis=-1)\n",
    "\n",
    "    # inputs = layers.Input((img_w, img_h, img_ch))\n",
    "    \n",
    "    f1, p1 = downsample_block(inputs, n_base, batch_normalization, dropout)\n",
    "    f2, p2 = downsample_block(p1, n_base*2, batch_normalization, dropout)\n",
    "    f3, p3 = downsample_block(p2, n_base*4, batch_normalization, dropout)\n",
    "    f4, p4 = downsample_block(p3, n_base*8, batch_normalization, dropout)\n",
    "    \n",
    "    \n",
    "    ## Bottleneck\n",
    "    bottleneck = conv_block(p4, n_base*16, batch_normalization)\n",
    "    \n",
    "    ## Decoder part\n",
    "    p5 = upsample_block(bottleneck, f4, n_base*8, batch_normalization, dropout)\n",
    "    p6 = upsample_block(p5, f3, n_base*4, batch_normalization, dropout)\n",
    "    p7 = upsample_block(p6, f2, n_base*2, batch_normalization, dropout)\n",
    "    p8 = upsample_block(p7, f1, n_base, batch_normalization, dropout)\n",
    "\n",
    "    \n",
    "    ## 1 Convo layer\n",
    "    p9 = Conv2D(filters=1, kernel_size=(1,1), \n",
    "                            padding='same')(p8)\n",
    "    outputs = Activation('sigmoid')(p9)\n",
    "    \n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.8/dist-packages (0.19.3)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (9.1.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (1.9.1)\n",
      "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (2.8.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (21.3)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (2022.8.12)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (1.22.3)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (2.22.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->scikit-image) (3.0.9)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task1a) Lung segmentation in chest X-ray images:\n",
    "import os\n",
    "from random import shuffle\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "image_path = '/DL_course_data/Lab3/MRI/Image' \n",
    "mask_path = '/DL_course_data/Lab3/MRI/Mask'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(image_path,mask_path):\n",
    "    \n",
    "    image_list = os.listdir(image_path)\n",
    "    mask_list = os.listdir(mask_path)\n",
    "    \n",
    "    images = []\n",
    "    masks = []\n",
    "\n",
    "    for image in image_list:\n",
    "        img = imread(os.path.join(image_path, image), as_gray=True)  # \"as_grey\"\n",
    "        img = resize(img, (240, 240), anti_aliasing=True).astype('float32')\n",
    "        images.append(img)\n",
    "\n",
    "    for image in image_list:\n",
    "        mask = str.replace(image,'.png','_Tumor.png')\n",
    "        mask_img = imread(os.path.join(mask_path, mask), as_gray=True)\n",
    "        mask_img = resize(mask_img, (240, 240), anti_aliasing=True).astype('float32')\n",
    "        masks.append(mask_img)\n",
    "        \n",
    "    ## Load data in traditional way\n",
    "    # img_train, img_val, mask_train, mask_val = train_test_split(images, masks, shuffle = True,\n",
    "    #                                                   test_size = 0.2)\n",
    "\n",
    "    images = np.expand_dims(images, axis = -1)\n",
    "    masks = np.expand_dims(masks, axis = -1)\n",
    "    \n",
    "    return np.array(images), np.array(masks)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + 0.0001) / (K.sum(y_true_f) + K.sum(y_pred_f) + 0.0001)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_base =8\n",
    "LR = 1e-4\n",
    "batch_normalization = True\n",
    "dropout = True\n",
    "epochs = 100\n",
    "batch_size = 8\n",
    "weight_strength = 1\n",
    "\n",
    "img_w, img_h = 240,240\n",
    "img_ch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, masks = load_data(image_path,mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import binary_dilation, binary_erosion\n",
    "\n",
    "weight_boundary = []\n",
    "\n",
    "radius = 2\n",
    "structure = np.ones((5,5))\n",
    "\n",
    "\n",
    "for i in range(len(masks)):\n",
    "    weight_boundary.append(binary_dilation(masks[i,:,:,0], structure).astype(int) - binary_erosion(masks[i,:,:,0],structure).astype(int))\n",
    "    # mask_eroded[i,:,:,0] = binary_erosion(masks[i,:,:,0],structure)\n",
    "    # # weight_boundary[i,:,:,0] = mask_dilated[i,:,:,0] - mask_eroded[i,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2136"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_loss(weight_map, weight_strength): \n",
    "    def weighted_dice_loss(y_true, y_pred):\n",
    "        y_true_f = K.flatten(y_true) \n",
    "        y_pred_f = K.flatten(y_pred)\n",
    "        weight_f = K.flatten(weight_map) \n",
    "        weight_f = weight_f * weight_strength \n",
    "        weight_f = 1/(weight_f + 1)\n",
    "        weighted_intersection = K.sum(weight_f * (y_true_f * y_pred_f))\n",
    "        return -(2. * weighted_intersection + K.epsilon()) / (K.sum(y_true_f) + K.sum(y_pred_f) + K.epsilon())\n",
    "    return weighted_dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import concatenate\n",
    "\n",
    "def generator_with_weights(x_train, y_train, weight_train, batch_size):\n",
    "    while True:\n",
    "               \n",
    "        for ind in (range(0, len(x_train), batch_size)):\n",
    "            \n",
    "            batch_img = x_train[ind:ind+batch_size]\n",
    "            batch_weightmap = weight_train[ind:ind+batch_size]\n",
    "            batch_label = y_train[ind:ind+batch_size]\n",
    "            \n",
    "            # Sanity check assures batch size always satisfied\n",
    "            # by repeating the last 2-3 images at last batch.\n",
    "            length = len(batch_img)\n",
    "            if length == batch_size:\n",
    "                pass\n",
    "            else:\n",
    "                for tmp in range(batch_size - length):\n",
    "                    batch_img = np.append(batch_img, np.expand_dims(batch_img[-1],axis=0), axis = 0)\n",
    "                    batch_weightmap = np.append(batch_weightmap, np.expand_dims(batch_weightmap[-1],axis=0), axis = 0)\n",
    "                    batch_label = np.append(batch_label, np.expand_dims(batch_label[-1], axis=0), axis = 0)\n",
    "        \n",
    "            backgound_value = x_train.min()\n",
    "            data_gen_args = dict(rotation_range=10.,\n",
    "                                     width_shift_range=0.1,\n",
    "                                     height_shift_range=0.1,\n",
    "                                     cval = backgound_value,\n",
    "                                     zoom_range=0.2,\n",
    "                                     horizontal_flip = True)\n",
    "            \n",
    "            image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "            weights_datagen = ImageDataGenerator(**data_gen_args)\n",
    "            mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "            \n",
    "            image_generator = image_datagen.flow(batch_img, shuffle=False,\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 seed=1)\n",
    "\n",
    "            weights_generator = image_datagen.flow(batch_weightmap, shuffle=False,\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 seed=1)\n",
    "            \n",
    "            mask_generator = mask_datagen.flow(batch_label, shuffle=False,\n",
    "                                               batch_size=batch_size,\n",
    "                                               seed=1)\n",
    "            \n",
    "            image = image_generator.next()\n",
    "            weight = weights_generator.next()\n",
    "            label = mask_generator.next()\n",
    "            input = concatenate([image,weight],axis=-1)\n",
    "            \n",
    "            \n",
    "            yield input, label\n",
    "            # yield (image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import concatenate\n",
    "\n",
    "def n_generator_with_weights(x_train, y_train, weight_train, batch_size):\n",
    "    while True:\n",
    "               \n",
    "        for ind in (range(0, len(x_train), batch_size)):\n",
    "            \n",
    "            batch_img = x_train[ind:ind+batch_size]\n",
    "            batch_weightmap = weight_train[ind:ind+batch_size]\n",
    "            batch_label = y_train[ind:ind+batch_size]\n",
    "            \n",
    "            # Sanity check assures batch size always satisfied\n",
    "            # by repeating the last 2-3 images at last batch.\n",
    "            length = len(batch_img)\n",
    "            if length == batch_size:\n",
    "                pass\n",
    "            else:\n",
    "                for tmp in range(batch_size - length):\n",
    "                    batch_img = np.append(batch_img, np.expand_dims(batch_img[-1],axis=0), axis = 0)\n",
    "                    batch_weightmap = np.append(batch_weightmap, np.expand_dims(batch_weightmap[-1],axis=0), axis = 0)\n",
    "                    batch_label = np.append(batch_label, np.expand_dims(batch_label[-1], axis=0), axis = 0)\n",
    "        \n",
    "            backgound_value = x_train.min()\n",
    "            data_gen_args = dict(rotation_range=10.,\n",
    "                                     width_shift_range=0.1,\n",
    "                                     height_shift_range=0.1,\n",
    "                                     cval = backgound_value,\n",
    "                                     zoom_range=0.2,\n",
    "                                     horizontal_flip = True)\n",
    "            \n",
    "            image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "            weights_datagen = ImageDataGenerator(**data_gen_args)\n",
    "            mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "            \n",
    "            image_generator = image_datagen.flow(batch_img, shuffle=False,\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 seed=1)\n",
    "\n",
    "            weights_generator = image_datagen.flow(batch_weightmap, shuffle=False,\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 seed=1)\n",
    "            \n",
    "            mask_generator = mask_datagen.flow(batch_label, shuffle=False,\n",
    "                                               batch_size=batch_size,\n",
    "                                               seed=1)\n",
    "            \n",
    "            image = image_generator.next()\n",
    "            weight = weights_generator.next()\n",
    "            label = mask_generator.next()\n",
    "            # input = concatenate([image,weight],axis=-1)\n",
    "            \n",
    "            \n",
    "            yield concatenate([image,weight],axis=-1), label\n",
    "            gc.collect()\n",
    "            # yield (image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=4)\n",
    "cvscores = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_hist(History): \n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.title(\"Learning curve\")\n",
    "    plt.plot(History.history[\"loss\"], label=\"loss\")\n",
    "    plt.plot(History.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.plot( np.argmin(History.history[\"val_loss\"]),\n",
    "            np.min(History.history[\"val_loss\"]),\n",
    "            marker=\"x\", color=\"r\", label=\"best model\")\n",
    "\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss Value\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure\n",
    "\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.plot(History.history[\"accuracy\"], label=\"accuracy\")\n",
    "    plt.plot(History.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "    plt.plot( np.argmax(History.history[\"val_accuracy\"]),\n",
    "            np.max(History.history[\"val_accuracy\"]),\n",
    "            marker=\"x\", color=\"r\", label=\"best model\")\n",
    "\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 240, 240, 2  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 240, 240, 8)  152         ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 240, 240, 8)  32         ['conv2d[1][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 240, 240, 8)  0           ['batch_normalization[1][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 240, 240, 8)  584         ['activation[1][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 240, 240, 8)  32         ['conv2d_1[1][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 240, 240, 8)  0           ['batch_normalization_1[1][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 120, 120, 8)  0           ['activation_1[1][0]']           \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 120, 120, 8)  0           ['max_pooling2d[1][0]']          \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 120, 120, 16  1168        ['dropout[1][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 120, 120, 16  64         ['conv2d_2[1][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 120, 120, 16  0           ['batch_normalization_2[1][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 120, 120, 16  2320        ['activation_2[1][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 120, 120, 16  64         ['conv2d_3[1][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 120, 120, 16  0           ['batch_normalization_3[1][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 60, 60, 16)  0           ['activation_3[1][0]']           \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 60, 60, 16)   0           ['max_pooling2d_1[1][0]']        \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 60, 60, 32)   4640        ['dropout_1[1][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 60, 60, 32)  128         ['conv2d_4[1][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 60, 60, 32)   0           ['batch_normalization_4[1][0]']  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 60, 60, 32)   9248        ['activation_4[1][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 60, 60, 32)  128         ['conv2d_5[1][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 60, 60, 32)   0           ['batch_normalization_5[1][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 30, 30, 32)  0           ['activation_5[1][0]']           \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 30, 30, 32)   0           ['max_pooling2d_2[1][0]']        \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 30, 30, 64)   18496       ['dropout_2[1][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 30, 30, 64)  256         ['conv2d_6[1][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 30, 30, 64)   0           ['batch_normalization_6[1][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 30, 30, 64)   36928       ['activation_6[1][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 30, 30, 64)  256         ['conv2d_7[1][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 30, 30, 64)   0           ['batch_normalization_7[1][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 15, 15, 64)  0           ['activation_7[1][0]']           \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 15, 15, 64)   0           ['max_pooling2d_3[1][0]']        \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 15, 15, 128)  73856       ['dropout_3[1][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 15, 15, 128)  512        ['conv2d_8[1][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 15, 15, 128)  0           ['batch_normalization_8[1][0]']  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 15, 15, 128)  147584      ['activation_8[1][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 15, 15, 128)  512        ['conv2d_9[1][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 15, 15, 128)  0           ['batch_normalization_9[1][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 30, 30, 64)  32832       ['activation_9[1][0]']           \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 30, 30, 128)  0           ['conv2d_transpose[1][0]',       \n",
      "                                                                  'activation_7[1][0]']           \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 30, 30, 128)  0           ['concatenate_1[1][0]']          \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 30, 30, 64)   73792       ['dropout_4[1][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 30, 30, 64)  256         ['conv2d_10[1][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 30, 30, 64)   0           ['batch_normalization_10[1][0]'] \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 30, 30, 64)   36928       ['activation_10[1][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 30, 30, 64)  256         ['conv2d_11[1][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 30, 30, 64)   0           ['batch_normalization_11[1][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 60, 60, 32)  8224        ['activation_11[1][0]']          \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 60, 60, 64)   0           ['conv2d_transpose_1[1][0]',     \n",
      "                                                                  'activation_5[1][0]']           \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 60, 60, 64)   0           ['concatenate_2[1][0]']          \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 60, 60, 32)   18464       ['dropout_5[1][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 60, 60, 32)  128         ['conv2d_12[1][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 60, 60, 32)   0           ['batch_normalization_12[1][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 60, 60, 32)   9248        ['activation_12[1][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 60, 60, 32)  128         ['conv2d_13[1][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 60, 60, 32)   0           ['batch_normalization_13[1][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 120, 120, 16  2064       ['activation_13[1][0]']          \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 120, 120, 32  0           ['conv2d_transpose_2[1][0]',     \n",
      "                                )                                 'activation_3[1][0]']           \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 120, 120, 32  0           ['concatenate_3[1][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 120, 120, 16  4624        ['dropout_6[1][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 120, 120, 16  64         ['conv2d_14[1][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 120, 120, 16  0           ['batch_normalization_14[1][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 120, 120, 16  2320        ['activation_14[1][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 120, 120, 16  64         ['conv2d_15[1][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 120, 120, 16  0           ['batch_normalization_15[1][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 240, 240, 8)  520        ['activation_15[1][0]']          \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 240, 240, 16  0           ['conv2d_transpose_3[1][0]',     \n",
      "                                )                                 'activation_1[1][0]']           \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 240, 240, 16  0           ['concatenate_4[1][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 240, 240, 8)  1160        ['dropout_7[1][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 240, 240, 8)  32         ['conv2d_16[1][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 240, 240, 8)  0           ['batch_normalization_16[1][0]'] \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 240, 240, 8)  584         ['activation_16[1][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 240, 240, 8)  32         ['conv2d_17[1][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 240, 240, 8)  0           ['batch_normalization_17[1][0]'] \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 240, 240, 1)  9           ['activation_17[1][0]']          \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 240, 240, 1)  0           ['conv2d_18[1][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 488,689\n",
      "Trainable params: 487,217\n",
      "Non-trainable params: 1,472\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "from matplotlib import image\n",
    "\n",
    "for train, val in kf.split(images, masks, weight_boundary):\n",
    "    # image_train, image_val = images[train],images[val]\n",
    "    # weight_train, weight_val = weight_boundary[train], weight_boundary[val]\n",
    "    # mask_train, mask_val = masks[train], masks[val]\n",
    "    ## Get model\n",
    "    model = get_unet_weightmap(img_w, img_h, img_ch, n_base, LR, \n",
    "                batch_normalization, dropout)\n",
    "\n",
    "    # train_generator = generator_with_weights(images[train], masks[train], weight_boundary[train], batch_size)\n",
    "    # val_generator = generator_with_weights(images[val], masks[val], weight_boundary[val], batch_size)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss = [dice_coef_loss],          # Model Compiling   \n",
    "                optimizer = Adam(lr = LR),\n",
    "                metrics = [dice_coef, tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "    model_history = model.fit_generator(generator_with_weights(images[train], masks[train], weight_boundary[train], batch_size),\n",
    "        steps_per_epoch = len(images[train])//batch_size,\n",
    "        validation_data = generator_with_weights(images[val], masks[val], weight_boundary[val], batch_size), \n",
    "        validation_steps = len(images[val])//batch_size,\n",
    "        epochs = epochs,  verbose=1)\n",
    "    show_hist(model_history)\n",
    "\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(images[val], masks[val], verbose=1)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "    \n",
    "    print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.9252661392092705, 10.042130947113037, 4.18890155851841, 3.611527383327484]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'dice_coef', 'precision_8', 'recall_8']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
