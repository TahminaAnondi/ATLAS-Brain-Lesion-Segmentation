{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Activation, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, SpatialDropout2D,Conv2DTranspose,Concatenate\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(x, n_base, batch_normalization):\n",
    "    \n",
    "    x = Conv2D(filters=n_base, kernel_size=(3,3), \n",
    "                        strides=(1,1),padding='same')(x)\n",
    "    if (batch_normalization):\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters=n_base, kernel_size=(3,3), \n",
    "                        strides=(1,1),padding='same')(x)\n",
    "    if (batch_normalization):\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def downsample_block(x, n_base, batch_normalization, dropout):\n",
    "    f = conv_block(x, n_base, batch_normalization)\n",
    "    p = layers.MaxPool2D(pool_size = (2,2))(f)\n",
    "    if(dropout):\n",
    "        p = layers.Dropout(0.2)(p)\n",
    "        \n",
    "    return f, p\n",
    "\n",
    "def upsample_block(x, f, n_base, batch_normalization, dropout):\n",
    "    \n",
    "    x = Conv2DTranspose(filters=n_base, kernel_size=(2,2), \n",
    "                         strides=(2,2),padding='same')(x)\n",
    "    x = Concatenate()([x,f])\n",
    "    if(dropout):\n",
    "        x = layers.Dropout(0.2)(x)\n",
    "    x = conv_block(x, n_base, batch_normalization)\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet(img_w, img_h, img_ch, n_base, LR, batch_normalization, dropout):\n",
    "    \n",
    "#     ## Parameters\n",
    "#     n_base = 8\n",
    "#     LR = 1e-4\n",
    "#     batch_normalization = True\n",
    "#     dropout = False\n",
    "    \n",
    "    \n",
    "    ## Encoder part\n",
    "#     model = Sequential()\n",
    "    inputs = layers.Input((img_w, img_h, img_ch))\n",
    "    \n",
    "    f1, p1 = downsample_block(inputs, n_base, batch_normalization, dropout)\n",
    "    f2, p2 = downsample_block(p1, n_base*2, batch_normalization, dropout)\n",
    "    f3, p3 = downsample_block(p2, n_base*4, batch_normalization, dropout)\n",
    "    f4, p4 = downsample_block(p3, n_base*8, batch_normalization, dropout)\n",
    "    \n",
    "    \n",
    "    ## Bottleneck\n",
    "    bottleneck = conv_block(p4, n_base*16, batch_normalization)\n",
    "    \n",
    "    ## Decoder part\n",
    "    p5 = upsample_block(bottleneck, f4, n_base*8, batch_normalization, dropout)\n",
    "    p6 = upsample_block(p5, f3, n_base*4, batch_normalization, dropout)\n",
    "    p7 = upsample_block(p6, f2, n_base*2, batch_normalization, dropout)\n",
    "    p8 = upsample_block(p7, f1, n_base, batch_normalization, dropout)\n",
    "\n",
    "    \n",
    "    ## 1 Convo layer\n",
    "    p9 = Conv2D(filters=1, kernel_size=(1,1), \n",
    "                            padding='same')(p8)\n",
    "    outputs = Activation('sigmoid')(p9)\n",
    "    \n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "#     model = model(inputs = inputs, outputs = outputs)\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + 0.0001) / (K.sum(y_true_f) + K.sum(y_pred_f) + 0.0001)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_12 (InputLayer)          [(None, 240, 240, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_209 (Conv2D)            (None, 240, 240, 16  160         ['input_12[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_198 (Batch  (None, 240, 240, 16  64         ['conv2d_209[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_209 (Activation)    (None, 240, 240, 16  0           ['batch_normalization_198[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_210 (Conv2D)            (None, 240, 240, 16  2320        ['activation_209[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_199 (Batch  (None, 240, 240, 16  64         ['conv2d_210[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_210 (Activation)    (None, 240, 240, 16  0           ['batch_normalization_199[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_44 (MaxPooling2D  (None, 120, 120, 16  0          ['activation_210[0][0]']         \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " dropout_88 (Dropout)           (None, 120, 120, 16  0           ['max_pooling2d_44[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_211 (Conv2D)            (None, 120, 120, 32  4640        ['dropout_88[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_200 (Batch  (None, 120, 120, 32  128        ['conv2d_211[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_211 (Activation)    (None, 120, 120, 32  0           ['batch_normalization_200[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_212 (Conv2D)            (None, 120, 120, 32  9248        ['activation_211[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_201 (Batch  (None, 120, 120, 32  128        ['conv2d_212[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_212 (Activation)    (None, 120, 120, 32  0           ['batch_normalization_201[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_45 (MaxPooling2D  (None, 60, 60, 32)  0           ['activation_212[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_89 (Dropout)           (None, 60, 60, 32)   0           ['max_pooling2d_45[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_213 (Conv2D)            (None, 60, 60, 64)   18496       ['dropout_89[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_202 (Batch  (None, 60, 60, 64)  256         ['conv2d_213[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_213 (Activation)    (None, 60, 60, 64)   0           ['batch_normalization_202[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_214 (Conv2D)            (None, 60, 60, 64)   36928       ['activation_213[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_203 (Batch  (None, 60, 60, 64)  256         ['conv2d_214[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_214 (Activation)    (None, 60, 60, 64)   0           ['batch_normalization_203[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_46 (MaxPooling2D  (None, 30, 30, 64)  0           ['activation_214[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_90 (Dropout)           (None, 30, 30, 64)   0           ['max_pooling2d_46[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_215 (Conv2D)            (None, 30, 30, 128)  73856       ['dropout_90[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_204 (Batch  (None, 30, 30, 128)  512        ['conv2d_215[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_215 (Activation)    (None, 30, 30, 128)  0           ['batch_normalization_204[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_216 (Conv2D)            (None, 30, 30, 128)  147584      ['activation_215[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_205 (Batch  (None, 30, 30, 128)  512        ['conv2d_216[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_216 (Activation)    (None, 30, 30, 128)  0           ['batch_normalization_205[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling2d_47 (MaxPooling2D  (None, 15, 15, 128)  0          ['activation_216[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_91 (Dropout)           (None, 15, 15, 128)  0           ['max_pooling2d_47[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_217 (Conv2D)            (None, 15, 15, 256)  295168      ['dropout_91[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_206 (Batch  (None, 15, 15, 256)  1024       ['conv2d_217[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_217 (Activation)    (None, 15, 15, 256)  0           ['batch_normalization_206[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_218 (Conv2D)            (None, 15, 15, 256)  590080      ['activation_217[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_207 (Batch  (None, 15, 15, 256)  1024       ['conv2d_218[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_218 (Activation)    (None, 15, 15, 256)  0           ['batch_normalization_207[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_transpose_44 (Conv2DTra  (None, 30, 30, 128)  131200     ['activation_218[0][0]']         \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_44 (Concatenate)   (None, 30, 30, 256)  0           ['conv2d_transpose_44[0][0]',    \n",
      "                                                                  'activation_216[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_92 (Dropout)           (None, 30, 30, 256)  0           ['concatenate_44[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_219 (Conv2D)            (None, 30, 30, 128)  295040      ['dropout_92[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_208 (Batch  (None, 30, 30, 128)  512        ['conv2d_219[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_219 (Activation)    (None, 30, 30, 128)  0           ['batch_normalization_208[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_220 (Conv2D)            (None, 30, 30, 128)  147584      ['activation_219[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_209 (Batch  (None, 30, 30, 128)  512        ['conv2d_220[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_220 (Activation)    (None, 30, 30, 128)  0           ['batch_normalization_209[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_transpose_45 (Conv2DTra  (None, 60, 60, 64)  32832       ['activation_220[0][0]']         \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_45 (Concatenate)   (None, 60, 60, 128)  0           ['conv2d_transpose_45[0][0]',    \n",
      "                                                                  'activation_214[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_93 (Dropout)           (None, 60, 60, 128)  0           ['concatenate_45[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_221 (Conv2D)            (None, 60, 60, 64)   73792       ['dropout_93[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_210 (Batch  (None, 60, 60, 64)  256         ['conv2d_221[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_221 (Activation)    (None, 60, 60, 64)   0           ['batch_normalization_210[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_222 (Conv2D)            (None, 60, 60, 64)   36928       ['activation_221[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_211 (Batch  (None, 60, 60, 64)  256         ['conv2d_222[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_222 (Activation)    (None, 60, 60, 64)   0           ['batch_normalization_211[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_transpose_46 (Conv2DTra  (None, 120, 120, 32  8224       ['activation_222[0][0]']         \n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_46 (Concatenate)   (None, 120, 120, 64  0           ['conv2d_transpose_46[0][0]',    \n",
      "                                )                                 'activation_212[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_94 (Dropout)           (None, 120, 120, 64  0           ['concatenate_46[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_223 (Conv2D)            (None, 120, 120, 32  18464       ['dropout_94[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_212 (Batch  (None, 120, 120, 32  128        ['conv2d_223[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_223 (Activation)    (None, 120, 120, 32  0           ['batch_normalization_212[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_224 (Conv2D)            (None, 120, 120, 32  9248        ['activation_223[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_213 (Batch  (None, 120, 120, 32  128        ['conv2d_224[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_224 (Activation)    (None, 120, 120, 32  0           ['batch_normalization_213[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_47 (Conv2DTra  (None, 240, 240, 16  2064       ['activation_224[0][0]']         \n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_47 (Concatenate)   (None, 240, 240, 32  0           ['conv2d_transpose_47[0][0]',    \n",
      "                                )                                 'activation_210[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_95 (Dropout)           (None, 240, 240, 32  0           ['concatenate_47[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_225 (Conv2D)            (None, 240, 240, 16  4624        ['dropout_95[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_214 (Batch  (None, 240, 240, 16  64         ['conv2d_225[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_225 (Activation)    (None, 240, 240, 16  0           ['batch_normalization_214[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_226 (Conv2D)            (None, 240, 240, 16  2320        ['activation_225[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_215 (Batch  (None, 240, 240, 16  64         ['conv2d_226[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " activation_226 (Activation)    (None, 240, 240, 16  0           ['batch_normalization_215[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_227 (Conv2D)            (None, 240, 240, 1)  17          ['activation_226[0][0]']         \n",
      "                                                                                                  \n",
      " activation_227 (Activation)    (None, 240, 240, 1)  0           ['conv2d_227[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,946,705\n",
      "Trainable params: 1,943,761\n",
      "Non-trainable params: 2,944\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "## Task1a) Lung segmentation in chest X-ray images:\n",
    "from random import shuffle\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "n_base =16\n",
    "LR = 1e-4\n",
    "batch_normalization = True\n",
    "dropout = True\n",
    "epochs = 50\n",
    "batch_size = 8\n",
    "\n",
    "img_w, img_h = 240,240\n",
    "img_ch = 1\n",
    "\n",
    "model = get_unet(img_w, img_h, img_ch, n_base, LR, \n",
    "                 batch_normalization, dropout)\n",
    "\n",
    "## BCE Parameters\n",
    "# model.compile(loss = 'binary_crossentropy',          # Model Compiling   \n",
    "#               optimizer = Adam(lr = LR),\n",
    "#               metrics = ['binary_accuracy'])\n",
    "\n",
    "\n",
    "## Dice Parameters\n",
    "model.compile(loss = [dice_coef_loss],          # Model Compiling   \n",
    "              optimizer = Adam(lr = LR),\n",
    "              metrics = [dice_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get paths for images and masks\n",
    "datapath = '/DL_course_data/Lab3/MRI/' \n",
    "image_path = '/DL_course_data/Lab3/MRI/Image'\n",
    "mask_path = '/DL_course_data/Lab3/MRI/Mask'\n",
    "\n",
    "image_path_list = os.listdir(image_path)\n",
    "mask_path_list = os.listdir(mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7523 validated image filenames belonging to 9403 classes.\n",
      "Found 1880 validated image filenames belonging to 9403 classes.\n"
     ]
    }
   ],
   "source": [
    "## Try out with flow from dataframe\n",
    "\n",
    "image_list = [os.path.join(image_path,i) for i in image_path_list]\n",
    "mask_list = [ i.replace(\".png\",\"_Tumor.png\") for i in image_list]\n",
    "data = pd.DataFrame()\n",
    "data['images'] = image_list\n",
    "data['masks'] = mask_list\n",
    "\n",
    "\n",
    "## Generator\n",
    "datagen = ImageDataGenerator(rescale=1/255.,validation_split=0.2)\n",
    "    \n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    data,\n",
    "    x_col = 'images',\n",
    "    y_col = 'masks',\n",
    "    color_mode = 'grayscale',\n",
    "    target_size=(128,128),\n",
    "    class_model = None,\n",
    "    batch_size = batch_size,\n",
    "    subset = 'training',\n",
    "    shuffle = True,\n",
    "    seed = 1)\n",
    "\n",
    "val_generator = datagen.flow_from_dataframe(\n",
    "    data,\n",
    "    x_col = 'images',\n",
    "    y_col = 'masks',\n",
    "    color_mode = 'grayscale',\n",
    "    target_size=(128,128),\n",
    "    class_model = None,\n",
    "    batch_size = batch_size,\n",
    "    subset = 'validation',\n",
    "    shuffle = True,\n",
    "    seed = 1) \n",
    "\n",
    "\n",
    "train_steps = train_generator.n//train_generator.batch_size\n",
    "val_steps = val_generator.n//val_generator.batch_size\n",
    "\n",
    "# model_histogram = model.fit_generator(train_generator, \n",
    "#     steps_per_epoch = train_steps,\n",
    "#     validation_data = val_generator, validation_steps = val_steps,\n",
    "#     epochs = epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(image_path,mask_path, img_h, img_w, p):\n",
    "    \n",
    "    images = []\n",
    "    masks = []\n",
    "\n",
    "    for image in image_list:\n",
    "        img = imread(image, as_gray=True)  # \"as_grey\"\n",
    "        img = resize(img, (img_h, img_w), anti_aliasing=True).astype('float32')\n",
    "        images.append(img)\n",
    "\n",
    "    for mask in mask_list:\n",
    "        mask_img = imread(mask, as_gray=True)\n",
    "        mask = resize(mask_img, (img_h, img_w), anti_aliasing=True).astype('float32')\n",
    "        masks.append(mask)\n",
    "\n",
    "    ## Load data in traditional way\n",
    "    img_train, img_val, mask_train, mask_val = train_test_split(images, masks, shuffle = True,\n",
    "                                                      test_size = p)\n",
    "    img_train = np.expand_dims(img_train, axis = -1)\n",
    "    img_train = np.array(img_train)\n",
    "    img_val = np.expand_dims(img_val, axis = -1)    \n",
    "    img_val = np.array(img_val)\n",
    "    mask_train = np.expand_dims(mask_train, axis = -1)\n",
    "    mask_train = np.array(mask_train)\n",
    "    mask_val = np.expand_dims(mask_val, axis = -1)\n",
    "    mask_val = np.array(mask_val)\n",
    "    \n",
    "    return img_train, img_val, mask_train, mask_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = [os.path.join(image_path,i) for i in image_path_list]\n",
    "mask_list = [ os.path.join(mask_path,i.replace(\".png\",\"_Tumor.png\")) for i in image_path_list]\n",
    "img_train, img_val, mask_train, mask_val = load_data(image_list,mask_list, 240, 240, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-148-c0b37f3fbfff>:17: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model_histogram = model.fit_generator(train_generator, steps_per_epoch = train_generator.n//batch_size,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "940/940 [==============================] - 83s 86ms/step - loss: 0.9218 - dice_coef: 0.0782 - val_loss: 0.9323 - val_dice_coef: 0.0677\n",
      "Epoch 2/50\n",
      "940/940 [==============================] - 80s 85ms/step - loss: 0.8803 - dice_coef: 0.1197 - val_loss: 0.9857 - val_dice_coef: 0.0143\n",
      "Epoch 3/50\n",
      "940/940 [==============================] - 76s 81ms/step - loss: 0.8421 - dice_coef: 0.1578 - val_loss: 0.9889 - val_dice_coef: 0.0111\n",
      "Epoch 4/50\n",
      "940/940 [==============================] - 76s 81ms/step - loss: 0.8123 - dice_coef: 0.1875 - val_loss: 0.9968 - val_dice_coef: 0.0032\n",
      "Epoch 5/50\n",
      "940/940 [==============================] - 76s 81ms/step - loss: 0.7903 - dice_coef: 0.2098 - val_loss: 0.9966 - val_dice_coef: 0.0034\n",
      "Epoch 6/50\n",
      "940/940 [==============================] - 76s 81ms/step - loss: 0.7867 - dice_coef: 0.2132 - val_loss: 0.9988 - val_dice_coef: 0.0012\n",
      "Epoch 7/50\n",
      "940/940 [==============================] - 76s 81ms/step - loss: 0.7723 - dice_coef: 0.2276 - val_loss: 0.9995 - val_dice_coef: 4.8457e-04\n",
      "Epoch 8/50\n",
      "940/940 [==============================] - 76s 81ms/step - loss: 0.7681 - dice_coef: 0.2321 - val_loss: 0.9997 - val_dice_coef: 2.6980e-04\n",
      "Epoch 9/50\n",
      "940/940 [==============================] - 76s 81ms/step - loss: 0.7628 - dice_coef: 0.2370 - val_loss: 0.9999 - val_dice_coef: 1.3281e-04\n",
      "Epoch 10/50\n",
      "940/940 [==============================] - 76s 81ms/step - loss: 0.7548 - dice_coef: 0.2451 - val_loss: 0.9998 - val_dice_coef: 1.9552e-04\n",
      "Epoch 12/50\n",
      "940/940 [==============================] - 76s 81ms/step - loss: 0.7523 - dice_coef: 0.2475 - val_loss: 1.0000 - val_dice_coef: 3.2912e-05\n",
      "Epoch 13/50\n",
      "940/940 [==============================] - 76s 81ms/step - loss: 0.7510 - dice_coef: 0.2491 - val_loss: 0.9997 - val_dice_coef: 2.5903e-04\n",
      "Epoch 14/50\n",
      "940/940 [==============================] - 76s 81ms/step - loss: 0.7486 - dice_coef: 0.2514 - val_loss: 1.0000 - val_dice_coef: 2.9616e-05\n",
      "Epoch 15/50\n",
      "123/940 [==>...........................] - ETA: 1:00 - loss: 0.7587 - dice_coef: 0.2413"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "747/940 [======================>.......] - ETA: 14s - loss: 0.7486 - dice_coef: 0.2512"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/xinyi/Desktop/dp_labs/Lab4/bonus_task.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/xinyi/Desktop/dp_labs/Lab4/bonus_task.ipynb#X34sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m train_generator \u001b[39m=\u001b[39m image_aug\u001b[39m.\u001b[39mflow(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xinyi/Desktop/dp_labs/Lab4/bonus_task.ipynb#X34sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                                 img_train,mask_train,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xinyi/Desktop/dp_labs/Lab4/bonus_task.ipynb#X34sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                                 batch_size \u001b[39m=\u001b[39m batch_size)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xinyi/Desktop/dp_labs/Lab4/bonus_task.ipynb#X34sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m val_generator \u001b[39m=\u001b[39m image_aug\u001b[39m.\u001b[39mflow(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xinyi/Desktop/dp_labs/Lab4/bonus_task.ipynb#X34sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m                                 img_val,mask_val,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xinyi/Desktop/dp_labs/Lab4/bonus_task.ipynb#X34sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m                                 batch_size \u001b[39m=\u001b[39m batch_size)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/xinyi/Desktop/dp_labs/Lab4/bonus_task.ipynb#X34sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m model_histogram \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit_generator(train_generator, steps_per_epoch \u001b[39m=\u001b[39;49m train_generator\u001b[39m.\u001b[39;49mn\u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49mbatch_size,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xinyi/Desktop/dp_labs/Lab4/bonus_task.ipynb#X34sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     validation_data \u001b[39m=\u001b[39;49m val_generator, validation_steps \u001b[39m=\u001b[39;49m val_generator\u001b[39m.\u001b[39;49mn\u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49mbatch_size,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xinyi/Desktop/dp_labs/Lab4/bonus_task.ipynb#X34sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     epochs \u001b[39m=\u001b[39;49m epochs,  verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py:2260\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2249\u001b[0m \u001b[39m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[1;32m   2250\u001b[0m \n\u001b[1;32m   2251\u001b[0m \u001b[39mDEPRECATED:\u001b[39;00m\n\u001b[1;32m   2252\u001b[0m \u001b[39m  `Model.fit` now supports generators, so there is no longer any need to use\u001b[39;00m\n\u001b[1;32m   2253\u001b[0m \u001b[39m  this endpoint.\u001b[39;00m\n\u001b[1;32m   2254\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2255\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   2256\u001b[0m     \u001b[39m'\u001b[39m\u001b[39m`Model.fit_generator` is deprecated and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   2257\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mwill be removed in a future version. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   2258\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   2259\u001b[0m     stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m-> 2260\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m   2261\u001b[0m     generator,\n\u001b[1;32m   2262\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m   2263\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m   2264\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   2265\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   2266\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[1;32m   2267\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[1;32m   2268\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[1;32m   2269\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[1;32m   2270\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   2271\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   2272\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   2273\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m   2274\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py:1414\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1412\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs  \u001b[39m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[1;32m   1413\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[0;32m-> 1414\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[1;32m   1415\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[1;32m   1416\u001b[0m   \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py:438\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \n\u001b[1;32m    433\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 438\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m'\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m'\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py:297\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    296\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mend\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 297\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[1;32m    298\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    300\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m. Expected values are [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py:318\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    315\u001b[0m   batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[1;32m    316\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 318\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[1;32m    320\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    321\u001b[0m   end_hook_name \u001b[39m=\u001b[39m hook_name\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py:356\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[1;32m    355\u001b[0m   hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 356\u001b[0m   hook(batch, logs)\n\u001b[1;32m    358\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[1;32m    359\u001b[0m   \u001b[39mif\u001b[39;00m hook_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py:1034\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1033\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m-> 1034\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/callbacks.py:1106\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1102\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m add_seen\n\u001b[1;32m   1104\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1105\u001b[0m   \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1106\u001b[0m   logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39;49msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   1107\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen, \u001b[39mlist\u001b[39m(logs\u001b[39m.\u001b[39mitems()), finalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/tf_utils.py:607\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n\u001b[1;32m    605\u001b[0m   \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(t) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m t\n\u001b[0;32m--> 607\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/nest.py:916\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    912\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    913\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    915\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 916\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    917\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/nest.py:916\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    912\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    913\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    915\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 916\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    917\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/tf_utils.py:601\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    599\u001b[0m   \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    600\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, tf\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m--> 601\u001b[0m     t \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    602\u001b[0m   \u001b[39m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[39;00m\n\u001b[1;32m    603\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(t, (np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mgeneric)):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py:1159\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \n\u001b[1;32m   1138\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1156\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1159\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1160\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py:1125\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1124\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1125\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[1;32m   1126\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Add data augmentation\n",
    "image_aug = ImageDataGenerator(rotation_range=20,\n",
    "                                width_shift_range=0.2,\n",
    "                                height_shift_range=0.2,\n",
    "                                zoom_range = 0.3,\n",
    "                                horizontal_flip=True,\n",
    "                                rescale=1. / 255)\n",
    "\n",
    "train_generator = image_aug.flow(\n",
    "                                img_train,mask_train,\n",
    "                                batch_size = batch_size)\n",
    "\n",
    "val_generator = image_aug.flow(\n",
    "                                img_val,mask_val,\n",
    "                                batch_size = batch_size)\n",
    "\n",
    "model_histogram = model.fit_generator(train_generator, steps_per_epoch = train_generator.n//batch_size,\n",
    "    validation_data = val_generator, validation_steps = val_generator.n//batch_size,\n",
    "    epochs = epochs,  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = imread('/DL_course_data/Lab3/CT/Image/Im68_54.png')\n",
    "mask = imread('/DL_course_data/Lab3/CT/Mask/Im68_54.png')\n",
    "\n",
    "row, col = image.shape\n",
    "def show_paired(pic_1, pic_2):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "    ax = axes.ravel()\n",
    "    ax[0].imshow(pic_1, cmap='gray')\n",
    "    ax[0].set_title(\"Brain image\")\n",
    "    ax[1].imshow(pic_2, cmap='gray')\n",
    "    ax[1].set_title(\"Mask image\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "show_paired(image,mask)\n",
    "\n",
    "# mask_n = imread('/DL_course_data/Lab3/MRI/Mask/Brats17_TCIA_280_1_t1ce_52_Tumor.png')\n",
    "# mask_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
