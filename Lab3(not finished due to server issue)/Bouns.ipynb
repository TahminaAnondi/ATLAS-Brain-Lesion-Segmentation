{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                  # for working with tensors outside the network\n",
    "import pandas as pd                 # for data reading and writing\n",
    "import matplotlib.pyplot as plt     # for data inspection\n",
    "import os\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, Activation, BatchNormalization, GlobalAveragePooling2D, Dense, Dropout\n",
    "from keras.layers import add\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from keras.activations import relu, softmax\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block(n_output, upscale=False):\n",
    "    # n_output: number of feature maps in the block\n",
    "    # upscale: should we use the 1x1 conv2d mapping for shortcut or not\n",
    "    \n",
    "    # keras functional api: return the function of type\n",
    "    # Tensor -> Tensor\n",
    "    def f(x):\n",
    "        \n",
    "        # H_l(x):\n",
    "        # first pre-activation\n",
    "        h = BatchNormalization()(x)\n",
    "        h = Activation(relu)(h)\n",
    "        \n",
    "        # first convolution\n",
    "        h = Conv2D(kernel_size=3, filters=n_output, strides=1, padding='same', kernel_regularizer=regularizers.l2(0.01))(h)\n",
    "        \n",
    "        # second pre-activation\n",
    "        h = BatchNormalization()(x)\n",
    "        h = Activation(relu)(h)\n",
    "        # second convolution\n",
    "        h = Conv2D(kernel_size=3, filters=n_output, strides=1, padding='same', kernel_regularizer=regularizers.l2(0.01))(h)\n",
    "        \n",
    "        # f(x):\n",
    "        if upscale:\n",
    "            # 1x1 conv2d\n",
    "            f = Conv2D(kernel_size=1, filters=n_output, strides=1, padding='same')(x)\n",
    "        else:\n",
    "            # identity\n",
    "            f = x\n",
    "        \n",
    "        # F_l(x) = f(x) + H_l(x):\n",
    "        return add([f, h])\n",
    "    \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input tensor is the 128x128 grayscale image of X-ray\n",
    "def ResNet():\n",
    "    input_tensor = Input((128, 128, 1))\n",
    "\n",
    "    # first conv2d with post-activation to transform the input data to some reasonable form\n",
    "    x = Conv2D(kernel_size=3, filters=16, strides=1, padding='same', kernel_regularizer=regularizers.l2(0.01))(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(relu)(x)\n",
    "\n",
    "    # F_1\n",
    "    x = block(16)(x)\n",
    "    # F_2\n",
    "    x = block(16)(x)\n",
    "\n",
    "    # F_3\n",
    "    # H_3 is the function from the tensor of size 28x28x16 to the the tensor of size 28x28x32\n",
    "    # and we can't add together tensors of inconsistent sizes, so we use upscale=True\n",
    "    # x = block(32, upscale=True)(x)       # !!! <------- Uncomment for local evaluation\n",
    "    # F_4\n",
    "    # x = block(32)(x)                     # !!! <------- Uncomment for local evaluation\n",
    "    # F_5\n",
    "    # x = block(32)(x)                     # !!! <------- Uncomment for local evaluation\n",
    "\n",
    "    # F_6\n",
    "    # x = block(48, upscale=True)(x)       # !!! <------- Uncomment for local evaluation\n",
    "    # F_7\n",
    "    # x = block(48)(x)                     # !!! <------- Uncomment for local evaluation\n",
    "\n",
    "    # last activation of the entire network's output\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(relu)(x)\n",
    "\n",
    "    # average pooling across the channels\n",
    "    # 28x28x48 -> 1x48\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    # dropout for more robust learning\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    # last softmax layer\n",
    "    x = Dense(units=9, kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    x = Activation(softmax)(x)\n",
    "\n",
    "    model = Model(inputs=input_tensor, outputs=x)\n",
    "    return model\n",
    "\n",
    "model = ResNet()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data and model parameters\n",
    "img_ch, img_width, img_height = 1, 128, 128\n",
    "n_epochs = 80\n",
    "Batch_Size = 32\n",
    "Base = 8\n",
    "LR = 0.00001\n",
    "\n",
    "TRAIN_DIR = '/DL_course_data/Lab1/X_ray/train/'\n",
    "VAL_DIR = '/DL_course_data/Lab1/X_ray/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: 0/5780  of train images\n",
      "Reading: 100/5780  of train images\n",
      "Reading: 200/5780  of train images\n",
      "Reading: 300/5780  of train images\n",
      "Reading: 400/5780  of train images\n",
      "Reading: 500/5780  of train images\n",
      "Reading: 600/5780  of train images\n",
      "Reading: 700/5780  of train images\n",
      "Reading: 800/5780  of train images\n",
      "Reading: 900/5780  of train images\n",
      "Reading: 1000/5780  of train images\n",
      "Reading: 1100/5780  of train images\n",
      "Reading: 1200/5780  of train images\n",
      "Reading: 1300/5780  of train images\n",
      "Reading: 1400/5780  of train images\n",
      "Reading: 1500/5780  of train images\n",
      "Reading: 1600/5780  of train images\n",
      "Reading: 1700/5780  of train images\n",
      "Reading: 1800/5780  of train images\n",
      "Reading: 1900/5780  of train images\n",
      "Reading: 2000/5780  of train images\n",
      "Reading: 2100/5780  of train images\n",
      "Reading: 2200/5780  of train images\n",
      "Reading: 2300/5780  of train images\n",
      "Reading: 2400/5780  of train images\n",
      "Reading: 2500/5780  of train images\n",
      "Reading: 2600/5780  of train images\n",
      "Reading: 2700/5780  of train images\n",
      "Reading: 2800/5780  of train images\n",
      "Reading: 2900/5780  of train images\n",
      "Reading: 3000/5780  of train images\n",
      "Reading: 3100/5780  of train images\n",
      "Reading: 3200/5780  of train images\n",
      "Reading: 3300/5780  of train images\n",
      "Reading: 3400/5780  of train images\n",
      "Reading: 3500/5780  of train images\n",
      "Reading: 3600/5780  of train images\n",
      "Reading: 3700/5780  of train images\n",
      "Reading: 3800/5780  of train images\n",
      "Reading: 3900/5780  of train images\n",
      "Reading: 4000/5780  of train images\n",
      "Reading: 4100/5780  of train images\n",
      "Reading: 4200/5780  of train images\n",
      "Reading: 4300/5780  of train images\n",
      "Reading: 4400/5780  of train images\n",
      "Reading: 4500/5780  of train images\n",
      "Reading: 4600/5780  of train images\n",
      "Reading: 4700/5780  of train images\n",
      "Reading: 4800/5780  of train images\n",
      "Reading: 4900/5780  of train images\n",
      "Reading: 5000/5780  of train images\n",
      "Reading: 5100/5780  of train images\n",
      "Reading: 5200/5780  of train images\n",
      "Reading: 5300/5780  of train images\n",
      "Reading: 5400/5780  of train images\n",
      "Reading: 5500/5780  of train images\n",
      "Reading: 5600/5780  of train images\n",
      "Reading: 5700/5780  of train images\n",
      "Reading: 0/450  of train images\n",
      "Reading: 100/450  of train images\n",
      "Reading: 200/450  of train images\n",
      "Reading: 300/450  of train images\n",
      "Reading: 400/450  of train images\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "\n",
    "def gen_labels(im_name, pat1, pat2, pat3, pat4, pat5, pat6, pat7, pat8, pat9):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    im_name : Str\n",
    "        The image file name.\n",
    "    pat1 : Str\n",
    "        A string pattern in the filename for 1st class, e.g \"Mel\"\n",
    "    pat2 : Str\n",
    "        A string pattern in the filename 2nd class, e.g, \"Nev\"\n",
    "    Returns\n",
    "    -------\n",
    "    Label : Numpy array\n",
    "        Class label of the filename name based on its pattern.\n",
    "    '''\n",
    "    if pat1 in im_name:\n",
    "        label = np.array([0])\n",
    "    elif pat2 in im_name:\n",
    "        label = np.array([1])\n",
    "    elif pat3 in im_name:\n",
    "        label = np.array([2])\n",
    "    elif pat4 in im_name:\n",
    "        label = np.array([3])\n",
    "    elif pat5 in im_name:\n",
    "        label = np.array([4])\n",
    "    elif pat6 in im_name:\n",
    "        label = np.array([5])\n",
    "    elif pat7 in im_name:\n",
    "        label = np.array([6])\n",
    "    elif pat8 in im_name:\n",
    "        label = np.array([7])\n",
    "    elif pat9 in im_name:\n",
    "        label = np.array([8])\n",
    "    return label\n",
    "\n",
    "def get_data(data_path, data_list, img_h, img_w):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data_path : Str\n",
    "        Path to the data directory\n",
    "    train_list : List\n",
    "        A list containing the name of the images.\n",
    "    img_h : Int\n",
    "        image height to be resized to.\n",
    "    img_w : Int\n",
    "        image width to be resized to.\n",
    "    Returns\n",
    "    -------\n",
    "    img_labels : Nested List\n",
    "        A nested list containing the loaded images along with their\n",
    "        correcponding labels.\n",
    "    \"\"\"\n",
    "    img_labels = []\n",
    "    for item in enumerate(data_list):\n",
    "        img = imread(os.path.join(data_path, item[1]), as_gray = True) # \"as_grey\"\n",
    "        img = resize(img, (img_h, img_w), anti_aliasing = True).astype('float32')\n",
    "        img_labels.append([np.array(img), gen_labels(item[1], 'C1', 'C2','C3','C4','C5','C6','C7','C8','C9')])\n",
    "        if item[0] % 100 == 0:\n",
    "             print('Reading: {0}/{1}  of train images'.format(item[0], len(data_list)))\n",
    "    shuffle(img_labels)\n",
    "    return img_labels\n",
    "\n",
    "def get_data_arrays(nested_list, img_h, img_w):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    nested_list : nested list\n",
    "        nested list of image arrays with corresponding class labels.\n",
    "    img_h : Int\n",
    "        Image height.\n",
    "    img_w : Int\n",
    "    Image width.\n",
    "    Returns\n",
    "    -------\n",
    "    img_arrays : Numpy array\n",
    "        4D Array with the size of (n_data,img_h,img_w, 1)\n",
    "    label_arrays : Numpy array\n",
    "        1D array with the size (n_data).\n",
    "    \"\"\"\n",
    "    img_arrays = np.zeros((len(nested_list), img_h, img_w), dtype = np.float32)\n",
    "    label_arrays = np.zeros((len(nested_list)), dtype = np.int32)\n",
    "    for ind in range(len(nested_list)):\n",
    "        img_arrays[ind] = nested_list[ind][0]\n",
    "        label_arrays[ind] = nested_list[ind][1]\n",
    "    img_arrays = np.expand_dims(img_arrays, axis =3)\n",
    "    return img_arrays, label_arrays\n",
    "\n",
    "def get_train_test_arrays(train_data_path, test_data_path, train_list,\n",
    "                          test_list, img_h, img_w):\n",
    "    \"\"\"\n",
    "    Get the directory to the train and test sets, the files names and\n",
    "    the size of the image and return the image and label arrays for\n",
    "    train and test sets.\n",
    "    \"\"\"\n",
    "    train_data = get_data(train_data_path, train_list, img_h, img_w)\n",
    "    test_data = get_data(test_data_path, test_list, img_h, img_w)\n",
    "    train_img, train_label =  get_data_arrays(train_data, img_h, img_w)\n",
    "    test_img, test_label = get_data_arrays(test_data, img_h, img_w)\n",
    "    del(train_data)\n",
    "    del(test_data)\n",
    "    return train_img, test_img, train_label, test_label\n",
    "\n",
    "\n",
    "img_w, img_h = 128, 128      # Setting the width and heights of the images.\n",
    "data_path = '/DL_course_data/Lab1/X_ray'     # Path to data root with two subdirs.\n",
    "train_data_path = os.path.join(data_path, 'train')\n",
    "test_data_path = os.path.join(data_path, 'test')\n",
    "train_list = os.listdir(train_data_path)\n",
    "test_list = os.listdir(test_data_path)\n",
    "x_train, x_test, y_train, y_test = get_train_test_arrays(\n",
    "        train_data_path, test_data_path,\n",
    "        train_list, test_list, img_h, img_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5780"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "y_train_n = tf.keras.utils.to_categorical(y_train,num_classes=9, dtype='float32')\n",
    "y_test_n = tf.keras.utils.to_categorical(y_test,num_classes=9, dtype='float32')\n",
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6230\n"
     ]
    }
   ],
   "source": [
    "x = np.concatenate((x_train,x_test))\n",
    "y = np.concatenate((y_train_n,y_test_n))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rotation_range=10,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   rescale=1./255,\n",
    "                                   horizontal_flip=True)\n",
    "                    \n",
    "x_train_generator = train_datagen.flow(x_train,  \n",
    "                                    batch_size = Batch_Size)\n",
    "\n",
    "\n",
    "# Create validation generator\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "x_val_generator = val_datagen.flow(x_test, \n",
    "                                batch_size = Batch_Size,\n",
    "                                seed=42)\n",
    "\n",
    "                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class weight for the inbalance in the dataset\n",
    "from sklearn.utils import class_weight\n",
    "def get_length(idx):\n",
    "    return len(y_train[np.where(y_train == idx)])\n",
    "\n",
    "labels_dict = {0: get_length(0), 1: get_length(1), 2: get_length(2), 3: get_length(3), \n",
    "                4: get_length(4), 5: get_length(5), 6: get_length(6), 7: get_length(7), 8: get_length(8)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.0,\n",
       " 1: 1.0,\n",
       " 2: 1.0,\n",
       " 3: 1.8360104809901925,\n",
       " 4: 2.1044875736059234,\n",
       " 5: 2.3043534400507877,\n",
       " 6: 2.3730303058470072,\n",
       " 7: 2.4018784601846654,\n",
       " 8: 2.467393067295292}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def get_class_weight(labels_dict):\n",
    "    \"\"\"Calculate the weights of different categories\"\"\"\n",
    "    total = sum(labels_dict.values())\n",
    "    max_num = max(labels_dict.values())\n",
    "    mu = 1.0 / (total / max_num)\n",
    "    class_weight = dict()\n",
    "    for key, value in labels_dict.items():\n",
    "        score = math.log(mu * total / float(value))\n",
    "        class_weight[key] = score if score > 1.0 else 1.0\n",
    "    return class_weight\n",
    "\n",
    "class_weight = get_class_weight(labels_dict)\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create checkpoint for the model, save the best model\n",
    "mc = ModelCheckpoint('weights.best.keras', monitor='val_acc', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define learning rate scheduler \n",
    "# Use sigmoidal decay as the learning rate policy\n",
    "def sigmoidal_decay(e, start=0, end=100, lr_start=1e-3, lr_end=1e-5):\n",
    "    if e < start:\n",
    "        return lr_start\n",
    "    \n",
    "    if e > end:\n",
    "        return lr_end\n",
    "    \n",
    "    middle = (start + end) / 2\n",
    "    s = lambda x: 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    return s(13 * (-e + middle) / np.abs(end - start)) * np.abs(lr_start - lr_end) + lr_end\n",
    "\n",
    "xs = np.linspace(0, 100)\n",
    "ys = np.vectorize(sigmoidal_decay)(xs)\n",
    "plt.plot(xs, ys)\n",
    "plt.show()\n",
    "\n",
    "EPOCHS = 3                       \n",
    "lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=4)\n",
    "cvscores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      " 39/146 [=======>......................] - ETA: 2:39 - loss: 3.1890 - accuracy: 0.3862"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/xinyi/Documents/GitHub/deep_learning_G5/Lab3(not finished due to server issue)/Bouns.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/xinyi/Documents/GitHub/deep_learning_G5/Lab3%28not%20finished%20due%20to%20server%20issue%29/Bouns.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m model \u001b[39m=\u001b[39m ResNet()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xinyi/Documents/GitHub/deep_learning_G5/Lab3%28not%20finished%20due%20to%20server%20issue%29/Bouns.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/xinyi/Documents/GitHub/deep_learning_G5/Lab3%28not%20finished%20due%20to%20server%20issue%29/Bouns.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m History \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(x_train,y_train, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xinyi/Documents/GitHub/deep_learning_G5/Lab3%28not%20finished%20due%20to%20server%20issue%29/Bouns.ipynb#X12sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     validation_data \u001b[39m=\u001b[39;49m (x_val, y_val), \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xinyi/Documents/GitHub/deep_learning_G5/Lab3%28not%20finished%20due%20to%20server%20issue%29/Bouns.ipynb#X12sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     epochs \u001b[39m=\u001b[39;49m n_epochs,  verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, class_weight \u001b[39m=\u001b[39;49m class_weight, callbacks \u001b[39m=\u001b[39;49m [lr,mc])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xinyi/Documents/GitHub/deep_learning_G5/Lab3%28not%20finished%20due%20to%20server%20issue%29/Bouns.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m4\u001b[39m, \u001b[39m4\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xinyi/Documents/GitHub/deep_learning_G5/Lab3%28not%20finished%20due%20to%20server%20issue%29/Bouns.ipynb#X12sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m\"\u001b[39m\u001b[39mLearning curve\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run training for certain amount of epochs\n",
    "from matplotlib import image\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "for train, val in kf.split(x, y):\n",
    "    x_train, x_val = x[train],x[val]\n",
    "    y_train, y_val = y[train],y[val]\n",
    "\n",
    "    model = ResNet()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    History = model.fit(x_train,y_train, \n",
    "        validation_data = (x_val, y_val), \n",
    "        epochs = n_epochs,  verbose=1, class_weight = class_weight, callbacks = [lr,mc])\n",
    "\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.title(\"Learning curve\")\n",
    "    plt.plot(History.history[\"loss\"], label=\"loss\")\n",
    "    plt.plot(History.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.plot( np.argmin(History.history[\"val_loss\"]),\n",
    "            np.min(History.history[\"val_loss\"]),\n",
    "            marker=\"x\", color=\"r\", label=\"best model\")\n",
    "\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss Value\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    figure\n",
    "\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.plot(History.history[\"accuracy\"], label=\"accuracy\")\n",
    "    plt.plot(History.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "    plt.plot( np.argmax(History.history[\"val_accuracy\"]),\n",
    "            np.max(History.history[\"val_accuracy\"]),\n",
    "            marker=\"x\", color=\"r\", label=\"best model\")\n",
    "\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(x_val, y_val, verbose=1)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "    \n",
    "    print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU') \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
